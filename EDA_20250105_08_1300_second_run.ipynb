{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6e3e10-78d2-413c-87c3-f256294da062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor, log_evaluation, record_evaluation\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.impute import IterativeImputer\n",
    "import pickle\n",
    "import optuna\n",
    "from optuna.visualization import plot_slice, plot_param_importances\n",
    "import shap\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "pl.Config.set_fmt_str_lengths(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8421cc58-8b61-4b48-8c20-3544d3a81f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5a256f-c55b-415d-8d12-e753283ffee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'I:/Kaggle/jane-street-real-time-market-data-forecasting/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d215c3-e2a4-4ea2-8125-708737b10ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.csv',\n",
       " 'kaggle_evaluation',\n",
       " 'lags.parquet',\n",
       " 'my_folder',\n",
       " 'responders.csv',\n",
       " 'sample_submission.csv',\n",
       " 'team_folder',\n",
       " 'test.parquet',\n",
       " 'train.parquet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab47b6d-409b-41a7-a443-fcddc750f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47127338, 93)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_39</th><th>feature_40</th><th>feature_41</th><th>feature_42</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>3.889038</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.851033</td><td>0.242971</td><td>0.2634</td><td>-0.891687</td><td>11</td><td>7</td><td>76</td><td>-0.883028</td><td>0.003067</td><td>-0.744703</td><td>null</td><td>-0.169586</td><td>null</td><td>-1.335938</td><td>-1.707803</td><td>0.91013</td><td>null</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>null</td><td>null</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>null</td><td>null</td><td>null</td><td>0.28118</td><td>0.269163</td><td>0.349028</td><td>-0.012596</td><td>-0.225932</td><td>null</td><td>-1.073602</td><td>null</td><td>null</td><td>-0.181716</td><td>null</td><td>null</td><td>null</td><td>0.564021</td><td>2.088506</td><td>0.832022</td><td>null</td><td>0.204797</td><td>null</td><td>null</td><td>-0.808103</td><td>null</td><td>-2.037683</td><td>0.727661</td><td>null</td><td>-0.989118</td><td>-0.345213</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.251104</td><td>-0.110252</td><td>-0.491157</td><td>-1.02269</td><td>0.152241</td><td>-0.659864</td><td>null</td><td>null</td><td>-0.261412</td><td>-0.211486</td><td>-0.335556</td><td>-0.281498</td><td>0.775981</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>7</td><td>1.370613</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.676961</td><td>0.151984</td><td>0.192465</td><td>-0.521729</td><td>11</td><td>7</td><td>76</td><td>-0.865307</td><td>-0.225629</td><td>-0.582163</td><td>null</td><td>0.317467</td><td>null</td><td>-1.250016</td><td>-1.682929</td><td>1.412757</td><td>null</td><td>0.520378</td><td>0.744132</td><td>-0.788658</td><td>0.641776</td><td>null</td><td>null</td><td>0.2272</td><td>0.580907</td><td>1.128879</td><td>null</td><td>null</td><td>null</td><td>-1.512286</td><td>-1.414357</td><td>-1.823322</td><td>-0.082763</td><td>-0.184119</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-10.835207</td><td>-0.002704</td><td>-0.621836</td><td>null</td><td>1.172836</td><td>null</td><td>null</td><td>-1.625862</td><td>null</td><td>-1.410017</td><td>1.063013</td><td>null</td><td>0.888355</td><td>0.467994</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.065759</td><td>0.013322</td><td>-0.592855</td><td>-1.052685</td><td>-0.393726</td><td>-0.741603</td><td>null</td><td>null</td><td>-0.281207</td><td>-0.182894</td><td>-0.245565</td><td>-0.302441</td><td>0.703665</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>9</td><td>2.285698</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.056285</td><td>0.187227</td><td>0.249901</td><td>-0.77305</td><td>11</td><td>7</td><td>76</td><td>-0.675719</td><td>-0.199404</td><td>-0.586798</td><td>null</td><td>-0.814909</td><td>null</td><td>-1.296782</td><td>-2.040234</td><td>0.639589</td><td>null</td><td>1.597359</td><td>0.657514</td><td>-1.350148</td><td>0.364215</td><td>null</td><td>null</td><td>-0.017751</td><td>-0.317361</td><td>-0.122379</td><td>null</td><td>null</td><td>null</td><td>-0.320921</td><td>-0.95809</td><td>-2.436589</td><td>0.070999</td><td>-0.245239</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.420632</td><td>-3.515137</td><td>-4.67776</td><td>null</td><td>0.535897</td><td>null</td><td>null</td><td>-0.72542</td><td>null</td><td>-2.29417</td><td>1.764551</td><td>null</td><td>-0.120789</td><td>-0.063458</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.882604</td><td>-0.072482</td><td>-0.617934</td><td>-0.86323</td><td>-0.241892</td><td>-0.709919</td><td>null</td><td>null</td><td>0.377131</td><td>0.300724</td><td>-0.106842</td><td>-0.096792</td><td>2.109352</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>10</td><td>0.690606</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.139366</td><td>0.273328</td><td>0.306549</td><td>-1.262223</td><td>42</td><td>5</td><td>150</td><td>-0.694008</td><td>3.004091</td><td>0.114809</td><td>null</td><td>-0.251882</td><td>null</td><td>-1.902009</td><td>-0.979447</td><td>0.241165</td><td>null</td><td>-0.392359</td><td>-0.224699</td><td>-2.129397</td><td>-0.855287</td><td>null</td><td>null</td><td>0.404142</td><td>-0.578156</td><td>0.105702</td><td>null</td><td>null</td><td>null</td><td>0.544138</td><td>-0.087091</td><td>-1.500147</td><td>-0.201288</td><td>-0.038042</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.382074</td><td>2.669135</td><td>0.611711</td><td>null</td><td>2.413415</td><td>null</td><td>null</td><td>1.313203</td><td>null</td><td>-0.810125</td><td>2.939022</td><td>null</td><td>3.988801</td><td>1.834661</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.697595</td><td>1.074309</td><td>-0.206929</td><td>-0.530602</td><td>4.765215</td><td>0.571554</td><td>null</td><td>null</td><td>-0.226891</td><td>-0.251412</td><td>-0.215522</td><td>-0.296244</td><td>1.114137</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>14</td><td>0.44057</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.9552</td><td>0.262404</td><td>0.344457</td><td>-0.613813</td><td>44</td><td>3</td><td>16</td><td>-0.947351</td><td>-0.030018</td><td>-0.502379</td><td>null</td><td>0.646086</td><td>null</td><td>-1.844685</td><td>-1.58656</td><td>-0.182024</td><td>null</td><td>-0.969949</td><td>-0.673813</td><td>-1.282132</td><td>-1.399894</td><td>null</td><td>null</td><td>0.043815</td><td>-0.320225</td><td>-0.031713</td><td>null</td><td>null</td><td>null</td><td>-0.08842</td><td>-0.995003</td><td>-2.635336</td><td>-0.196461</td><td>-0.618719</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-2.0146</td><td>-2.321076</td><td>-3.711265</td><td>null</td><td>1.253902</td><td>null</td><td>null</td><td>0.476195</td><td>null</td><td>-0.771732</td><td>2.843421</td><td>null</td><td>1.379815</td><td>0.411827</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.948601</td><td>-0.136814</td><td>-0.447704</td><td>-1.141761</td><td>0.099631</td><td>-0.661928</td><td>null</td><td>null</td><td>3.678076</td><td>2.793581</td><td>2.61825</td><td>3.418133</td><td>-3.57282</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 93)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ dat ┆ tim ┆ sym ┆ wei ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res │\n",
       "│ e_i ┆ e_i ┆ bol ┆ ght ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon │\n",
       "│ d   ┆ d   ┆ _id ┆ --- ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der │\n",
       "│ --- ┆ --- ┆ --- ┆ f32 ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ _6  ┆ _0_ ┆ _1_ ┆ _2_ ┆ _3_ ┆ _4_ ┆ _5_ ┆ _6_ ┆ _7_ ┆ _8_ │\n",
       "│ i16 ┆ i16 ┆ i8  ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag │\n",
       "│     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ i8  ┆ i8  ┆ i16 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 0   ┆ 0   ┆ 1   ┆ 3.8 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.8 ┆ 0.2 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ 0.0 ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -1. ┆ 0.9 ┆ nul ┆ 1.6 ┆ 1.5 ┆ -1. ┆ -0. ┆ nul ┆ nul ┆ 1.3 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.2 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ -0. ┆ nul ┆ -1. ┆ nul ┆ nul ┆ -0. ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ 2.0 ┆ 0.8 ┆ nul ┆ 0.2 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 0.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -0. ┆ -0. ┆ -1. ┆ 0.1 ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 890 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 510 ┆ 429 ┆ 634 ┆ 891 ┆     ┆     ┆     ┆ 883 ┆ 030 ┆ 744 ┆ l   ┆ 169 ┆ l   ┆ 335 ┆ 707 ┆ 101 ┆ l   ┆ 364 ┆ 221 ┆ 551 ┆ 229 ┆ l   ┆ l   ┆ 783 ┆ 283 ┆ 231 ┆ l   ┆ l   ┆ l   ┆ 811 ┆ 691 ┆ 490 ┆ 012 ┆ 225 ┆ l   ┆ 073 ┆ l   ┆ l   ┆ 181 ┆ l   ┆ l   ┆ l   ┆ 640 ┆ 885 ┆ 320 ┆ l   ┆ 047 ┆ l   ┆ l   ┆ 808 ┆ l   ┆ 037 ┆ 276 ┆ l   ┆ 989 ┆ 345 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 251 ┆ 110 ┆ 491 ┆ 022 ┆ 522 ┆ 659 ┆ l   ┆ l   ┆ 261 ┆ 211 ┆ 335 ┆ 281 ┆ 759 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 38  ┆     ┆     ┆     ┆     ┆     ┆ 33  ┆ 71  ┆     ┆ 687 ┆     ┆     ┆     ┆ 028 ┆ 67  ┆ 703 ┆     ┆ 586 ┆     ┆ 938 ┆ 803 ┆ 3   ┆     ┆ 31  ┆ 33  ┆ 398 ┆ 627 ┆     ┆     ┆ 01  ┆ 712 ┆ 96  ┆     ┆     ┆     ┆ 8   ┆ 63  ┆ 28  ┆ 596 ┆ 932 ┆     ┆ 602 ┆     ┆     ┆ 716 ┆     ┆     ┆     ┆ 21  ┆ 06  ┆ 22  ┆     ┆ 97  ┆     ┆     ┆ 103 ┆     ┆ 683 ┆ 61  ┆     ┆ 118 ┆ 213 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 104 ┆ 252 ┆ 157 ┆ 69  ┆ 41  ┆ 864 ┆     ┆     ┆ 412 ┆ 486 ┆ 556 ┆ 498 ┆ 81  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 7   ┆ 1.3 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.6 ┆ 0.1 ┆ 0.1 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.3 ┆ nul ┆ -1. ┆ -1. ┆ 1.4 ┆ nul ┆ 0.5 ┆ 0.7 ┆ -0. ┆ 0.6 ┆ nul ┆ nul ┆ 0.2 ┆ 0.5 ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -1. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -10 ┆ -0. ┆ -0. ┆ nul ┆ 1.1 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 1.0 ┆ nul ┆ 0.8 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ 0.0 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 706 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 769 ┆ 519 ┆ 924 ┆ 521 ┆     ┆     ┆     ┆ 865 ┆ 225 ┆ 582 ┆ l   ┆ 174 ┆ l   ┆ 250 ┆ 682 ┆ 127 ┆ l   ┆ 203 ┆ 441 ┆ 788 ┆ 417 ┆ l   ┆ l   ┆ 272 ┆ 809 ┆ 288 ┆ l   ┆ l   ┆ l   ┆ 512 ┆ 414 ┆ 823 ┆ 082 ┆ 184 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ .83 ┆ 002 ┆ 621 ┆ l   ┆ 728 ┆ l   ┆ l   ┆ 625 ┆ l   ┆ 410 ┆ 630 ┆ l   ┆ 883 ┆ 679 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 065 ┆ 133 ┆ 592 ┆ 052 ┆ 393 ┆ 741 ┆ l   ┆ l   ┆ 281 ┆ 182 ┆ 245 ┆ 302 ┆ 036 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 13  ┆     ┆     ┆     ┆     ┆     ┆ 61  ┆ 84  ┆ 65  ┆ 729 ┆     ┆     ┆     ┆ 307 ┆ 629 ┆ 163 ┆     ┆ 67  ┆     ┆ 016 ┆ 929 ┆ 57  ┆     ┆ 78  ┆ 32  ┆ 658 ┆ 76  ┆     ┆     ┆     ┆ 07  ┆ 79  ┆     ┆     ┆     ┆ 286 ┆ 357 ┆ 322 ┆ 763 ┆ 119 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 520 ┆ 704 ┆ 836 ┆     ┆ 36  ┆     ┆     ┆ 862 ┆     ┆ 017 ┆ 13  ┆     ┆ 55  ┆ 94  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 759 ┆ 22  ┆ 855 ┆ 685 ┆ 726 ┆ 603 ┆     ┆     ┆ 207 ┆ 894 ┆ 565 ┆ 441 ┆ 65  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 9   ┆ 2.2 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.0 ┆ 0.1 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -2. ┆ 0.6 ┆ nul ┆ 1.5 ┆ 0.6 ┆ -1. ┆ 0.3 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -3. ┆ -4. ┆ nul ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 1.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ 0.3 ┆ 0.3 ┆ -0. ┆ -0. ┆ 2.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 856 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 562 ┆ 872 ┆ 499 ┆ 773 ┆     ┆     ┆     ┆ 675 ┆ 199 ┆ 586 ┆ l   ┆ 814 ┆ l   ┆ 296 ┆ 040 ┆ 395 ┆ l   ┆ 973 ┆ 575 ┆ 350 ┆ 642 ┆ l   ┆ l   ┆ 017 ┆ 317 ┆ 122 ┆ l   ┆ l   ┆ l   ┆ 320 ┆ 958 ┆ 436 ┆ 709 ┆ 245 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 420 ┆ 515 ┆ 677 ┆ l   ┆ 358 ┆ l   ┆ l   ┆ 725 ┆ l   ┆ 294 ┆ 645 ┆ l   ┆ 120 ┆ 063 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 882 ┆ 072 ┆ 617 ┆ 863 ┆ 241 ┆ 709 ┆ l   ┆ l   ┆ 771 ┆ 007 ┆ 106 ┆ 096 ┆ 093 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 98  ┆     ┆     ┆     ┆     ┆     ┆ 85  ┆ 27  ┆ 01  ┆ 05  ┆     ┆     ┆     ┆ 719 ┆ 404 ┆ 798 ┆     ┆ 909 ┆     ┆ 782 ┆ 234 ┆ 89  ┆     ┆ 59  ┆ 14  ┆ 148 ┆ 15  ┆     ┆     ┆ 751 ┆ 361 ┆ 379 ┆     ┆     ┆     ┆ 921 ┆ 09  ┆ 589 ┆ 99  ┆ 239 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 632 ┆ 137 ┆ 76  ┆     ┆ 97  ┆     ┆     ┆ 42  ┆     ┆ 17  ┆ 51  ┆     ┆ 789 ┆ 458 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 604 ┆ 482 ┆ 934 ┆ 23  ┆ 892 ┆ 919 ┆     ┆     ┆ 31  ┆ 24  ┆ 842 ┆ 792 ┆ 52  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 10  ┆ 0.6 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.1 ┆ 0.2 ┆ 0.3 ┆ -1. ┆ 42  ┆ 5   ┆ 150 ┆ -0. ┆ 3.0 ┆ 0.1 ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -0. ┆ 0.2 ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ nul ┆ nul ┆ 0.4 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.3 ┆ 2.6 ┆ 0.6 ┆ nul ┆ 2.4 ┆ nul ┆ nul ┆ 1.3 ┆ nul ┆ -0. ┆ 2.9 ┆ nul ┆ 3.9 ┆ 1.8 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ 1.0 ┆ -0. ┆ -0. ┆ 4.7 ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 906 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 393 ┆ 733 ┆ 065 ┆ 262 ┆     ┆     ┆     ┆ 694 ┆ 040 ┆ 148 ┆ l   ┆ 251 ┆ l   ┆ 902 ┆ 979 ┆ 411 ┆ l   ┆ 392 ┆ 224 ┆ 129 ┆ 855 ┆ l   ┆ l   ┆ 041 ┆ 578 ┆ 057 ┆ l   ┆ l   ┆ l   ┆ 441 ┆ 087 ┆ 500 ┆ 201 ┆ 038 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 820 ┆ 691 ┆ 117 ┆ l   ┆ 134 ┆ l   ┆ l   ┆ 132 ┆ l   ┆ 810 ┆ 390 ┆ l   ┆ 888 ┆ 346 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 697 ┆ 743 ┆ 206 ┆ 530 ┆ 652 ┆ 715 ┆ l   ┆ l   ┆ 226 ┆ 251 ┆ 215 ┆ 296 ┆ 141 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 06  ┆     ┆     ┆     ┆     ┆     ┆ 66  ┆ 28  ┆ 49  ┆ 223 ┆     ┆     ┆     ┆ 008 ┆ 91  ┆ 09  ┆     ┆ 882 ┆     ┆ 009 ┆ 447 ┆ 65  ┆     ┆ 359 ┆ 699 ┆ 397 ┆ 287 ┆     ┆     ┆ 42  ┆ 156 ┆ 02  ┆     ┆     ┆     ┆ 38  ┆ 091 ┆ 147 ┆ 288 ┆ 042 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 74  ┆ 35  ┆ 11  ┆     ┆ 15  ┆     ┆     ┆ 03  ┆     ┆ 125 ┆ 22  ┆     ┆ 01  ┆ 61  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 595 ┆ 09  ┆ 929 ┆ 602 ┆ 15  ┆ 54  ┆     ┆     ┆ 891 ┆ 412 ┆ 522 ┆ 244 ┆ 37  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 14  ┆ 0.4 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.9 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ 44  ┆ 3   ┆ 16  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.6 ┆ nul ┆ -1. ┆ -1. ┆ -0. ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ -1. ┆ nul ┆ nul ┆ 0.0 ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -2. ┆ -2. ┆ -3. ┆ nul ┆ 1.2 ┆ nul ┆ nul ┆ 0.4 ┆ nul ┆ -0. ┆ 2.8 ┆ nul ┆ 1.3 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ 3.6 ┆ 2.7 ┆ 2.6 ┆ 3.4 ┆ -3. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 405 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 552 ┆ 624 ┆ 444 ┆ 613 ┆     ┆     ┆     ┆ 947 ┆ 030 ┆ 502 ┆ l   ┆ 460 ┆ l   ┆ 844 ┆ 586 ┆ 182 ┆ l   ┆ 969 ┆ 673 ┆ 282 ┆ 399 ┆ l   ┆ l   ┆ 438 ┆ 320 ┆ 031 ┆ l   ┆ l   ┆ l   ┆ 088 ┆ 995 ┆ 635 ┆ 196 ┆ 618 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 014 ┆ 321 ┆ 711 ┆ l   ┆ 539 ┆ l   ┆ l   ┆ 761 ┆ l   ┆ 771 ┆ 434 ┆ l   ┆ 798 ┆ 118 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 948 ┆ 136 ┆ 447 ┆ 141 ┆ 996 ┆ 661 ┆ l   ┆ l   ┆ 780 ┆ 935 ┆ 182 ┆ 181 ┆ 572 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆ 04  ┆ 57  ┆ 813 ┆     ┆     ┆     ┆ 351 ┆ 018 ┆ 379 ┆     ┆ 86  ┆     ┆ 685 ┆ 56  ┆ 024 ┆     ┆ 949 ┆ 813 ┆ 132 ┆ 894 ┆     ┆     ┆ 15  ┆ 225 ┆ 713 ┆     ┆     ┆     ┆ 42  ┆ 003 ┆ 336 ┆ 461 ┆ 719 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 6   ┆ 076 ┆ 265 ┆     ┆ 02  ┆     ┆     ┆ 95  ┆     ┆ 732 ┆ 21  ┆     ┆ 15  ┆ 27  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 601 ┆ 814 ┆ 704 ┆ 761 ┆ 31  ┆ 928 ┆     ┆     ┆ 76  ┆ 81  ┆ 5   ┆ 33  ┆ 82  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pl.read_parquet(path + 'train.parquet/').select(pl.all().shrink_dtype())\n",
    "lags_df = train_df.with_columns(pl.col('date_id') + 1).drop(['weight', 'partition_id'] + [col for col in train_df.columns if 'feature' in col]).rename({f'responder_{x}': f'responder_{x}_lag_1' for x in range(9)})\n",
    "train_df = train_df.drop(['responder_0', 'responder_1', 'responder_2', 'responder_3', 'responder_4', 'responder_5', 'responder_7', 'responder_8', 'partition_id']).select(pl.all().shrink_dtype())\n",
    "train_df = train_df.join(lags_df, on=['date_id', 'time_id', 'symbol_id'], how='left').select(pl.all().shrink_dtype())\n",
    "del lags_df\n",
    "gc.collect()\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7434dcc6-f9b9-4e8a-aa41-50c724fd1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scan = pl.scan_parquet(path + 'train.parquet/')\n",
    "test_scan = pl.scan_parquet(path + 'test.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93569971-385d-4e5a-b362-ff4fbf80cf6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_symbol_ids_list = sorted(train_scan.select('symbol_id').unique().collect()['symbol_id'].to_list())\n",
    "test_symbol_ids_list = sorted(test_scan.select('symbol_id').unique().collect()['symbol_id'].to_list())\n",
    "unique_symbol_ids_list = sorted(list(set(train_symbol_ids_list + test_symbol_ids_list)))\n",
    "unique_symbol_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d27779c-c935-48d8-a8ce-42a39e8e1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_cat_cols(df):\n",
    "    for v in tqdm(unique_symbol_ids_list):\n",
    "        new_col_name = 'symbol_id_' + str(v)\n",
    "        #df[new_col_name] = (df['symbol_id'] == v).astype(int)\n",
    "        df = df.with_columns((pl.col('symbol_id') == v).cast(pl.Int8).alias(new_col_name))\n",
    "\n",
    "    \n",
    "    #df = df.drop('symbol_id', axis=1)\n",
    "\n",
    "    return df.select(pl.all().shrink_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3834f8e8-0f10-4891-a325-5d288f99b503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.032444032"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.estimated_size() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3ffe03-76cd-4ee5-bf7c-940de4646a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = path + 'my_folder/models/20250105_08/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e04716-a5a1-471c-b452-0a8b5f7a7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_online_learning(train_data):\n",
    "    weights = train_data['weight'].to_pandas()\n",
    "    y = train_data['responder_6'].to_pandas()\n",
    "\n",
    "    unique_date_ids = train_data['date_id'].unique()    \n",
    "    train_date_id_cut = 1300\n",
    "\n",
    "    print('max date:', unique_date_ids.max())\n",
    "    print('date id cut:', train_date_id_cut)\n",
    "\n",
    "    X_train = train_data.filter(pl.col('date_id') <= train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()#.sample(frac=0.01)\n",
    "    X_val = train_data.filter(pl.col('date_id') > train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "\n",
    "    print(X_train.shape[0] / train_data.shape[0])\n",
    "\n",
    "    y_train = y.loc[X_train.index]\n",
    "    y_val = y[-X_val.shape[0]:]\n",
    "\n",
    "    weights_train = weights.loc[X_train.index]\n",
    "    weights_val = weights[-X_val.shape[0]:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    display(X_train.head())\n",
    "    display(X_train.tail())\n",
    "    \n",
    "\n",
    "    #train_dataset = lgb.Dataset(data=X_train, label=y_train, weight=weights_train)\n",
    "    #val_dataset = lgb.Dataset(data=X_val, label=y_val, weight=weights_val)\n",
    "\n",
    "    base_params = {\n",
    "        'verbosity': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'device': 'gpu',\n",
    "        'early_stopping_round': 30,\n",
    "        'lambda_l2': 100,\n",
    "        #'metric': 'r2',\n",
    "        #'seed': 42\n",
    "    }\n",
    "\n",
    "    '''model = lgb.train(\n",
    "        params=base_params,\n",
    "        train_set=train_dataset,\n",
    "        num_boost_round=90\n",
    "    )'''\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=90000\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)])#, init_model=current_model)\n",
    "    #model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "    best_iteration = model.best_iteration_\n",
    "    print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "    plt.figure()\n",
    "    lgb.plot_metric(model)\n",
    "    plt.ylim(0, 2)\n",
    "    plt.show()\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "\n",
    "    print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "    return model\n",
    "\n",
    "    val_date_ids = sorted(train_data.filter(pl.col('date_id') > train_date_id_cut)['date_id'].unique())\n",
    "    \n",
    "    for date_id_v in val_date_ids:\n",
    "        for time_id_v in sorted(train_data.filter(pl.col('date_id') == date_id_v)['time_id'].unique()):\n",
    "            time_id_df = train_data.filter((pl.col('date_id') == date_id_v) & (pl.col('time_id') == time_id_v))\n",
    "\n",
    "            print(time_id_df.shape)\n",
    "            display(time_id_df)\n",
    "\n",
    "            time_id_X_train = time_id_df.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "            time_id_y_train = time_id_df['responder_6'].to_pandas()\n",
    "            time_id_weights_train = time_id_df['weight'].to_pandas()\n",
    "\n",
    "            val_data_df = train_data.filter(pl.col('date_id') >= date_id_v)[time_id_df.shape[0]:]\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return\n",
    "    \n",
    "    '''weights = train_data['weight']\n",
    "    y = train_data['responder_6']\n",
    "    \n",
    "    unique_date_ids = train_data['date_id'].unique()\n",
    "    train_date_id_cut = int(unique_date_ids.max() - 10)\n",
    "\n",
    "    print('max date:', unique_date_ids.max())\n",
    "    print('date id cut:', train_date_id_cut)\n",
    "    \n",
    "    X_train = train_data.filter(pl.col('date_id') <= train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "    X_val = train_data.filter(pl.col('date_id') > train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "\n",
    "    print(X_train.shape[0] / train_data.shape[0])\n",
    "    \n",
    "    y_train = y[:X_train.shape[0]].to_pandas()\n",
    "    y_val = y[X_train.shape[0]:].to_pandas()\n",
    "    \n",
    "    weights_train = weights[:X_train.shape[0]].to_pandas()\n",
    "    weights_val = weights[X_train.shape[0]:].to_pandas()\n",
    "\n",
    "    print(X_train.shape)\n",
    "    display(X_train.head())\n",
    "\n",
    "    base_params = {\n",
    "        'verbosity': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'device': 'gpu',\n",
    "        'early_stopping_round': 30,\n",
    "        'lambda_l2': 100\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=100000\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=50)])#, categorical_feature=['symbol_id'])\n",
    "\n",
    "    best_iteration = model.best_iteration_\n",
    "    print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "\n",
    "    plt.figure()\n",
    "    lgb.plot_metric(model)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()    \n",
    "\n",
    "    if not os.path.exists(models_path):\n",
    "        os.makedirs(models_path)\n",
    "\n",
    "    with open(models_path + \"lgb_model.pkl\", 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "    sample_val = X_val.sample(frac=0.001)\n",
    "    sample_y = y_val.loc[sample_val.index]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X=sample_val, y=sample_y)\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "    del X_train, y_train, X_val, y_val, weights_train, weights_val\n",
    "    gc.collect()\n",
    "\n",
    "    # Retraining on the full dataset using best_iteration\n",
    "    X_full = train_data.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "    y_full = y.to_pandas()\n",
    "    weights_full = weights.to_pandas()\n",
    "\n",
    "    base_params.pop('early_stopping_round')\n",
    "\n",
    "    model_full = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=best_iteration\n",
    "    )\n",
    "    \n",
    "    model_full.fit(X_full, y_full, sample_weight=weights_full)\n",
    "\n",
    "    with open(models_path + \"lgb_model_full.pkl\", 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    print(\"Retraining complete. Model saved as 'lgb_model_full.pkl'.\")\n",
    "\n",
    "    return shap_importance'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f11640b-066f-4b04-9b5d-344b1c861b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max date: 1698\n",
      "date id cut: 1300\n",
      "0.6895364639521969\n",
      "(32496018, 88)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>feature_07</th>\n",
       "      <th>feature_08</th>\n",
       "      <th>feature_09</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>feature_51</th>\n",
       "      <th>feature_52</th>\n",
       "      <th>feature_53</th>\n",
       "      <th>feature_54</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>feature_63</th>\n",
       "      <th>feature_64</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_0_lag_1</th>\n",
       "      <th>responder_1_lag_1</th>\n",
       "      <th>responder_2_lag_1</th>\n",
       "      <th>responder_3_lag_1</th>\n",
       "      <th>responder_4_lag_1</th>\n",
       "      <th>responder_5_lag_1</th>\n",
       "      <th>responder_6_lag_1</th>\n",
       "      <th>responder_7_lag_1</th>\n",
       "      <th>responder_8_lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851033</td>\n",
       "      <td>0.242971</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>-0.891687</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.883028</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>-0.744703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.169586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.335938</td>\n",
       "      <td>-1.707803</td>\n",
       "      <td>0.910130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.636431</td>\n",
       "      <td>1.522133</td>\n",
       "      <td>-1.551398</td>\n",
       "      <td>-0.229627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.378301</td>\n",
       "      <td>-0.283712</td>\n",
       "      <td>0.123196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281180</td>\n",
       "      <td>0.269163</td>\n",
       "      <td>0.349028</td>\n",
       "      <td>-0.012596</td>\n",
       "      <td>-0.225932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.073602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.181716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564021</td>\n",
       "      <td>2.088506</td>\n",
       "      <td>0.832022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.808103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.037683</td>\n",
       "      <td>0.727661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.989118</td>\n",
       "      <td>-0.345213</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.251104</td>\n",
       "      <td>-0.110252</td>\n",
       "      <td>-0.491157</td>\n",
       "      <td>-1.022690</td>\n",
       "      <td>0.152241</td>\n",
       "      <td>-0.659864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.261412</td>\n",
       "      <td>-0.211486</td>\n",
       "      <td>-0.335556</td>\n",
       "      <td>-0.281498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676961</td>\n",
       "      <td>0.151984</td>\n",
       "      <td>0.192465</td>\n",
       "      <td>-0.521729</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.865307</td>\n",
       "      <td>-0.225629</td>\n",
       "      <td>-0.582163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.250016</td>\n",
       "      <td>-1.682929</td>\n",
       "      <td>1.412757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520378</td>\n",
       "      <td>0.744132</td>\n",
       "      <td>-0.788658</td>\n",
       "      <td>0.641776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227200</td>\n",
       "      <td>0.580907</td>\n",
       "      <td>1.128879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.512286</td>\n",
       "      <td>-1.414357</td>\n",
       "      <td>-1.823322</td>\n",
       "      <td>-0.082763</td>\n",
       "      <td>-0.184119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.835207</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.621836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.172836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.625862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.410017</td>\n",
       "      <td>1.063013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888355</td>\n",
       "      <td>0.467994</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.065759</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.592855</td>\n",
       "      <td>-1.052685</td>\n",
       "      <td>-0.393726</td>\n",
       "      <td>-0.741603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.281207</td>\n",
       "      <td>-0.182894</td>\n",
       "      <td>-0.245565</td>\n",
       "      <td>-0.302441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056285</td>\n",
       "      <td>0.187227</td>\n",
       "      <td>0.249901</td>\n",
       "      <td>-0.773050</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.675719</td>\n",
       "      <td>-0.199404</td>\n",
       "      <td>-0.586798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.814909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.296782</td>\n",
       "      <td>-2.040234</td>\n",
       "      <td>0.639589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.597359</td>\n",
       "      <td>0.657514</td>\n",
       "      <td>-1.350148</td>\n",
       "      <td>0.364215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017751</td>\n",
       "      <td>-0.317361</td>\n",
       "      <td>-0.122379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.320921</td>\n",
       "      <td>-0.958090</td>\n",
       "      <td>-2.436589</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>-0.245239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.420632</td>\n",
       "      <td>-3.515137</td>\n",
       "      <td>-4.677760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.725420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.294170</td>\n",
       "      <td>1.764551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.120789</td>\n",
       "      <td>-0.063458</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.882604</td>\n",
       "      <td>-0.072482</td>\n",
       "      <td>-0.617934</td>\n",
       "      <td>-0.863230</td>\n",
       "      <td>-0.241892</td>\n",
       "      <td>-0.709919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.300724</td>\n",
       "      <td>-0.106842</td>\n",
       "      <td>-0.096792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.139366</td>\n",
       "      <td>0.273328</td>\n",
       "      <td>0.306549</td>\n",
       "      <td>-1.262223</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.694008</td>\n",
       "      <td>3.004091</td>\n",
       "      <td>0.114809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.251882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.902009</td>\n",
       "      <td>-0.979447</td>\n",
       "      <td>0.241165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.392359</td>\n",
       "      <td>-0.224699</td>\n",
       "      <td>-2.129397</td>\n",
       "      <td>-0.855287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404142</td>\n",
       "      <td>-0.578156</td>\n",
       "      <td>0.105702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544138</td>\n",
       "      <td>-0.087091</td>\n",
       "      <td>-1.500147</td>\n",
       "      <td>-0.201288</td>\n",
       "      <td>-0.038042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382074</td>\n",
       "      <td>2.669135</td>\n",
       "      <td>0.611711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.413415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.313203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.810125</td>\n",
       "      <td>2.939022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.988801</td>\n",
       "      <td>1.834661</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.697595</td>\n",
       "      <td>1.074309</td>\n",
       "      <td>-0.206929</td>\n",
       "      <td>-0.530602</td>\n",
       "      <td>4.765215</td>\n",
       "      <td>0.571554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.226891</td>\n",
       "      <td>-0.251412</td>\n",
       "      <td>-0.215522</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>0.262404</td>\n",
       "      <td>0.344457</td>\n",
       "      <td>-0.613813</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.947351</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>-0.502379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.844685</td>\n",
       "      <td>-1.586560</td>\n",
       "      <td>-0.182024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.969949</td>\n",
       "      <td>-0.673813</td>\n",
       "      <td>-1.282132</td>\n",
       "      <td>-1.399894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043815</td>\n",
       "      <td>-0.320225</td>\n",
       "      <td>-0.031713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.088420</td>\n",
       "      <td>-0.995003</td>\n",
       "      <td>-2.635336</td>\n",
       "      <td>-0.196461</td>\n",
       "      <td>-0.618719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.014600</td>\n",
       "      <td>-2.321076</td>\n",
       "      <td>-3.711265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.253902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.771732</td>\n",
       "      <td>2.843421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.379815</td>\n",
       "      <td>0.411827</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.948601</td>\n",
       "      <td>-0.136814</td>\n",
       "      <td>-0.447704</td>\n",
       "      <td>-1.141761</td>\n",
       "      <td>0.099631</td>\n",
       "      <td>-0.661928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.678076</td>\n",
       "      <td>2.793581</td>\n",
       "      <td>2.618250</td>\n",
       "      <td>3.418133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_00  feature_01  feature_02  feature_03  feature_04  feature_05  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN    0.851033   \n",
       "1         NaN         NaN         NaN         NaN         NaN    0.676961   \n",
       "2         NaN         NaN         NaN         NaN         NaN    1.056285   \n",
       "3         NaN         NaN         NaN         NaN         NaN    1.139366   \n",
       "4         NaN         NaN         NaN         NaN         NaN    0.955200   \n",
       "\n",
       "   feature_06  feature_07  feature_08  feature_09  feature_10  feature_11  \\\n",
       "0    0.242971    0.263400   -0.891687          11           7          76   \n",
       "1    0.151984    0.192465   -0.521729          11           7          76   \n",
       "2    0.187227    0.249901   -0.773050          11           7          76   \n",
       "3    0.273328    0.306549   -1.262223          42           5         150   \n",
       "4    0.262404    0.344457   -0.613813          44           3          16   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  feature_16  feature_17  \\\n",
       "0   -0.883028    0.003067   -0.744703         NaN   -0.169586         NaN   \n",
       "1   -0.865307   -0.225629   -0.582163         NaN    0.317467         NaN   \n",
       "2   -0.675719   -0.199404   -0.586798         NaN   -0.814909         NaN   \n",
       "3   -0.694008    3.004091    0.114809         NaN   -0.251882         NaN   \n",
       "4   -0.947351   -0.030018   -0.502379         NaN    0.646086         NaN   \n",
       "\n",
       "   feature_18  feature_19  feature_20  feature_21  feature_22  feature_23  \\\n",
       "0   -1.335938   -1.707803    0.910130         NaN    1.636431    1.522133   \n",
       "1   -1.250016   -1.682929    1.412757         NaN    0.520378    0.744132   \n",
       "2   -1.296782   -2.040234    0.639589         NaN    1.597359    0.657514   \n",
       "3   -1.902009   -0.979447    0.241165         NaN   -0.392359   -0.224699   \n",
       "4   -1.844685   -1.586560   -0.182024         NaN   -0.969949   -0.673813   \n",
       "\n",
       "   feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "0   -1.551398   -0.229627         NaN         NaN    1.378301   -0.283712   \n",
       "1   -0.788658    0.641776         NaN         NaN    0.227200    0.580907   \n",
       "2   -1.350148    0.364215         NaN         NaN   -0.017751   -0.317361   \n",
       "3   -2.129397   -0.855287         NaN         NaN    0.404142   -0.578156   \n",
       "4   -1.282132   -1.399894         NaN         NaN    0.043815   -0.320225   \n",
       "\n",
       "   feature_30  feature_31  feature_32  feature_33  feature_34  feature_35  \\\n",
       "0    0.123196         NaN         NaN         NaN    0.281180    0.269163   \n",
       "1    1.128879         NaN         NaN         NaN   -1.512286   -1.414357   \n",
       "2   -0.122379         NaN         NaN         NaN   -0.320921   -0.958090   \n",
       "3    0.105702         NaN         NaN         NaN    0.544138   -0.087091   \n",
       "4   -0.031713         NaN         NaN         NaN   -0.088420   -0.995003   \n",
       "\n",
       "   feature_36  feature_37  feature_38  feature_39  feature_40  feature_41  \\\n",
       "0    0.349028   -0.012596   -0.225932         NaN   -1.073602         NaN   \n",
       "1   -1.823322   -0.082763   -0.184119         NaN         NaN         NaN   \n",
       "2   -2.436589    0.070999   -0.245239         NaN         NaN         NaN   \n",
       "3   -1.500147   -0.201288   -0.038042         NaN         NaN         NaN   \n",
       "4   -2.635336   -0.196461   -0.618719         NaN         NaN         NaN   \n",
       "\n",
       "   feature_42  feature_43  feature_44  feature_45  feature_46  feature_47  \\\n",
       "0         NaN   -0.181716         NaN         NaN         NaN    0.564021   \n",
       "1         NaN         NaN         NaN         NaN         NaN  -10.835207   \n",
       "2         NaN         NaN         NaN         NaN         NaN   -1.420632   \n",
       "3         NaN         NaN         NaN         NaN         NaN    0.382074   \n",
       "4         NaN         NaN         NaN         NaN         NaN   -2.014600   \n",
       "\n",
       "   feature_48  feature_49  feature_50  feature_51  feature_52  feature_53  \\\n",
       "0    2.088506    0.832022         NaN    0.204797         NaN         NaN   \n",
       "1   -0.002704   -0.621836         NaN    1.172836         NaN         NaN   \n",
       "2   -3.515137   -4.677760         NaN    0.535897         NaN         NaN   \n",
       "3    2.669135    0.611711         NaN    2.413415         NaN         NaN   \n",
       "4   -2.321076   -3.711265         NaN    1.253902         NaN         NaN   \n",
       "\n",
       "   feature_54  feature_55  feature_56  feature_57  feature_58  feature_59  \\\n",
       "0   -0.808103         NaN   -2.037683    0.727661         NaN   -0.989118   \n",
       "1   -1.625862         NaN   -1.410017    1.063013         NaN    0.888355   \n",
       "2   -0.725420         NaN   -2.294170    1.764551         NaN   -0.120789   \n",
       "3    1.313203         NaN   -0.810125    2.939022         NaN    3.988801   \n",
       "4    0.476195         NaN   -0.771732    2.843421         NaN    1.379815   \n",
       "\n",
       "   feature_60  feature_61  feature_62  feature_63  feature_64  feature_65  \\\n",
       "0   -0.345213    -1.36224         NaN         NaN         NaN         NaN   \n",
       "1    0.467994    -1.36224         NaN         NaN         NaN         NaN   \n",
       "2   -0.063458    -1.36224         NaN         NaN         NaN         NaN   \n",
       "3    1.834661    -1.36224         NaN         NaN         NaN         NaN   \n",
       "4    0.411827    -1.36224         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   feature_66  feature_67  feature_68  feature_69  feature_70  feature_71  \\\n",
       "0         NaN   -1.251104   -0.110252   -0.491157   -1.022690    0.152241   \n",
       "1         NaN   -1.065759    0.013322   -0.592855   -1.052685   -0.393726   \n",
       "2         NaN   -0.882604   -0.072482   -0.617934   -0.863230   -0.241892   \n",
       "3         NaN   -0.697595    1.074309   -0.206929   -0.530602    4.765215   \n",
       "4         NaN   -0.948601   -0.136814   -0.447704   -1.141761    0.099631   \n",
       "\n",
       "   feature_72  feature_73  feature_74  feature_75  feature_76  feature_77  \\\n",
       "0   -0.659864         NaN         NaN   -0.261412   -0.211486   -0.335556   \n",
       "1   -0.741603         NaN         NaN   -0.281207   -0.182894   -0.245565   \n",
       "2   -0.709919         NaN         NaN    0.377131    0.300724   -0.106842   \n",
       "3    0.571554         NaN         NaN   -0.226891   -0.251412   -0.215522   \n",
       "4   -0.661928         NaN         NaN    3.678076    2.793581    2.618250   \n",
       "\n",
       "   feature_78  responder_0_lag_1  responder_1_lag_1  responder_2_lag_1  \\\n",
       "0   -0.281498                NaN                NaN                NaN   \n",
       "1   -0.302441                NaN                NaN                NaN   \n",
       "2   -0.096792                NaN                NaN                NaN   \n",
       "3   -0.296244                NaN                NaN                NaN   \n",
       "4    3.418133                NaN                NaN                NaN   \n",
       "\n",
       "   responder_3_lag_1  responder_4_lag_1  responder_5_lag_1  responder_6_lag_1  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   responder_7_lag_1  responder_8_lag_1  \n",
       "0                NaN                NaN  \n",
       "1                NaN                NaN  \n",
       "2                NaN                NaN  \n",
       "3                NaN                NaN  \n",
       "4                NaN                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>feature_07</th>\n",
       "      <th>feature_08</th>\n",
       "      <th>feature_09</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>feature_51</th>\n",
       "      <th>feature_52</th>\n",
       "      <th>feature_53</th>\n",
       "      <th>feature_54</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>feature_63</th>\n",
       "      <th>feature_64</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_0_lag_1</th>\n",
       "      <th>responder_1_lag_1</th>\n",
       "      <th>responder_2_lag_1</th>\n",
       "      <th>responder_3_lag_1</th>\n",
       "      <th>responder_4_lag_1</th>\n",
       "      <th>responder_5_lag_1</th>\n",
       "      <th>responder_6_lag_1</th>\n",
       "      <th>responder_7_lag_1</th>\n",
       "      <th>responder_8_lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32496013</th>\n",
       "      <td>-0.273723</td>\n",
       "      <td>-0.628400</td>\n",
       "      <td>0.021183</td>\n",
       "      <td>0.326928</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.267356</td>\n",
       "      <td>0.739021</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.886931</td>\n",
       "      <td>0.800840</td>\n",
       "      <td>0.619701</td>\n",
       "      <td>-0.944317</td>\n",
       "      <td>-0.731467</td>\n",
       "      <td>-0.826058</td>\n",
       "      <td>1.270973</td>\n",
       "      <td>2.309707</td>\n",
       "      <td>-0.168244</td>\n",
       "      <td>-0.180836</td>\n",
       "      <td>-0.228961</td>\n",
       "      <td>-0.731446</td>\n",
       "      <td>0.499912</td>\n",
       "      <td>-0.058762</td>\n",
       "      <td>-1.233727</td>\n",
       "      <td>0.421452</td>\n",
       "      <td>1.658583</td>\n",
       "      <td>-0.643178</td>\n",
       "      <td>-0.641713</td>\n",
       "      <td>-0.127338</td>\n",
       "      <td>1.012934</td>\n",
       "      <td>-0.808432</td>\n",
       "      <td>0.640629</td>\n",
       "      <td>0.046857</td>\n",
       "      <td>-0.553982</td>\n",
       "      <td>-0.097041</td>\n",
       "      <td>-0.199727</td>\n",
       "      <td>-0.778504</td>\n",
       "      <td>0.546700</td>\n",
       "      <td>0.259686</td>\n",
       "      <td>-0.897121</td>\n",
       "      <td>-0.245391</td>\n",
       "      <td>-0.181529</td>\n",
       "      <td>-0.041429</td>\n",
       "      <td>-0.114340</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>-0.162039</td>\n",
       "      <td>-0.156312</td>\n",
       "      <td>-0.445739</td>\n",
       "      <td>-0.194293</td>\n",
       "      <td>-0.992565</td>\n",
       "      <td>0.026359</td>\n",
       "      <td>0.776747</td>\n",
       "      <td>0.515383</td>\n",
       "      <td>-0.310368</td>\n",
       "      <td>0.715174</td>\n",
       "      <td>0.382011</td>\n",
       "      <td>-0.057844</td>\n",
       "      <td>-0.040984</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.526368</td>\n",
       "      <td>-0.235048</td>\n",
       "      <td>-0.354705</td>\n",
       "      <td>1.505933</td>\n",
       "      <td>1.735560</td>\n",
       "      <td>0.519725</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>1.266712</td>\n",
       "      <td>1.023329</td>\n",
       "      <td>1.049752</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-0.234894</td>\n",
       "      <td>-0.328479</td>\n",
       "      <td>-0.167722</td>\n",
       "      <td>-0.107061</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.299852</td>\n",
       "      <td>0.113701</td>\n",
       "      <td>0.191003</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>-0.233323</td>\n",
       "      <td>-0.171773</td>\n",
       "      <td>-0.042368</td>\n",
       "      <td>-0.313162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496014</th>\n",
       "      <td>0.516346</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>0.170515</td>\n",
       "      <td>0.457404</td>\n",
       "      <td>0.704279</td>\n",
       "      <td>-0.016830</td>\n",
       "      <td>0.200757</td>\n",
       "      <td>0.196041</td>\n",
       "      <td>1.106106</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>0.569555</td>\n",
       "      <td>0.320779</td>\n",
       "      <td>0.445927</td>\n",
       "      <td>0.833764</td>\n",
       "      <td>0.766083</td>\n",
       "      <td>0.760303</td>\n",
       "      <td>2.978000</td>\n",
       "      <td>0.180232</td>\n",
       "      <td>-0.071296</td>\n",
       "      <td>0.833885</td>\n",
       "      <td>-0.442648</td>\n",
       "      <td>1.909253</td>\n",
       "      <td>1.260226</td>\n",
       "      <td>2.173384</td>\n",
       "      <td>0.124759</td>\n",
       "      <td>-1.742508</td>\n",
       "      <td>-2.060564</td>\n",
       "      <td>2.431904</td>\n",
       "      <td>0.894903</td>\n",
       "      <td>1.336326</td>\n",
       "      <td>0.233143</td>\n",
       "      <td>0.268164</td>\n",
       "      <td>0.180035</td>\n",
       "      <td>-0.047150</td>\n",
       "      <td>-0.035961</td>\n",
       "      <td>1.073607</td>\n",
       "      <td>0.868699</td>\n",
       "      <td>1.179430</td>\n",
       "      <td>0.910744</td>\n",
       "      <td>0.365738</td>\n",
       "      <td>-0.806121</td>\n",
       "      <td>-1.221758</td>\n",
       "      <td>-0.294194</td>\n",
       "      <td>-0.309661</td>\n",
       "      <td>-1.669550</td>\n",
       "      <td>-1.185478</td>\n",
       "      <td>-0.013506</td>\n",
       "      <td>-0.296199</td>\n",
       "      <td>0.629851</td>\n",
       "      <td>1.619304</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>-1.331440</td>\n",
       "      <td>-1.206886</td>\n",
       "      <td>-0.506745</td>\n",
       "      <td>-0.665731</td>\n",
       "      <td>-1.265526</td>\n",
       "      <td>-1.339285</td>\n",
       "      <td>0.179611</td>\n",
       "      <td>-0.155559</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.099937</td>\n",
       "      <td>0.127875</td>\n",
       "      <td>-0.027559</td>\n",
       "      <td>2.582265</td>\n",
       "      <td>-0.386582</td>\n",
       "      <td>1.081167</td>\n",
       "      <td>-0.309833</td>\n",
       "      <td>0.429599</td>\n",
       "      <td>0.702698</td>\n",
       "      <td>0.696585</td>\n",
       "      <td>0.391108</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.507126</td>\n",
       "      <td>-0.303390</td>\n",
       "      <td>-0.442164</td>\n",
       "      <td>-0.255057</td>\n",
       "      <td>-0.366450</td>\n",
       "      <td>-0.150453</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>-2.491776</td>\n",
       "      <td>0.146255</td>\n",
       "      <td>0.055375</td>\n",
       "      <td>-0.119033</td>\n",
       "      <td>0.025655</td>\n",
       "      <td>0.050160</td>\n",
       "      <td>0.044680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496015</th>\n",
       "      <td>-0.276064</td>\n",
       "      <td>-0.562562</td>\n",
       "      <td>0.126326</td>\n",
       "      <td>0.341234</td>\n",
       "      <td>0.648612</td>\n",
       "      <td>-0.010778</td>\n",
       "      <td>0.217542</td>\n",
       "      <td>0.150108</td>\n",
       "      <td>0.763144</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>388</td>\n",
       "      <td>-0.154750</td>\n",
       "      <td>0.241596</td>\n",
       "      <td>-0.084922</td>\n",
       "      <td>-0.210215</td>\n",
       "      <td>-0.473479</td>\n",
       "      <td>-0.281191</td>\n",
       "      <td>0.932661</td>\n",
       "      <td>-1.085921</td>\n",
       "      <td>-0.415765</td>\n",
       "      <td>0.663795</td>\n",
       "      <td>-0.465737</td>\n",
       "      <td>1.354075</td>\n",
       "      <td>2.110133</td>\n",
       "      <td>2.677571</td>\n",
       "      <td>-0.370774</td>\n",
       "      <td>-2.367140</td>\n",
       "      <td>-1.442387</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>-0.131176</td>\n",
       "      <td>0.483004</td>\n",
       "      <td>0.787535</td>\n",
       "      <td>-0.551896</td>\n",
       "      <td>0.947080</td>\n",
       "      <td>0.807590</td>\n",
       "      <td>-0.549592</td>\n",
       "      <td>0.100099</td>\n",
       "      <td>0.098323</td>\n",
       "      <td>0.180247</td>\n",
       "      <td>1.340250</td>\n",
       "      <td>-0.481007</td>\n",
       "      <td>1.146693</td>\n",
       "      <td>-0.012450</td>\n",
       "      <td>0.033310</td>\n",
       "      <td>-0.014503</td>\n",
       "      <td>0.447920</td>\n",
       "      <td>0.086581</td>\n",
       "      <td>-0.195873</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.530240</td>\n",
       "      <td>-0.618310</td>\n",
       "      <td>-0.746920</td>\n",
       "      <td>0.534145</td>\n",
       "      <td>-0.556152</td>\n",
       "      <td>0.391937</td>\n",
       "      <td>0.606587</td>\n",
       "      <td>1.020363</td>\n",
       "      <td>0.241115</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.080730</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.368261</td>\n",
       "      <td>-0.287799</td>\n",
       "      <td>-0.280969</td>\n",
       "      <td>0.449343</td>\n",
       "      <td>1.240352</td>\n",
       "      <td>-0.351033</td>\n",
       "      <td>0.879358</td>\n",
       "      <td>-0.191713</td>\n",
       "      <td>-0.081830</td>\n",
       "      <td>-0.143664</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>-0.265242</td>\n",
       "      <td>-0.402117</td>\n",
       "      <td>-0.290549</td>\n",
       "      <td>-0.336317</td>\n",
       "      <td>-0.207405</td>\n",
       "      <td>-0.323209</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.286257</td>\n",
       "      <td>1.291592</td>\n",
       "      <td>0.117581</td>\n",
       "      <td>0.050176</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>0.032325</td>\n",
       "      <td>-0.019257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496016</th>\n",
       "      <td>0.048198</td>\n",
       "      <td>-0.705530</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>0.377266</td>\n",
       "      <td>-0.100474</td>\n",
       "      <td>-0.014540</td>\n",
       "      <td>0.407335</td>\n",
       "      <td>0.410498</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>0.412368</td>\n",
       "      <td>1.015218</td>\n",
       "      <td>0.308765</td>\n",
       "      <td>-0.950215</td>\n",
       "      <td>-0.248845</td>\n",
       "      <td>-0.995436</td>\n",
       "      <td>0.486453</td>\n",
       "      <td>1.312123</td>\n",
       "      <td>-1.498882</td>\n",
       "      <td>-0.192676</td>\n",
       "      <td>-0.928796</td>\n",
       "      <td>-1.160311</td>\n",
       "      <td>0.198818</td>\n",
       "      <td>-0.378694</td>\n",
       "      <td>0.325012</td>\n",
       "      <td>-1.749679</td>\n",
       "      <td>-1.901364</td>\n",
       "      <td>-0.891058</td>\n",
       "      <td>-0.919408</td>\n",
       "      <td>-0.148865</td>\n",
       "      <td>-0.459053</td>\n",
       "      <td>-0.338284</td>\n",
       "      <td>0.518999</td>\n",
       "      <td>0.109611</td>\n",
       "      <td>-1.465696</td>\n",
       "      <td>-0.033068</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.565646</td>\n",
       "      <td>-0.376636</td>\n",
       "      <td>-0.389352</td>\n",
       "      <td>0.796484</td>\n",
       "      <td>0.069480</td>\n",
       "      <td>0.411968</td>\n",
       "      <td>0.808051</td>\n",
       "      <td>0.978345</td>\n",
       "      <td>0.280803</td>\n",
       "      <td>0.242483</td>\n",
       "      <td>0.710215</td>\n",
       "      <td>1.463319</td>\n",
       "      <td>-0.488809</td>\n",
       "      <td>0.659116</td>\n",
       "      <td>2.040899</td>\n",
       "      <td>0.413254</td>\n",
       "      <td>1.128831</td>\n",
       "      <td>0.767357</td>\n",
       "      <td>1.831824</td>\n",
       "      <td>0.678784</td>\n",
       "      <td>0.461269</td>\n",
       "      <td>0.819580</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.427502</td>\n",
       "      <td>-0.318685</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.073792</td>\n",
       "      <td>1.567347</td>\n",
       "      <td>0.145724</td>\n",
       "      <td>0.456878</td>\n",
       "      <td>-0.023279</td>\n",
       "      <td>0.530322</td>\n",
       "      <td>1.483768</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>-0.563597</td>\n",
       "      <td>-0.828064</td>\n",
       "      <td>-0.598701</td>\n",
       "      <td>-0.625653</td>\n",
       "      <td>-0.810607</td>\n",
       "      <td>-0.975171</td>\n",
       "      <td>-0.226147</td>\n",
       "      <td>-0.275249</td>\n",
       "      <td>-0.060692</td>\n",
       "      <td>0.117830</td>\n",
       "      <td>0.084099</td>\n",
       "      <td>0.020054</td>\n",
       "      <td>0.030628</td>\n",
       "      <td>0.043376</td>\n",
       "      <td>0.028681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496017</th>\n",
       "      <td>0.726119</td>\n",
       "      <td>-0.738978</td>\n",
       "      <td>-0.543837</td>\n",
       "      <td>-0.127495</td>\n",
       "      <td>0.738317</td>\n",
       "      <td>-0.016428</td>\n",
       "      <td>0.349479</td>\n",
       "      <td>0.261747</td>\n",
       "      <td>1.239655</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>-0.284493</td>\n",
       "      <td>-0.111495</td>\n",
       "      <td>-0.307370</td>\n",
       "      <td>-0.666224</td>\n",
       "      <td>-0.526006</td>\n",
       "      <td>-0.703370</td>\n",
       "      <td>1.702379</td>\n",
       "      <td>-0.828881</td>\n",
       "      <td>-0.261229</td>\n",
       "      <td>-0.142134</td>\n",
       "      <td>1.071015</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.441871</td>\n",
       "      <td>-0.060235</td>\n",
       "      <td>-0.406465</td>\n",
       "      <td>1.331972</td>\n",
       "      <td>1.533296</td>\n",
       "      <td>-0.759594</td>\n",
       "      <td>-0.765753</td>\n",
       "      <td>-0.111876</td>\n",
       "      <td>0.225191</td>\n",
       "      <td>-0.501364</td>\n",
       "      <td>0.095531</td>\n",
       "      <td>0.541944</td>\n",
       "      <td>-0.419761</td>\n",
       "      <td>1.187102</td>\n",
       "      <td>0.986660</td>\n",
       "      <td>-0.395733</td>\n",
       "      <td>0.387021</td>\n",
       "      <td>0.534711</td>\n",
       "      <td>0.483614</td>\n",
       "      <td>-0.260048</td>\n",
       "      <td>0.127165</td>\n",
       "      <td>-0.377836</td>\n",
       "      <td>-0.915420</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.049700</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>-0.492871</td>\n",
       "      <td>-0.406338</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>0.749103</td>\n",
       "      <td>-0.521930</td>\n",
       "      <td>0.799627</td>\n",
       "      <td>-0.034946</td>\n",
       "      <td>-1.414886</td>\n",
       "      <td>0.073785</td>\n",
       "      <td>-0.142013</td>\n",
       "      <td>0.054707</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.452743</td>\n",
       "      <td>-0.292108</td>\n",
       "      <td>-0.404927</td>\n",
       "      <td>1.215832</td>\n",
       "      <td>-0.188363</td>\n",
       "      <td>-0.254359</td>\n",
       "      <td>-0.146385</td>\n",
       "      <td>-0.454595</td>\n",
       "      <td>-0.273597</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.223208</td>\n",
       "      <td>-0.366105</td>\n",
       "      <td>-0.271781</td>\n",
       "      <td>-0.175845</td>\n",
       "      <td>-0.219294</td>\n",
       "      <td>-0.326256</td>\n",
       "      <td>-0.485207</td>\n",
       "      <td>0.461096</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>-0.010951</td>\n",
       "      <td>-0.541191</td>\n",
       "      <td>-0.296320</td>\n",
       "      <td>-0.021512</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.061172</td>\n",
       "      <td>0.136612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature_00  feature_01  feature_02  feature_03  feature_04  \\\n",
       "32496013   -0.273723   -0.628400    0.021183    0.326928    0.120378   \n",
       "32496014    0.516346   -0.358216    0.170515    0.457404    0.704279   \n",
       "32496015   -0.276064   -0.562562    0.126326    0.341234    0.648612   \n",
       "32496016    0.048198   -0.705530   -0.000436    0.377266   -0.100474   \n",
       "32496017    0.726119   -0.738978   -0.543837   -0.127495    0.738317   \n",
       "\n",
       "          feature_05  feature_06  feature_07  feature_08  feature_09  \\\n",
       "32496013   -0.017101    0.293846    0.267356    0.739021          42   \n",
       "32496014   -0.016830    0.200757    0.196041    1.106106          11   \n",
       "32496015   -0.010778    0.217542    0.150108    0.763144          68   \n",
       "32496016   -0.014540    0.407335    0.410498    0.778039          34   \n",
       "32496017   -0.016428    0.349479    0.261747    1.239655          50   \n",
       "\n",
       "          feature_10  feature_11  feature_12  feature_13  feature_14  \\\n",
       "32496013           5         150    0.886931    0.800840    0.619701   \n",
       "32496014           7          76    0.569555    0.320779    0.445927   \n",
       "32496015           6         388   -0.154750    0.241596   -0.084922   \n",
       "32496016           4         214    0.412368    1.015218    0.308765   \n",
       "32496017           1         522   -0.284493   -0.111495   -0.307370   \n",
       "\n",
       "          feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
       "32496013   -0.944317   -0.731467   -0.826058    1.270973    2.309707   \n",
       "32496014    0.833764    0.766083    0.760303    2.978000    0.180232   \n",
       "32496015   -0.210215   -0.473479   -0.281191    0.932661   -1.085921   \n",
       "32496016   -0.950215   -0.248845   -0.995436    0.486453    1.312123   \n",
       "32496017   -0.666224   -0.526006   -0.703370    1.702379   -0.828881   \n",
       "\n",
       "          feature_20  feature_21  feature_22  feature_23  feature_24  \\\n",
       "32496013   -0.168244   -0.180836   -0.228961   -0.731446    0.499912   \n",
       "32496014   -0.071296    0.833885   -0.442648    1.909253    1.260226   \n",
       "32496015   -0.415765    0.663795   -0.465737    1.354075    2.110133   \n",
       "32496016   -1.498882   -0.192676   -0.928796   -1.160311    0.198818   \n",
       "32496017   -0.261229   -0.142134    1.071015    0.095017    0.441871   \n",
       "\n",
       "          feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "32496013   -0.058762   -1.233727    0.421452    1.658583   -0.643178   \n",
       "32496014    2.173384    0.124759   -1.742508   -2.060564    2.431904   \n",
       "32496015    2.677571   -0.370774   -2.367140   -1.442387    0.450709   \n",
       "32496016   -0.378694    0.325012   -1.749679   -1.901364   -0.891058   \n",
       "32496017   -0.060235   -0.406465    1.331972    1.533296   -0.759594   \n",
       "\n",
       "          feature_30  feature_31  feature_32  feature_33  feature_34  \\\n",
       "32496013   -0.641713   -0.127338    1.012934   -0.808432    0.640629   \n",
       "32496014    0.894903    1.336326    0.233143    0.268164    0.180035   \n",
       "32496015   -0.131176    0.483004    0.787535   -0.551896    0.947080   \n",
       "32496016   -0.919408   -0.148865   -0.459053   -0.338284    0.518999   \n",
       "32496017   -0.765753   -0.111876    0.225191   -0.501364    0.095531   \n",
       "\n",
       "          feature_35  feature_36  feature_37  feature_38  feature_39  \\\n",
       "32496013    0.046857   -0.553982   -0.097041   -0.199727   -0.778504   \n",
       "32496014   -0.047150   -0.035961    1.073607    0.868699    1.179430   \n",
       "32496015    0.807590   -0.549592    0.100099    0.098323    0.180247   \n",
       "32496016    0.109611   -1.465696   -0.033068    0.006976    0.565646   \n",
       "32496017    0.541944   -0.419761    1.187102    0.986660   -0.395733   \n",
       "\n",
       "          feature_40  feature_41  feature_42  feature_43  feature_44  \\\n",
       "32496013    0.546700    0.259686   -0.897121   -0.245391   -0.181529   \n",
       "32496014    0.910744    0.365738   -0.806121   -1.221758   -0.294194   \n",
       "32496015    1.340250   -0.481007    1.146693   -0.012450    0.033310   \n",
       "32496016   -0.376636   -0.389352    0.796484    0.069480    0.411968   \n",
       "32496017    0.387021    0.534711    0.483614   -0.260048    0.127165   \n",
       "\n",
       "          feature_45  feature_46  feature_47  feature_48  feature_49  \\\n",
       "32496013   -0.041429   -0.114340    0.074312   -0.162039   -0.156312   \n",
       "32496014   -0.309661   -1.669550   -1.185478   -0.013506   -0.296199   \n",
       "32496015   -0.014503    0.447920    0.086581   -0.195873    0.004835   \n",
       "32496016    0.808051    0.978345    0.280803    0.242483    0.710215   \n",
       "32496017   -0.377836   -0.915420   -0.005872   -0.049700    0.013723   \n",
       "\n",
       "          feature_50  feature_51  feature_52  feature_53  feature_54  \\\n",
       "32496013   -0.445739   -0.194293   -0.992565    0.026359    0.776747   \n",
       "32496014    0.629851    1.619304    0.130224   -1.331440   -1.206886   \n",
       "32496015    0.530240   -0.618310   -0.746920    0.534145   -0.556152   \n",
       "32496016    1.463319   -0.488809    0.659116    2.040899    0.413254   \n",
       "32496017   -0.492871   -0.406338   -0.043089    0.749103   -0.521930   \n",
       "\n",
       "          feature_55  feature_56  feature_57  feature_58  feature_59  \\\n",
       "32496013    0.515383   -0.310368    0.715174    0.382011   -0.057844   \n",
       "32496014   -0.506745   -0.665731   -1.265526   -1.339285    0.179611   \n",
       "32496015    0.391937    0.606587    1.020363    0.241115   -0.063700   \n",
       "32496016    1.128831    0.767357    1.831824    0.678784    0.461269   \n",
       "32496017    0.799627   -0.034946   -1.414886    0.073785   -0.142013   \n",
       "\n",
       "          feature_60  feature_61  feature_62  feature_63  feature_64  \\\n",
       "32496013   -0.040984    0.796951   -0.526368   -0.235048   -0.354705   \n",
       "32496014   -0.155559    0.796951   -0.099937    0.127875   -0.027559   \n",
       "32496015    0.080730    0.796951   -0.368261   -0.287799   -0.280969   \n",
       "32496016    0.819580    0.796951   -0.427502   -0.318685   -0.264619   \n",
       "32496017    0.054707    0.796951   -0.452743   -0.292108   -0.404927   \n",
       "\n",
       "          feature_65  feature_66  feature_67  feature_68  feature_69  \\\n",
       "32496013    1.505933    1.735560    0.519725    0.034015    0.247436   \n",
       "32496014    2.582265   -0.386582    1.081167   -0.309833    0.429599   \n",
       "32496015    0.449343    1.240352   -0.351033    0.879358   -0.191713   \n",
       "32496016   -0.073792    1.567347    0.145724    0.456878   -0.023279   \n",
       "32496017    1.215832   -0.188363   -0.254359   -0.146385   -0.454595   \n",
       "\n",
       "          feature_70  feature_71  feature_72  feature_73  feature_74  \\\n",
       "32496013    1.266712    1.023329    1.049752   -0.020475    0.000255   \n",
       "32496014    0.702698    0.696585    0.391108   -0.312883   -0.507126   \n",
       "32496015   -0.081830   -0.143664    0.025583   -0.265242   -0.402117   \n",
       "32496016    0.530322    1.483768    0.636709   -0.563597   -0.828064   \n",
       "32496017   -0.273597    0.011529   -0.223208   -0.366105   -0.271781   \n",
       "\n",
       "          feature_75  feature_76  feature_77  feature_78  responder_0_lag_1  \\\n",
       "32496013   -0.234894   -0.328479   -0.167722   -0.107061           0.013119   \n",
       "32496014   -0.303390   -0.442164   -0.255057   -0.366450          -0.150453   \n",
       "32496015   -0.290549   -0.336317   -0.207405   -0.323209          -0.063781   \n",
       "32496016   -0.598701   -0.625653   -0.810607   -0.975171          -0.226147   \n",
       "32496017   -0.175845   -0.219294   -0.326256   -0.485207           0.461096   \n",
       "\n",
       "          responder_1_lag_1  responder_2_lag_1  responder_3_lag_1  \\\n",
       "32496013           0.299852           0.113701           0.191003   \n",
       "32496014           0.697600          -2.491776           0.146255   \n",
       "32496015           0.286257           1.291592           0.117581   \n",
       "32496016          -0.275249          -0.060692           0.117830   \n",
       "32496017           0.155033          -0.010951          -0.541191   \n",
       "\n",
       "          responder_4_lag_1  responder_5_lag_1  responder_6_lag_1  \\\n",
       "32496013           0.090730          -0.233323          -0.171773   \n",
       "32496014           0.055375          -0.119033           0.025655   \n",
       "32496015           0.050176          -0.013990          -0.005065   \n",
       "32496016           0.084099           0.020054           0.030628   \n",
       "32496017          -0.296320          -0.021512           0.045422   \n",
       "\n",
       "          responder_7_lag_1  responder_8_lag_1  \n",
       "32496013          -0.042368          -0.313162  \n",
       "32496014           0.050160           0.044680  \n",
       "32496015           0.032325          -0.019257  \n",
       "32496016           0.043376           0.028681  \n",
       "32496017           0.061172           0.136612  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's l2: 0.752714\tvalid_1's l2: 0.662428\n",
      "[20]\ttraining's l2: 0.750693\tvalid_1's l2: 0.661217\n",
      "[30]\ttraining's l2: 0.749317\tvalid_1's l2: 0.660341\n",
      "[40]\ttraining's l2: 0.748268\tvalid_1's l2: 0.659631\n",
      "[50]\ttraining's l2: 0.74732\tvalid_1's l2: 0.659018\n",
      "[60]\ttraining's l2: 0.746581\tvalid_1's l2: 0.658598\n",
      "[70]\ttraining's l2: 0.745827\tvalid_1's l2: 0.658279\n",
      "[80]\ttraining's l2: 0.74517\tvalid_1's l2: 0.658067\n",
      "[90]\ttraining's l2: 0.744618\tvalid_1's l2: 0.65788\n",
      "[100]\ttraining's l2: 0.744009\tvalid_1's l2: 0.657718\n",
      "[110]\ttraining's l2: 0.743517\tvalid_1's l2: 0.657523\n",
      "[120]\ttraining's l2: 0.742888\tvalid_1's l2: 0.657477\n",
      "[130]\ttraining's l2: 0.742405\tvalid_1's l2: 0.657409\n",
      "[140]\ttraining's l2: 0.741977\tvalid_1's l2: 0.65734\n",
      "[150]\ttraining's l2: 0.741394\tvalid_1's l2: 0.657396\n",
      "[160]\ttraining's l2: 0.740866\tvalid_1's l2: 0.657404\n",
      "[170]\ttraining's l2: 0.740513\tvalid_1's l2: 0.657354\n",
      "Best iteration: 142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Weighted R2 score is: 0.010586328007138546\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb_online_learning(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5b42e-8908-4589-9756-d4fb977ef6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8d3dc-c225-4c0d-a41f-3da3b887045f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efbf23-81e0-4e6f-a346-3e01ee558f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746715e-6673-4ba1-953c-41d00f590a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb20dd-2150-426f-8739-2f63402dc7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4651e-f019-4e55-8ce4-b03aae6c1c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c8234-33e1-4891-9527-58d15c529e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47aa04-b2ad-48db-a1b4-1939520ab885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc310b8-2089-42ee-8c3b-80545060deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(models_path):\n",
    "    os.makedirs(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3859c-b79e-426f-9799-fffdb93d3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(models_path + \"lgb_model.pkl\", 'wb') as file:\n",
    "    pickle.dump(lgb_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6684c-98f8-447c-8b58-28f1d21aef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open(f\"{models_path}/lgb_model.pkl\", \"rb\") as f:\n",
    "    lgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df7914-ec21-4603-9388-57043c98ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = train_df.filter(pl.col('date_id') > 1300)\n",
    "print(val_df.shape)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1e705-b82e-45f8-b992-bdb9595408a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389887f7-ef29-40d3-9595-f4af0b63b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_online_learning(val_data, current_model, optuna_n_trials):\n",
    "    val_data = val_data.clone()\n",
    "    print('this is the initial validation data')\n",
    "    print(val_data.shape)\n",
    "    display(val_data.head())\n",
    "    display(val_data.tail())\n",
    "    i = 0\n",
    "    val_date_ids = sorted(val_data['date_id'].unique())\n",
    "    for date_id_v in val_date_ids:\n",
    "        date_id_df = val_data.filter(pl.col('date_id') == date_id_v)\n",
    "        print('this is date_id_df')\n",
    "        print(date_id_df.shape)\n",
    "        display(date_id_df.head())\n",
    "        display(date_id_df.tail())\n",
    "        \n",
    "        X_train = date_id_df.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "        y_train = date_id_df['responder_6'].to_pandas()\n",
    "        weights_train = date_id_df['weight'].to_pandas()\n",
    "\n",
    "        #train_dataset = lgb.Dataset(data=X_train, label=y_train, weight=weights_train)\n",
    "\n",
    "        val_data = val_data[date_id_df.shape[0]:]\n",
    "        print('this is updated validation data')\n",
    "        print(val_data.shape)\n",
    "        display(val_data.head())\n",
    "        display(val_data.tail())\n",
    "\n",
    "        X_val = val_data.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "        y_val = val_data['responder_6'].to_pandas()\n",
    "        weights_val = val_data['weight'].to_pandas()\n",
    "\n",
    "        #val_dataset = lgb.Dataset(data=X_val, label=y_val, weight=weights_val)\n",
    "\n",
    "        '''base_params = {\n",
    "            'verbosity': -1,\n",
    "            'learning_rate': 1,\n",
    "            #'feature_fraction': 0.8,\n",
    "            'device': 'gpu',\n",
    "            'early_stopping_round': 30,\n",
    "            #'lambda_l2': 100\n",
    "        }'''\n",
    "\n",
    "        '''updated_model = lgb.train(\n",
    "            params=base_params,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=[train_dataset, val_dataset],\n",
    "            num_boost_round=90,\n",
    "            init_model=current_model,\n",
    "            callbacks=[log_evaluation(period=50), record_evaluation()]\n",
    "        )'''\n",
    "    \n",
    "        '''online_model = LGBMRegressor(\n",
    "            **base_params,\n",
    "            n_estimators=100000\n",
    "        )'''\n",
    "\n",
    "        '''current_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "        #current_model.fit(X_val, y_val, sample_weight=weights_val, eval_set=[(X_val, y_val), (X_train, y_train)], eval_sample_weight=[weights_val, weights_train], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "        #display(online_model)\n",
    "\n",
    "        plt.figure()\n",
    "        lgb.plot_metric(current_model)\n",
    "        plt.ylim(0, 2)\n",
    "        plt.show()\n",
    "        \n",
    "        val_preds = current_model.predict(X_val)\n",
    "        \n",
    "        return current_model'''\n",
    "\n",
    "        base_params = {\n",
    "            'verbosity': -1,\n",
    "            #'learning_rate': 0.05,\n",
    "            #'feature_fraction': 0.8,\n",
    "            'device': 'gpu',\n",
    "            'early_stopping_round': 10,\n",
    "            #'lambda_l2': 100,\n",
    "            'seed': 42\n",
    "        }\n",
    "\n",
    "        def objective(trial):\n",
    "\n",
    "            params_to_tune = {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.03),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 300),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 4000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 2, 3),\n",
    "                'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 0.3),\n",
    "                'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "                'lambda_l2': trial.suggest_float('lambda_l2', 1000, 2000)\n",
    "            }\n",
    "\n",
    "            online_model = LGBMRegressor(\n",
    "                **base_params,\n",
    "                **params_to_tune,\n",
    "                n_estimators=100000\n",
    "            )\n",
    "\n",
    "            online_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], init_model=current_model)\n",
    "            #online_model.fit(X_val, y_val, sample_weight=weights_val, eval_set=[(X_val, y_val), (X_train, y_train)], eval_sample_weight=[weights_val, weights_train], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "            '''plt.figure()\n",
    "            lgb.plot_metric(online_model)\n",
    "            plt.ylim(0, 2)\n",
    "            plt.show()'''\n",
    "\n",
    "            #best_iteration = online_model.best_iteration_\n",
    "            #print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "            val_preds = online_model.predict(X_val)\n",
    "\n",
    "            val_r2_score = r2_score(y_val, val_preds, sample_weight=weights_val)\n",
    "\n",
    "            return val_r2_score\n",
    "\n",
    "        with tqdm(total=optuna_n_trials, desc=\"Optimizing\", unit=\"trial\") as pbar:\n",
    "    \n",
    "            # Define a callback function to update the progress bar\n",
    "            def progress_bar_callback(study, trial):\n",
    "                pbar.update(1)\n",
    "        \n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(objective, n_trials=optuna_n_trials, callbacks=[progress_bar_callback])\n",
    "\n",
    "        return study\n",
    "    \n",
    "        best_params = study.best_params\n",
    "\n",
    "        online_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "        display(online_model)\n",
    "\n",
    "        plt.figure()\n",
    "        lgb.plot_metric(online_model)\n",
    "        plt.ylim(0, 2)\n",
    "        plt.show()\n",
    "        \n",
    "        val_preds = online_model.predict(X_val)\n",
    "\n",
    "        print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "        return online_model\n",
    "\n",
    "        if i > 20:\n",
    "            return\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82f864-8066-48e1-9afb-184bc933850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study = val_online_learning(val_df, lgb_model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd780c53-9568-480d-bc02-b28fc79566d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in lgb_study.best_params.keys():\n",
    "    fig = plot_slice(lgb_study, params=[param])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae940b42-2237-4577-bbe4-5a3b08bec314",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(lgb_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157c449-2f9c-45ae-a31a-c7a2e4c7c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5b2e5-0bce-41c2-8fcc-dd6e22a00aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa6a0f-3cc5-45a6-a111-d7f054c262be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_df = pd.DataFrame({k:[lgb_study.best_params[k]] for k in lgb_study.best_params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e7532-c40e-4ea6-8e4d-f4a0d96650d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69b03b-80e1-45c0-b742-063d9e9ee361",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_df.to_csv(models_path + 'lgb_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b4c48-301e-4940-934e-b471272dd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params_dict(params_df):\n",
    "    params_dict = {}\n",
    "    for col in params_df.columns:\n",
    "        v = params_df[col][0]\n",
    "        if type(v) == np.int64:\n",
    "            v = int(v)\n",
    "        params_dict[col] = v\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e61b03-9287-4a98-bee1-0259004823b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_dict = create_params_dict(lgb_params_df)\n",
    "lgb_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd110dc-19db-4002-9675-c5206b3ba329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b6282-1d42-4d92-a501-529f7da27e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119ec0b-151f-4c3e-a44f-909c59d8b25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66242a14-9e00-4e9c-96a9-f7b2c09d3ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e0e9d-517b-4ee8-8998-438e28026201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f98a4-a2dc-475d-ac3e-14c62606e802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321b527-d9a1-4977-94bf-661d62e83be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5bfc2-0c8d-4dc5-9c1f-a02595836d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_df.drop(['date_id', 'time_id', 'symbol_id']).columns\n",
    "imp_df = pd.DataFrame(sorted(zip(cols, first_shap_importance)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459cef0-80a6-4b90-9918-332b449c380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506da0e-1120-4d22-99b8-31da7adc1a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7e244-dc03-4612-a335-bd7366f6a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 40))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(imp_df['Feature'], imp_df['Importance'])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c5ce2-6075-47e7-8bf5-98468f451b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_df = imp_df[imp_df['Importance'] <= imp_df['Importance'].quantile(0.3)]\n",
    "unimportant_cols = unimportant_df['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc98e4-b6c4-41a2-b1bf-e63e16828ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected_df = train_df.drop(unimportant_cols)\n",
    "print(train_selected_df.shape)\n",
    "train_selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8c121-661f-4c90-8e3b-c9aa62bf2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_shap_importance = lgb_train(train_selected_df, y_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c749891-7ec2-4ea7-b4a3-40691e436f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
