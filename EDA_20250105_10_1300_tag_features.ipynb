{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6e3e10-78d2-413c-87c3-f256294da062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor, log_evaluation, record_evaluation\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.impute import IterativeImputer\n",
    "import pickle\n",
    "import optuna\n",
    "from optuna.visualization import plot_slice, plot_param_importances\n",
    "import shap\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "pl.Config.set_fmt_str_lengths(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8421cc58-8b61-4b48-8c20-3544d3a81f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5a256f-c55b-415d-8d12-e753283ffee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'I:/Kaggle/jane-street-real-time-market-data-forecasting/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d215c3-e2a4-4ea2-8125-708737b10ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.csv',\n",
       " 'kaggle_evaluation',\n",
       " 'lags.parquet',\n",
       " 'my_folder',\n",
       " 'responders.csv',\n",
       " 'sample_submission.csv',\n",
       " 'team_folder',\n",
       " 'test.parquet',\n",
       " 'train.parquet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab47b6d-409b-41a7-a443-fcddc750f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47127338, 93)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_39</th><th>feature_40</th><th>feature_41</th><th>feature_42</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>3.889038</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.851033</td><td>0.242971</td><td>0.2634</td><td>-0.891687</td><td>11</td><td>7</td><td>76</td><td>-0.883028</td><td>0.003067</td><td>-0.744703</td><td>null</td><td>-0.169586</td><td>null</td><td>-1.335938</td><td>-1.707803</td><td>0.91013</td><td>null</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>null</td><td>null</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>null</td><td>null</td><td>null</td><td>0.28118</td><td>0.269163</td><td>0.349028</td><td>-0.012596</td><td>-0.225932</td><td>null</td><td>-1.073602</td><td>null</td><td>null</td><td>-0.181716</td><td>null</td><td>null</td><td>null</td><td>0.564021</td><td>2.088506</td><td>0.832022</td><td>null</td><td>0.204797</td><td>null</td><td>null</td><td>-0.808103</td><td>null</td><td>-2.037683</td><td>0.727661</td><td>null</td><td>-0.989118</td><td>-0.345213</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.251104</td><td>-0.110252</td><td>-0.491157</td><td>-1.02269</td><td>0.152241</td><td>-0.659864</td><td>null</td><td>null</td><td>-0.261412</td><td>-0.211486</td><td>-0.335556</td><td>-0.281498</td><td>0.775981</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>7</td><td>1.370613</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.676961</td><td>0.151984</td><td>0.192465</td><td>-0.521729</td><td>11</td><td>7</td><td>76</td><td>-0.865307</td><td>-0.225629</td><td>-0.582163</td><td>null</td><td>0.317467</td><td>null</td><td>-1.250016</td><td>-1.682929</td><td>1.412757</td><td>null</td><td>0.520378</td><td>0.744132</td><td>-0.788658</td><td>0.641776</td><td>null</td><td>null</td><td>0.2272</td><td>0.580907</td><td>1.128879</td><td>null</td><td>null</td><td>null</td><td>-1.512286</td><td>-1.414357</td><td>-1.823322</td><td>-0.082763</td><td>-0.184119</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-10.835207</td><td>-0.002704</td><td>-0.621836</td><td>null</td><td>1.172836</td><td>null</td><td>null</td><td>-1.625862</td><td>null</td><td>-1.410017</td><td>1.063013</td><td>null</td><td>0.888355</td><td>0.467994</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.065759</td><td>0.013322</td><td>-0.592855</td><td>-1.052685</td><td>-0.393726</td><td>-0.741603</td><td>null</td><td>null</td><td>-0.281207</td><td>-0.182894</td><td>-0.245565</td><td>-0.302441</td><td>0.703665</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>9</td><td>2.285698</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.056285</td><td>0.187227</td><td>0.249901</td><td>-0.77305</td><td>11</td><td>7</td><td>76</td><td>-0.675719</td><td>-0.199404</td><td>-0.586798</td><td>null</td><td>-0.814909</td><td>null</td><td>-1.296782</td><td>-2.040234</td><td>0.639589</td><td>null</td><td>1.597359</td><td>0.657514</td><td>-1.350148</td><td>0.364215</td><td>null</td><td>null</td><td>-0.017751</td><td>-0.317361</td><td>-0.122379</td><td>null</td><td>null</td><td>null</td><td>-0.320921</td><td>-0.95809</td><td>-2.436589</td><td>0.070999</td><td>-0.245239</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.420632</td><td>-3.515137</td><td>-4.67776</td><td>null</td><td>0.535897</td><td>null</td><td>null</td><td>-0.72542</td><td>null</td><td>-2.29417</td><td>1.764551</td><td>null</td><td>-0.120789</td><td>-0.063458</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.882604</td><td>-0.072482</td><td>-0.617934</td><td>-0.86323</td><td>-0.241892</td><td>-0.709919</td><td>null</td><td>null</td><td>0.377131</td><td>0.300724</td><td>-0.106842</td><td>-0.096792</td><td>2.109352</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>10</td><td>0.690606</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.139366</td><td>0.273328</td><td>0.306549</td><td>-1.262223</td><td>42</td><td>5</td><td>150</td><td>-0.694008</td><td>3.004091</td><td>0.114809</td><td>null</td><td>-0.251882</td><td>null</td><td>-1.902009</td><td>-0.979447</td><td>0.241165</td><td>null</td><td>-0.392359</td><td>-0.224699</td><td>-2.129397</td><td>-0.855287</td><td>null</td><td>null</td><td>0.404142</td><td>-0.578156</td><td>0.105702</td><td>null</td><td>null</td><td>null</td><td>0.544138</td><td>-0.087091</td><td>-1.500147</td><td>-0.201288</td><td>-0.038042</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.382074</td><td>2.669135</td><td>0.611711</td><td>null</td><td>2.413415</td><td>null</td><td>null</td><td>1.313203</td><td>null</td><td>-0.810125</td><td>2.939022</td><td>null</td><td>3.988801</td><td>1.834661</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.697595</td><td>1.074309</td><td>-0.206929</td><td>-0.530602</td><td>4.765215</td><td>0.571554</td><td>null</td><td>null</td><td>-0.226891</td><td>-0.251412</td><td>-0.215522</td><td>-0.296244</td><td>1.114137</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>14</td><td>0.44057</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.9552</td><td>0.262404</td><td>0.344457</td><td>-0.613813</td><td>44</td><td>3</td><td>16</td><td>-0.947351</td><td>-0.030018</td><td>-0.502379</td><td>null</td><td>0.646086</td><td>null</td><td>-1.844685</td><td>-1.58656</td><td>-0.182024</td><td>null</td><td>-0.969949</td><td>-0.673813</td><td>-1.282132</td><td>-1.399894</td><td>null</td><td>null</td><td>0.043815</td><td>-0.320225</td><td>-0.031713</td><td>null</td><td>null</td><td>null</td><td>-0.08842</td><td>-0.995003</td><td>-2.635336</td><td>-0.196461</td><td>-0.618719</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-2.0146</td><td>-2.321076</td><td>-3.711265</td><td>null</td><td>1.253902</td><td>null</td><td>null</td><td>0.476195</td><td>null</td><td>-0.771732</td><td>2.843421</td><td>null</td><td>1.379815</td><td>0.411827</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.948601</td><td>-0.136814</td><td>-0.447704</td><td>-1.141761</td><td>0.099631</td><td>-0.661928</td><td>null</td><td>null</td><td>3.678076</td><td>2.793581</td><td>2.61825</td><td>3.418133</td><td>-3.57282</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 93)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ dat ┆ tim ┆ sym ┆ wei ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res │\n",
       "│ e_i ┆ e_i ┆ bol ┆ ght ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon │\n",
       "│ d   ┆ d   ┆ _id ┆ --- ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der │\n",
       "│ --- ┆ --- ┆ --- ┆ f32 ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ _6  ┆ _0_ ┆ _1_ ┆ _2_ ┆ _3_ ┆ _4_ ┆ _5_ ┆ _6_ ┆ _7_ ┆ _8_ │\n",
       "│ i16 ┆ i16 ┆ i8  ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag │\n",
       "│     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ i8  ┆ i8  ┆ i16 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 0   ┆ 0   ┆ 1   ┆ 3.8 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.8 ┆ 0.2 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ 0.0 ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -1. ┆ 0.9 ┆ nul ┆ 1.6 ┆ 1.5 ┆ -1. ┆ -0. ┆ nul ┆ nul ┆ 1.3 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.2 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ -0. ┆ nul ┆ -1. ┆ nul ┆ nul ┆ -0. ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ 2.0 ┆ 0.8 ┆ nul ┆ 0.2 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 0.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -0. ┆ -0. ┆ -1. ┆ 0.1 ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 890 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 510 ┆ 429 ┆ 634 ┆ 891 ┆     ┆     ┆     ┆ 883 ┆ 030 ┆ 744 ┆ l   ┆ 169 ┆ l   ┆ 335 ┆ 707 ┆ 101 ┆ l   ┆ 364 ┆ 221 ┆ 551 ┆ 229 ┆ l   ┆ l   ┆ 783 ┆ 283 ┆ 231 ┆ l   ┆ l   ┆ l   ┆ 811 ┆ 691 ┆ 490 ┆ 012 ┆ 225 ┆ l   ┆ 073 ┆ l   ┆ l   ┆ 181 ┆ l   ┆ l   ┆ l   ┆ 640 ┆ 885 ┆ 320 ┆ l   ┆ 047 ┆ l   ┆ l   ┆ 808 ┆ l   ┆ 037 ┆ 276 ┆ l   ┆ 989 ┆ 345 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 251 ┆ 110 ┆ 491 ┆ 022 ┆ 522 ┆ 659 ┆ l   ┆ l   ┆ 261 ┆ 211 ┆ 335 ┆ 281 ┆ 759 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 38  ┆     ┆     ┆     ┆     ┆     ┆ 33  ┆ 71  ┆     ┆ 687 ┆     ┆     ┆     ┆ 028 ┆ 67  ┆ 703 ┆     ┆ 586 ┆     ┆ 938 ┆ 803 ┆ 3   ┆     ┆ 31  ┆ 33  ┆ 398 ┆ 627 ┆     ┆     ┆ 01  ┆ 712 ┆ 96  ┆     ┆     ┆     ┆ 8   ┆ 63  ┆ 28  ┆ 596 ┆ 932 ┆     ┆ 602 ┆     ┆     ┆ 716 ┆     ┆     ┆     ┆ 21  ┆ 06  ┆ 22  ┆     ┆ 97  ┆     ┆     ┆ 103 ┆     ┆ 683 ┆ 61  ┆     ┆ 118 ┆ 213 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 104 ┆ 252 ┆ 157 ┆ 69  ┆ 41  ┆ 864 ┆     ┆     ┆ 412 ┆ 486 ┆ 556 ┆ 498 ┆ 81  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 7   ┆ 1.3 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.6 ┆ 0.1 ┆ 0.1 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.3 ┆ nul ┆ -1. ┆ -1. ┆ 1.4 ┆ nul ┆ 0.5 ┆ 0.7 ┆ -0. ┆ 0.6 ┆ nul ┆ nul ┆ 0.2 ┆ 0.5 ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -1. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -10 ┆ -0. ┆ -0. ┆ nul ┆ 1.1 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 1.0 ┆ nul ┆ 0.8 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ 0.0 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 706 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 769 ┆ 519 ┆ 924 ┆ 521 ┆     ┆     ┆     ┆ 865 ┆ 225 ┆ 582 ┆ l   ┆ 174 ┆ l   ┆ 250 ┆ 682 ┆ 127 ┆ l   ┆ 203 ┆ 441 ┆ 788 ┆ 417 ┆ l   ┆ l   ┆ 272 ┆ 809 ┆ 288 ┆ l   ┆ l   ┆ l   ┆ 512 ┆ 414 ┆ 823 ┆ 082 ┆ 184 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ .83 ┆ 002 ┆ 621 ┆ l   ┆ 728 ┆ l   ┆ l   ┆ 625 ┆ l   ┆ 410 ┆ 630 ┆ l   ┆ 883 ┆ 679 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 065 ┆ 133 ┆ 592 ┆ 052 ┆ 393 ┆ 741 ┆ l   ┆ l   ┆ 281 ┆ 182 ┆ 245 ┆ 302 ┆ 036 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 13  ┆     ┆     ┆     ┆     ┆     ┆ 61  ┆ 84  ┆ 65  ┆ 729 ┆     ┆     ┆     ┆ 307 ┆ 629 ┆ 163 ┆     ┆ 67  ┆     ┆ 016 ┆ 929 ┆ 57  ┆     ┆ 78  ┆ 32  ┆ 658 ┆ 76  ┆     ┆     ┆     ┆ 07  ┆ 79  ┆     ┆     ┆     ┆ 286 ┆ 357 ┆ 322 ┆ 763 ┆ 119 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 520 ┆ 704 ┆ 836 ┆     ┆ 36  ┆     ┆     ┆ 862 ┆     ┆ 017 ┆ 13  ┆     ┆ 55  ┆ 94  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 759 ┆ 22  ┆ 855 ┆ 685 ┆ 726 ┆ 603 ┆     ┆     ┆ 207 ┆ 894 ┆ 565 ┆ 441 ┆ 65  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 9   ┆ 2.2 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.0 ┆ 0.1 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -2. ┆ 0.6 ┆ nul ┆ 1.5 ┆ 0.6 ┆ -1. ┆ 0.3 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -3. ┆ -4. ┆ nul ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 1.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ 0.3 ┆ 0.3 ┆ -0. ┆ -0. ┆ 2.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 856 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 562 ┆ 872 ┆ 499 ┆ 773 ┆     ┆     ┆     ┆ 675 ┆ 199 ┆ 586 ┆ l   ┆ 814 ┆ l   ┆ 296 ┆ 040 ┆ 395 ┆ l   ┆ 973 ┆ 575 ┆ 350 ┆ 642 ┆ l   ┆ l   ┆ 017 ┆ 317 ┆ 122 ┆ l   ┆ l   ┆ l   ┆ 320 ┆ 958 ┆ 436 ┆ 709 ┆ 245 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 420 ┆ 515 ┆ 677 ┆ l   ┆ 358 ┆ l   ┆ l   ┆ 725 ┆ l   ┆ 294 ┆ 645 ┆ l   ┆ 120 ┆ 063 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 882 ┆ 072 ┆ 617 ┆ 863 ┆ 241 ┆ 709 ┆ l   ┆ l   ┆ 771 ┆ 007 ┆ 106 ┆ 096 ┆ 093 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 98  ┆     ┆     ┆     ┆     ┆     ┆ 85  ┆ 27  ┆ 01  ┆ 05  ┆     ┆     ┆     ┆ 719 ┆ 404 ┆ 798 ┆     ┆ 909 ┆     ┆ 782 ┆ 234 ┆ 89  ┆     ┆ 59  ┆ 14  ┆ 148 ┆ 15  ┆     ┆     ┆ 751 ┆ 361 ┆ 379 ┆     ┆     ┆     ┆ 921 ┆ 09  ┆ 589 ┆ 99  ┆ 239 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 632 ┆ 137 ┆ 76  ┆     ┆ 97  ┆     ┆     ┆ 42  ┆     ┆ 17  ┆ 51  ┆     ┆ 789 ┆ 458 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 604 ┆ 482 ┆ 934 ┆ 23  ┆ 892 ┆ 919 ┆     ┆     ┆ 31  ┆ 24  ┆ 842 ┆ 792 ┆ 52  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 10  ┆ 0.6 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.1 ┆ 0.2 ┆ 0.3 ┆ -1. ┆ 42  ┆ 5   ┆ 150 ┆ -0. ┆ 3.0 ┆ 0.1 ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -0. ┆ 0.2 ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ nul ┆ nul ┆ 0.4 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.3 ┆ 2.6 ┆ 0.6 ┆ nul ┆ 2.4 ┆ nul ┆ nul ┆ 1.3 ┆ nul ┆ -0. ┆ 2.9 ┆ nul ┆ 3.9 ┆ 1.8 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ 1.0 ┆ -0. ┆ -0. ┆ 4.7 ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 906 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 393 ┆ 733 ┆ 065 ┆ 262 ┆     ┆     ┆     ┆ 694 ┆ 040 ┆ 148 ┆ l   ┆ 251 ┆ l   ┆ 902 ┆ 979 ┆ 411 ┆ l   ┆ 392 ┆ 224 ┆ 129 ┆ 855 ┆ l   ┆ l   ┆ 041 ┆ 578 ┆ 057 ┆ l   ┆ l   ┆ l   ┆ 441 ┆ 087 ┆ 500 ┆ 201 ┆ 038 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 820 ┆ 691 ┆ 117 ┆ l   ┆ 134 ┆ l   ┆ l   ┆ 132 ┆ l   ┆ 810 ┆ 390 ┆ l   ┆ 888 ┆ 346 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 697 ┆ 743 ┆ 206 ┆ 530 ┆ 652 ┆ 715 ┆ l   ┆ l   ┆ 226 ┆ 251 ┆ 215 ┆ 296 ┆ 141 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 06  ┆     ┆     ┆     ┆     ┆     ┆ 66  ┆ 28  ┆ 49  ┆ 223 ┆     ┆     ┆     ┆ 008 ┆ 91  ┆ 09  ┆     ┆ 882 ┆     ┆ 009 ┆ 447 ┆ 65  ┆     ┆ 359 ┆ 699 ┆ 397 ┆ 287 ┆     ┆     ┆ 42  ┆ 156 ┆ 02  ┆     ┆     ┆     ┆ 38  ┆ 091 ┆ 147 ┆ 288 ┆ 042 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 74  ┆ 35  ┆ 11  ┆     ┆ 15  ┆     ┆     ┆ 03  ┆     ┆ 125 ┆ 22  ┆     ┆ 01  ┆ 61  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 595 ┆ 09  ┆ 929 ┆ 602 ┆ 15  ┆ 54  ┆     ┆     ┆ 891 ┆ 412 ┆ 522 ┆ 244 ┆ 37  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 14  ┆ 0.4 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.9 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ 44  ┆ 3   ┆ 16  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.6 ┆ nul ┆ -1. ┆ -1. ┆ -0. ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ -1. ┆ nul ┆ nul ┆ 0.0 ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -2. ┆ -2. ┆ -3. ┆ nul ┆ 1.2 ┆ nul ┆ nul ┆ 0.4 ┆ nul ┆ -0. ┆ 2.8 ┆ nul ┆ 1.3 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ 3.6 ┆ 2.7 ┆ 2.6 ┆ 3.4 ┆ -3. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 405 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 552 ┆ 624 ┆ 444 ┆ 613 ┆     ┆     ┆     ┆ 947 ┆ 030 ┆ 502 ┆ l   ┆ 460 ┆ l   ┆ 844 ┆ 586 ┆ 182 ┆ l   ┆ 969 ┆ 673 ┆ 282 ┆ 399 ┆ l   ┆ l   ┆ 438 ┆ 320 ┆ 031 ┆ l   ┆ l   ┆ l   ┆ 088 ┆ 995 ┆ 635 ┆ 196 ┆ 618 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 014 ┆ 321 ┆ 711 ┆ l   ┆ 539 ┆ l   ┆ l   ┆ 761 ┆ l   ┆ 771 ┆ 434 ┆ l   ┆ 798 ┆ 118 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 948 ┆ 136 ┆ 447 ┆ 141 ┆ 996 ┆ 661 ┆ l   ┆ l   ┆ 780 ┆ 935 ┆ 182 ┆ 181 ┆ 572 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆ 04  ┆ 57  ┆ 813 ┆     ┆     ┆     ┆ 351 ┆ 018 ┆ 379 ┆     ┆ 86  ┆     ┆ 685 ┆ 56  ┆ 024 ┆     ┆ 949 ┆ 813 ┆ 132 ┆ 894 ┆     ┆     ┆ 15  ┆ 225 ┆ 713 ┆     ┆     ┆     ┆ 42  ┆ 003 ┆ 336 ┆ 461 ┆ 719 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 6   ┆ 076 ┆ 265 ┆     ┆ 02  ┆     ┆     ┆ 95  ┆     ┆ 732 ┆ 21  ┆     ┆ 15  ┆ 27  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 601 ┆ 814 ┆ 704 ┆ 761 ┆ 31  ┆ 928 ┆     ┆     ┆ 76  ┆ 81  ┆ 5   ┆ 33  ┆ 82  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pl.read_parquet(path + 'train.parquet/').select(pl.all().shrink_dtype())\n",
    "lags_df = train_df.with_columns(pl.col('date_id') + 1).drop(['weight', 'partition_id'] + [col for col in train_df.columns if 'feature' in col]).rename({f'responder_{x}': f'responder_{x}_lag_1' for x in range(9)})\n",
    "train_df = train_df.drop(['responder_0', 'responder_1', 'responder_2', 'responder_3', 'responder_4', 'responder_5', 'responder_7', 'responder_8', 'partition_id']).select(pl.all().shrink_dtype())\n",
    "train_df = train_df.join(lags_df, on=['date_id', 'time_id', 'symbol_id'], how='left').select(pl.all().shrink_dtype())\n",
    "del lags_df\n",
    "gc.collect()\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7434dcc6-f9b9-4e8a-aa41-50c724fd1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scan = pl.scan_parquet(path + 'train.parquet/')\n",
    "test_scan = pl.scan_parquet(path + 'test.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93569971-385d-4e5a-b362-ff4fbf80cf6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_symbol_ids_list = sorted(train_scan.select('symbol_id').unique().collect()['symbol_id'].to_list())\n",
    "test_symbol_ids_list = sorted(test_scan.select('symbol_id').unique().collect()['symbol_id'].to_list())\n",
    "unique_symbol_ids_list = sorted(list(set(train_symbol_ids_list + test_symbol_ids_list)))\n",
    "unique_symbol_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d27779c-c935-48d8-a8ce-42a39e8e1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_cat_cols(df):\n",
    "    for v in tqdm(unique_symbol_ids_list):\n",
    "        new_col_name = 'symbol_id_' + str(v)\n",
    "        #df[new_col_name] = (df['symbol_id'] == v).astype(int)\n",
    "        df = df.with_columns((pl.col('symbol_id') == v).cast(pl.Int8).alias(new_col_name))\n",
    "\n",
    "    \n",
    "    #df = df.drop('symbol_id', axis=1)\n",
    "\n",
    "    return df.select(pl.all().shrink_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92164aef-b008-4286-a99e-1f330ce2f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pl.read_csv(path + 'features.csv').select(pl.all().shrink_dtype())\n",
    "responders_df = pl.read_csv(path + 'responders.csv').select(pl.all().shrink_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4aa99ce-57dd-4720-8dad-24a4312a7d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_list = features_df.columns\n",
    "tags_list.remove('feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40681e7d-05ba-4d73-86b9-036bb266ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "responder_tags_list = responders_df.columns\n",
    "responder_tags_list.remove('responder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a090596-aae7-47b4-9f8b-7d916f61be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_features(df):\n",
    "    for tag in tqdm(tags_list):\n",
    "        tag_features = features_df.filter(pl.col(f\"{tag}\") == True)[\"feature\"].to_list()\n",
    "        df = df.with_columns(\n",
    "            pl.sum_horizontal(tag_features).alias('feature_' + tag + '_sum'),\n",
    "            pl.mean_horizontal(tag_features).alias('feature_' + tag + '_mean'),\n",
    "            pl.min_horizontal(tag_features).alias('feature_' + tag + '_min'),\n",
    "            pl.max_horizontal(tag_features).alias('feature_' + tag + '_max')\n",
    "        )\n",
    "\n",
    "    return df.select(pl.all().shrink_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c16b97b-26b4-4214-ac9b-242b7f41e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_responders_tag_features(df):\n",
    "    for tag in tqdm(responder_tags_list):\n",
    "        tag_features = responders_df.filter(pl.col(f\"{tag}\") == True)[\"responder\"].to_list()\n",
    "        tag_features = [v + '_lag_1' for v in tag_features]\n",
    "        df = df.with_columns(\n",
    "            pl.sum_horizontal(tag_features).alias('responder_' + tag + '_sum'),\n",
    "            pl.mean_horizontal(tag_features).alias('responder_' + tag + '_mean'),\n",
    "            pl.min_horizontal(tag_features).alias('responder_' + tag + '_min'),\n",
    "            pl.max_horizontal(tag_features).alias('responder_' + tag + '_max')\n",
    "        )\n",
    "\n",
    "    return df.select(pl.all().shrink_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d159eba9-0648-4b6d-8df2-83d303cfba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:42<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "train_df = create_tag_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad6c70b-7b24-45c5-97c0-4edf10fc5d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47127338, 181)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 181)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_39</th><th>feature_40</th><th>feature_41</th><th>feature_42</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th><th>feature_tag_0_sum</th><th>feature_tag_0_mean</th><th>feature_tag_0_min</th><th>feature_tag_0_max</th><th>feature_tag_1_sum</th><th>feature_tag_1_mean</th><th>feature_tag_1_min</th><th>feature_tag_1_max</th><th>feature_tag_2_sum</th><th>feature_tag_2_mean</th><th>feature_tag_2_min</th><th>feature_tag_2_max</th><th>feature_tag_3_sum</th><th>feature_tag_3_mean</th><th>feature_tag_3_min</th><th>feature_tag_3_max</th><th>feature_tag_4_sum</th><th>feature_tag_4_mean</th><th>feature_tag_4_min</th><th>feature_tag_4_max</th><th>feature_tag_5_sum</th><th>feature_tag_5_mean</th><th>feature_tag_5_min</th><th>feature_tag_5_max</th><th>feature_tag_6_sum</th><th>feature_tag_6_mean</th><th>feature_tag_6_min</th><th>feature_tag_6_max</th><th>feature_tag_7_sum</th><th>feature_tag_7_mean</th><th>feature_tag_7_min</th><th>feature_tag_7_max</th><th>feature_tag_8_sum</th><th>feature_tag_8_mean</th><th>feature_tag_8_min</th><th>feature_tag_8_max</th><th>feature_tag_9_sum</th><th>feature_tag_9_mean</th><th>feature_tag_9_min</th><th>feature_tag_9_max</th><th>feature_tag_10_sum</th><th>feature_tag_10_mean</th><th>feature_tag_10_min</th><th>feature_tag_10_max</th><th>feature_tag_11_sum</th><th>feature_tag_11_mean</th><th>feature_tag_11_min</th><th>feature_tag_11_max</th><th>feature_tag_12_sum</th><th>feature_tag_12_mean</th><th>feature_tag_12_min</th><th>feature_tag_12_max</th><th>feature_tag_13_sum</th><th>feature_tag_13_mean</th><th>feature_tag_13_min</th><th>feature_tag_13_max</th><th>feature_tag_14_sum</th><th>feature_tag_14_mean</th><th>feature_tag_14_min</th><th>feature_tag_14_max</th><th>feature_tag_15_sum</th><th>feature_tag_15_mean</th><th>feature_tag_15_min</th><th>feature_tag_15_max</th><th>feature_tag_16_sum</th><th>feature_tag_16_mean</th><th>feature_tag_16_min</th><th>feature_tag_16_max</th><th>responder_tag_0_sum</th><th>responder_tag_0_mean</th><th>responder_tag_0_min</th><th>responder_tag_0_max</th><th>responder_tag_1_sum</th><th>responder_tag_1_mean</th><th>responder_tag_1_min</th><th>responder_tag_1_max</th><th>responder_tag_2_sum</th><th>responder_tag_2_mean</th><th>responder_tag_2_min</th><th>responder_tag_2_max</th><th>responder_tag_3_sum</th><th>responder_tag_3_mean</th><th>responder_tag_3_min</th><th>responder_tag_3_max</th><th>responder_tag_4_sum</th><th>responder_tag_4_mean</th><th>responder_tag_4_min</th><th>responder_tag_4_max</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i16</td><td>f32</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>3.889038</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.851033</td><td>0.242971</td><td>0.2634</td><td>-0.891687</td><td>11</td><td>7</td><td>76</td><td>-0.883028</td><td>0.003067</td><td>-0.744703</td><td>null</td><td>-0.169586</td><td>null</td><td>-1.335938</td><td>-1.707803</td><td>0.91013</td><td>null</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>null</td><td>null</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>null</td><td>null</td><td>null</td><td>0.28118</td><td>0.269163</td><td>0.349028</td><td>-0.012596</td><td>-0.225932</td><td>null</td><td>-1.073602</td><td>null</td><td>null</td><td>-0.181716</td><td>null</td><td>null</td><td>null</td><td>0.564021</td><td>2.088506</td><td>0.832022</td><td>null</td><td>0.204797</td><td>null</td><td>null</td><td>-0.808103</td><td>null</td><td>-2.037683</td><td>0.727661</td><td>null</td><td>-0.989118</td><td>-0.345213</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.251104</td><td>-0.110252</td><td>-0.491157</td><td>-1.02269</td><td>0.152241</td><td>-0.659864</td><td>null</td><td>null</td><td>-0.261412</td><td>-0.211486</td><td>-0.335556</td><td>-0.281498</td><td>0.775981</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.505453</td><td>0.438182</td><td>-1.551398</td><td>1.636431</td><td>94</td><td>31.333334</td><td>7</td><td>76</td><td>0.899371</td><td>0.29979</td><td>0.269163</td><td>0.349028</td><td>-0.79124</td><td>-0.046544</td><td>-2.037683</td><td>2.088506</td><td>-4.242425</td><td>-1.060606</td><td>-2.037683</td><td>0.204797</td><td>-1.96996</td><td>-0.49249</td><td>-1.707803</td><td>0.727661</td><td>-0.169586</td><td>-0.169586</td><td>-0.169586</td><td>-0.169586</td><td>-3.04374</td><td>-1.52187</td><td>-1.707803</td><td>-1.335938</td><td>-1.089952</td><td>-0.272488</td><td>-0.335556</td><td>-0.211486</td><td>-5.00749</td><td>-0.556388</td><td>-1.251104</td><td>0.152241</td><td>-1.530313</td><td>-0.510104</td><td>-1.02269</td><td>0.152241</td><td>-1.852513</td><td>-0.617504</td><td>-1.251104</td><td>-0.110252</td><td>-0.483484</td><td>-0.032232</td><td>-1.073602</td><td>2.088506</td><td>-1.144378</td><td>-0.114438</td><td>-0.744703</td><td>0.832022</td><td>-1.741769</td><td>-0.348354</td><td>-1.251104</td><td>0.851033</td><td>0.86699</td><td>0.144498</td><td>-1.36224</td><td>2.088506</td><td>1.375848</td><td>0.27517</td><td>-0.891687</td><td>0.91013</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>7</td><td>1.370613</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.676961</td><td>0.151984</td><td>0.192465</td><td>-0.521729</td><td>11</td><td>7</td><td>76</td><td>-0.865307</td><td>-0.225629</td><td>-0.582163</td><td>null</td><td>0.317467</td><td>null</td><td>-1.250016</td><td>-1.682929</td><td>1.412757</td><td>null</td><td>0.520378</td><td>0.744132</td><td>-0.788658</td><td>0.641776</td><td>null</td><td>null</td><td>0.2272</td><td>0.580907</td><td>1.128879</td><td>null</td><td>null</td><td>null</td><td>-1.512286</td><td>-1.414357</td><td>-1.823322</td><td>-0.082763</td><td>-0.184119</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-10.835207</td><td>-0.002704</td><td>-0.621836</td><td>null</td><td>1.172836</td><td>null</td><td>null</td><td>-1.625862</td><td>null</td><td>-1.410017</td><td>1.063013</td><td>null</td><td>0.888355</td><td>0.467994</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.065759</td><td>0.013322</td><td>-0.592855</td><td>-1.052685</td><td>-0.393726</td><td>-0.741603</td><td>null</td><td>null</td><td>-0.281207</td><td>-0.182894</td><td>-0.245565</td><td>-0.302441</td><td>0.703665</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4.467371</td><td>0.558421</td><td>-0.788658</td><td>1.412757</td><td>94</td><td>31.333334</td><td>7</td><td>76</td><td>-4.749964</td><td>-1.583321</td><td>-1.823322</td><td>-1.414357</td><td>-10.67063</td><td>-0.711375</td><td>-10.835207</td><td>1.172836</td><td>-1.487198</td><td>-0.495733</td><td>-1.410017</td><td>1.172836</td><td>-2.245778</td><td>-0.748593</td><td>-1.682929</td><td>1.063013</td><td>0.317467</td><td>0.317467</td><td>0.317467</td><td>0.317467</td><td>-2.932945</td><td>-1.466472</td><td>-1.682929</td><td>-1.250016</td><td>-1.012106</td><td>-0.253027</td><td>-0.302441</td><td>-0.182894</td><td>-5.506405</td><td>-0.611823</td><td>-1.065759</td><td>0.013322</td><td>-2.188014</td><td>-0.729338</td><td>-1.052685</td><td>-0.393726</td><td>-1.645292</td><td>-0.548431</td><td>-1.065759</td><td>0.013322</td><td>-3.503667</td><td>-0.269513</td><td>-1.823322</td><td>1.172836</td><td>-5.663682</td><td>-0.566368</td><td>-1.823322</td><td>0.467994</td><td>-13.141997</td><td>-2.628399</td><td>-10.835207</td><td>0.676961</td><td>-12.821986</td><td>-3.205497</td><td>-10.835207</td><td>-0.002704</td><td>1.912438</td><td>0.382488</td><td>-0.521729</td><td>1.412757</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>9</td><td>2.285698</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.056285</td><td>0.187227</td><td>0.249901</td><td>-0.77305</td><td>11</td><td>7</td><td>76</td><td>-0.675719</td><td>-0.199404</td><td>-0.586798</td><td>null</td><td>-0.814909</td><td>null</td><td>-1.296782</td><td>-2.040234</td><td>0.639589</td><td>null</td><td>1.597359</td><td>0.657514</td><td>-1.350148</td><td>0.364215</td><td>null</td><td>null</td><td>-0.017751</td><td>-0.317361</td><td>-0.122379</td><td>null</td><td>null</td><td>null</td><td>-0.320921</td><td>-0.95809</td><td>-2.436589</td><td>0.070999</td><td>-0.245239</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.420632</td><td>-3.515137</td><td>-4.67776</td><td>null</td><td>0.535897</td><td>null</td><td>null</td><td>-0.72542</td><td>null</td><td>-2.29417</td><td>1.764551</td><td>null</td><td>-0.120789</td><td>-0.063458</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.882604</td><td>-0.072482</td><td>-0.617934</td><td>-0.86323</td><td>-0.241892</td><td>-0.709919</td><td>null</td><td>null</td><td>0.377131</td><td>0.300724</td><td>-0.106842</td><td>-0.096792</td><td>2.109352</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.451039</td><td>0.18138</td><td>-1.350148</td><td>1.597359</td><td>94</td><td>31.333334</td><td>7</td><td>76</td><td>-3.7156</td><td>-1.238533</td><td>-2.436589</td><td>-0.320921</td><td>-9.970796</td><td>-0.66472</td><td>-4.67776</td><td>1.764551</td><td>-3.055055</td><td>-1.018352</td><td>-2.29417</td><td>0.535897</td><td>-1.001103</td><td>-0.333701</td><td>-2.040234</td><td>1.764551</td><td>-0.814909</td><td>-0.814909</td><td>-0.814909</td><td>-0.814909</td><td>-3.337016</td><td>-1.668508</td><td>-2.040234</td><td>-1.296782</td><td>0.474221</td><td>0.118555</td><td>-0.106842</td><td>0.377131</td><td>-4.849982</td><td>-0.538887</td><td>-0.882604</td><td>-0.072482</td><td>-1.81504</td><td>-0.605013</td><td>-0.86323</td><td>-0.241892</td><td>-1.573021</td><td>-0.52434</td><td>-0.882604</td><td>-0.072482</td><td>-7.046564</td><td>-0.542043</td><td>-3.515137</td><td>0.535897</td><td>-10.004279</td><td>-1.000428</td><td>-4.67776</td><td>0.249901</td><td>-2.7859</td><td>-0.55718</td><td>-1.420632</td><td>1.056285</td><td>-10.975769</td><td>-2.743942</td><td>-4.67776</td><td>-1.36224</td><td>1.359952</td><td>0.27199</td><td>-0.77305</td><td>1.056285</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>10</td><td>0.690606</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.139366</td><td>0.273328</td><td>0.306549</td><td>-1.262223</td><td>42</td><td>5</td><td>150</td><td>-0.694008</td><td>3.004091</td><td>0.114809</td><td>null</td><td>-0.251882</td><td>null</td><td>-1.902009</td><td>-0.979447</td><td>0.241165</td><td>null</td><td>-0.392359</td><td>-0.224699</td><td>-2.129397</td><td>-0.855287</td><td>null</td><td>null</td><td>0.404142</td><td>-0.578156</td><td>0.105702</td><td>null</td><td>null</td><td>null</td><td>0.544138</td><td>-0.087091</td><td>-1.500147</td><td>-0.201288</td><td>-0.038042</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.382074</td><td>2.669135</td><td>0.611711</td><td>null</td><td>2.413415</td><td>null</td><td>null</td><td>1.313203</td><td>null</td><td>-0.810125</td><td>2.939022</td><td>null</td><td>3.988801</td><td>1.834661</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.697595</td><td>1.074309</td><td>-0.206929</td><td>-0.530602</td><td>4.765215</td><td>0.571554</td><td>null</td><td>null</td><td>-0.226891</td><td>-0.251412</td><td>-0.215522</td><td>-0.296244</td><td>1.114137</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-3.428889</td><td>-0.428611</td><td>-2.129397</td><td>0.404142</td><td>197</td><td>65.666664</td><td>5</td><td>150</td><td>-1.0431</td><td>-0.3477</td><td>-1.500147</td><td>0.544138</td><td>15.559587</td><td>1.037306</td><td>-1.262223</td><td>3.988801</td><td>-0.298719</td><td>-0.099573</td><td>-1.902009</td><td>2.413415</td><td>3.272779</td><td>1.090926</td><td>-0.979447</td><td>2.939022</td><td>-0.251882</td><td>-0.251882</td><td>-0.251882</td><td>-0.251882</td><td>-2.881456</td><td>-1.440728</td><td>-1.902009</td><td>-0.979447</td><td>-0.990069</td><td>-0.247517</td><td>-0.296244</td><td>-0.215522</td><td>7.400844</td><td>0.822316</td><td>-0.697595</td><td>4.765215</td><td>4.806167</td><td>1.602056</td><td>-0.530602</td><td>4.765215</td><td>0.169785</td><td>0.056595</td><td>-0.697595</td><td>1.074309</td><td>17.815304</td><td>1.370408</td><td>-1.500147</td><td>4.765215</td><td>1.133351</td><td>0.113335</td><td>-1.500147</td><td>1.834661</td><td>-0.400764</td><td>-0.080153</td><td>-0.697595</td><td>1.139366</td><td>2.30068</td><td>0.57517</td><td>-1.36224</td><td>2.669135</td><td>0.698185</td><td>0.139637</td><td>-1.262223</td><td>1.139366</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>14</td><td>0.44057</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.9552</td><td>0.262404</td><td>0.344457</td><td>-0.613813</td><td>44</td><td>3</td><td>16</td><td>-0.947351</td><td>-0.030018</td><td>-0.502379</td><td>null</td><td>0.646086</td><td>null</td><td>-1.844685</td><td>-1.58656</td><td>-0.182024</td><td>null</td><td>-0.969949</td><td>-0.673813</td><td>-1.282132</td><td>-1.399894</td><td>null</td><td>null</td><td>0.043815</td><td>-0.320225</td><td>-0.031713</td><td>null</td><td>null</td><td>null</td><td>-0.08842</td><td>-0.995003</td><td>-2.635336</td><td>-0.196461</td><td>-0.618719</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-2.0146</td><td>-2.321076</td><td>-3.711265</td><td>null</td><td>1.253902</td><td>null</td><td>null</td><td>0.476195</td><td>null</td><td>-0.771732</td><td>2.843421</td><td>null</td><td>1.379815</td><td>0.411827</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.948601</td><td>-0.136814</td><td>-0.447704</td><td>-1.141761</td><td>0.099631</td><td>-0.661928</td><td>null</td><td>null</td><td>3.678076</td><td>2.793581</td><td>2.61825</td><td>3.418133</td><td>-3.57282</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-4.815935</td><td>-0.601992</td><td>-1.399894</td><td>0.043815</td><td>63</td><td>21.0</td><td>3</td><td>44</td><td>-3.71876</td><td>-1.239586</td><td>-2.635336</td><td>-0.08842</td><td>-2.320445</td><td>-0.154696</td><td>-3.711265</td><td>2.843421</td><td>-1.362515</td><td>-0.454172</td><td>-1.844685</td><td>1.253902</td><td>1.733056</td><td>0.577685</td><td>-1.58656</td><td>2.843421</td><td>0.646086</td><td>0.646086</td><td>0.646086</td><td>0.646086</td><td>-3.431245</td><td>-1.715623</td><td>-1.844685</td><td>-1.58656</td><td>12.508041</td><td>3.12701</td><td>2.61825</td><td>3.678076</td><td>-4.716927</td><td>-0.524103</td><td>-1.141761</td><td>0.099631</td><td>-1.704059</td><td>-0.56802</td><td>-1.141761</td><td>0.099631</td><td>-1.533119</td><td>-0.51104</td><td>-0.948601</td><td>-0.136814</td><td>5.378025</td><td>0.413694</td><td>-2.635336</td><td>3.678076</td><td>-2.160948</td><td>-0.216095</td><td>-3.711265</td><td>3.418133</td><td>-4.097114</td><td>-0.819423</td><td>-2.0146</td><td>0.9552</td><td>-9.409181</td><td>-2.352295</td><td>-3.711265</td><td>-1.36224</td><td>0.766224</td><td>0.153245</td><td>-0.613813</td><td>0.9552</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 181)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ dat ┆ tim ┆ sym ┆ wei ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res │\n",
       "│ e_i ┆ e_i ┆ bol ┆ ght ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon │\n",
       "│ d   ┆ d   ┆ _id ┆ --- ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ e_t ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der │\n",
       "│ --- ┆ --- ┆ --- ┆ f32 ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ _6  ┆ _0_ ┆ _1_ ┆ _2_ ┆ _3_ ┆ _4_ ┆ _5_ ┆ _6_ ┆ _7_ ┆ _8_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ ag_ ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta ┆ _ta │\n",
       "│ i16 ┆ i16 ┆ i8  ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ 0_s ┆ 0_m ┆ 0_m ┆ 0_m ┆ 1_s ┆ 1_m ┆ 1_m ┆ 1_m ┆ 2_s ┆ 2_m ┆ 2_m ┆ 2_m ┆ 3_s ┆ 3_m ┆ 3_m ┆ 3_m ┆ 4_s ┆ 4_m ┆ 4_m ┆ 4_m ┆ 5_s ┆ 5_m ┆ 5_m ┆ 5_m ┆ 6_s ┆ 6_m ┆ 6_m ┆ 6_m ┆ 7_s ┆ 7_m ┆ 7_m ┆ 7_m ┆ 8_s ┆ 8_m ┆ 8_m ┆ 8_m ┆ 9_s ┆ 9_m ┆ 9_m ┆ 9_m ┆ 10_ ┆ 10_ ┆ 10_ ┆ 10_ ┆ 11_ ┆ 11_ ┆ 11_ ┆ 11_ ┆ 12_ ┆ 12_ ┆ 12_ ┆ 12_ ┆ 13_ ┆ 13_ ┆ 13_ ┆ 13_ ┆ 14_ ┆ 14_ ┆ 14_ ┆ 14_ ┆ 15_ ┆ 15_ ┆ 15_ ┆ 15_ ┆ 16_ ┆ 16_ ┆ 16_ ┆ 16_ ┆ g_0 ┆ g_0 ┆ g_0 ┆ g_0 ┆ g_1 ┆ g_1 ┆ g_1 ┆ g_1 ┆ g_2 ┆ g_2 ┆ g_2 ┆ g_2 ┆ g_3 ┆ g_3 ┆ g_3 ┆ g_3 ┆ g_4 ┆ g_4 ┆ g_4 ┆ g_4 │\n",
       "│     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ i8  ┆ i8  ┆ i16 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ um  ┆ ean ┆ in  ┆ ax  ┆ sum ┆ mea ┆ min ┆ max ┆ sum ┆ mea ┆ min ┆ max ┆ sum ┆ mea ┆ min ┆ max ┆ sum ┆ mea ┆ min ┆ max ┆ sum ┆ mea ┆ min ┆ max ┆ sum ┆ mea ┆ min ┆ max ┆ sum ┆ mea ┆ min ┆ max ┆ _su ┆ _me ┆ _mi ┆ _ma ┆ _su ┆ _me ┆ _mi ┆ _ma ┆ _su ┆ _me ┆ _mi ┆ _ma ┆ _su ┆ _me ┆ _mi ┆ _ma ┆ _su ┆ _me ┆ _mi ┆ _ma │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ n   ┆ --- ┆ --- ┆ --- ┆ n   ┆ --- ┆ --- ┆ --- ┆ n   ┆ --- ┆ --- ┆ --- ┆ n   ┆ --- ┆ --- ┆ --- ┆ n   ┆ --- ┆ --- ┆ --- ┆ n   ┆ --- ┆ --- ┆ --- ┆ n   ┆ --- ┆ --- ┆ m   ┆ an  ┆ n   ┆ x   ┆ m   ┆ an  ┆ n   ┆ x   ┆ m   ┆ an  ┆ n   ┆ x   ┆ m   ┆ an  ┆ n   ┆ x   ┆ m   ┆ an  ┆ n   ┆ x   │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ i16 ┆ f32 ┆ i8  ┆ i16 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ --- ┆ f32 ┆ f32 ┆ f32 ┆ --- ┆ f32 ┆ f32 ┆ f32 ┆ --- ┆ f32 ┆ f32 ┆ f32 ┆ --- ┆ f32 ┆ f32 ┆ f32 ┆ --- ┆ f32 ┆ f32 ┆ f32 ┆ --- ┆ f32 ┆ f32 ┆ f32 ┆ --- ┆ f32 ┆ f32 ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ f32 ┆     ┆     ┆     ┆ f32 ┆     ┆     ┆     ┆ f32 ┆     ┆     ┆     ┆ f32 ┆     ┆     ┆     ┆ f32 ┆     ┆     ┆     ┆ f32 ┆     ┆     ┆     ┆ f32 ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 0   ┆ 0   ┆ 1   ┆ 3.8 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.8 ┆ 0.2 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ 0.0 ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -1. ┆ 0.9 ┆ nul ┆ 1.6 ┆ 1.5 ┆ -1. ┆ -0. ┆ nul ┆ nul ┆ 1.3 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.2 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ -0. ┆ nul ┆ -1. ┆ nul ┆ nul ┆ -0. ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ 2.0 ┆ 0.8 ┆ nul ┆ 0.2 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 0.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -0. ┆ -0. ┆ -1. ┆ 0.1 ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 3.5 ┆ 0.4 ┆ -1. ┆ 1.6 ┆ 94  ┆ 31. ┆ 7   ┆ 76  ┆ 0.8 ┆ 0.2 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ -0. ┆ -2. ┆ 2.0 ┆ -4. ┆ -1. ┆ -2. ┆ 0.2 ┆ -1. ┆ -0. ┆ -1. ┆ 0.7 ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -3. ┆ -1. ┆ -1. ┆ -1. ┆ -1. ┆ -0. ┆ -0. ┆ -0. ┆ -5. ┆ -0. ┆ -1. ┆ 0.1 ┆ -1. ┆ -0. ┆ -1. ┆ 0.1 ┆ -1. ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ 2.0 ┆ -1. ┆ -0. ┆ -0. ┆ 0.8 ┆ -1. ┆ -0. ┆ -1. ┆ 0.8 ┆ 0.8 ┆ 0.1 ┆ -1. ┆ 2.0 ┆ 1.3 ┆ 0.2 ┆ -0. ┆ 0.9 ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 890 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 510 ┆ 429 ┆ 634 ┆ 891 ┆     ┆     ┆     ┆ 883 ┆ 030 ┆ 744 ┆ l   ┆ 169 ┆ l   ┆ 335 ┆ 707 ┆ 101 ┆ l   ┆ 364 ┆ 221 ┆ 551 ┆ 229 ┆ l   ┆ l   ┆ 783 ┆ 283 ┆ 231 ┆ l   ┆ l   ┆ l   ┆ 811 ┆ 691 ┆ 490 ┆ 012 ┆ 225 ┆ l   ┆ 073 ┆ l   ┆ l   ┆ 181 ┆ l   ┆ l   ┆ l   ┆ 640 ┆ 885 ┆ 320 ┆ l   ┆ 047 ┆ l   ┆ l   ┆ 808 ┆ l   ┆ 037 ┆ 276 ┆ l   ┆ 989 ┆ 345 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 251 ┆ 110 ┆ 491 ┆ 022 ┆ 522 ┆ 659 ┆ l   ┆ l   ┆ 261 ┆ 211 ┆ 335 ┆ 281 ┆ 759 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 054 ┆ 381 ┆ 551 ┆ 364 ┆     ┆ 333 ┆     ┆     ┆ 993 ┆ 997 ┆ 691 ┆ 490 ┆ 791 ┆ 046 ┆ 037 ┆ 885 ┆ 242 ┆ 060 ┆ 037 ┆ 047 ┆ 969 ┆ 492 ┆ 707 ┆ 276 ┆ 169 ┆ 169 ┆ 169 ┆ 169 ┆ 043 ┆ 521 ┆ 707 ┆ 335 ┆ 089 ┆ 272 ┆ 335 ┆ 211 ┆ 007 ┆ 556 ┆ 251 ┆ 522 ┆ 530 ┆ 510 ┆ 022 ┆ 522 ┆ 852 ┆ 617 ┆ 251 ┆ 110 ┆ 483 ┆ 032 ┆ 073 ┆ 885 ┆ 144 ┆ 114 ┆ 744 ┆ 320 ┆ 741 ┆ 348 ┆ 251 ┆ 510 ┆ 669 ┆ 444 ┆ 362 ┆ 885 ┆ 758 ┆ 751 ┆ 891 ┆ 101 ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 38  ┆     ┆     ┆     ┆     ┆     ┆ 33  ┆ 71  ┆     ┆ 687 ┆     ┆     ┆     ┆ 028 ┆ 67  ┆ 703 ┆     ┆ 586 ┆     ┆ 938 ┆ 803 ┆ 3   ┆     ┆ 31  ┆ 33  ┆ 398 ┆ 627 ┆     ┆     ┆ 01  ┆ 712 ┆ 96  ┆     ┆     ┆     ┆ 8   ┆ 63  ┆ 28  ┆ 596 ┆ 932 ┆     ┆ 602 ┆     ┆     ┆ 716 ┆     ┆     ┆     ┆ 21  ┆ 06  ┆ 22  ┆     ┆ 97  ┆     ┆     ┆ 103 ┆     ┆ 683 ┆ 61  ┆     ┆ 118 ┆ 213 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 104 ┆ 252 ┆ 157 ┆ 69  ┆ 41  ┆ 864 ┆     ┆     ┆ 412 ┆ 486 ┆ 556 ┆ 498 ┆ 81  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 53  ┆ 82  ┆ 398 ┆ 31  ┆     ┆ 334 ┆     ┆     ┆ 71  ┆ 9   ┆ 63  ┆ 28  ┆ 24  ┆ 544 ┆ 683 ┆ 06  ┆ 425 ┆ 606 ┆ 683 ┆ 97  ┆ 96  ┆ 49  ┆ 803 ┆ 61  ┆ 586 ┆ 586 ┆ 586 ┆ 586 ┆ 74  ┆ 87  ┆ 803 ┆ 938 ┆ 952 ┆ 488 ┆ 556 ┆ 486 ┆ 49  ┆ 388 ┆ 104 ┆ 41  ┆ 313 ┆ 104 ┆ 69  ┆ 41  ┆ 513 ┆ 504 ┆ 104 ┆ 252 ┆ 484 ┆ 232 ┆ 602 ┆ 06  ┆ 378 ┆ 438 ┆ 703 ┆ 22  ┆ 769 ┆ 354 ┆ 104 ┆ 33  ┆ 9   ┆ 98  ┆ 24  ┆ 06  ┆ 48  ┆ 7   ┆ 687 ┆ 3   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 7   ┆ 1.3 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.6 ┆ 0.1 ┆ 0.1 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.3 ┆ nul ┆ -1. ┆ -1. ┆ 1.4 ┆ nul ┆ 0.5 ┆ 0.7 ┆ -0. ┆ 0.6 ┆ nul ┆ nul ┆ 0.2 ┆ 0.5 ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -1. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -10 ┆ -0. ┆ -0. ┆ nul ┆ 1.1 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 1.0 ┆ nul ┆ 0.8 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ 0.0 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 4.4 ┆ 0.5 ┆ -0. ┆ 1.4 ┆ 94  ┆ 31. ┆ 7   ┆ 76  ┆ -4. ┆ -1. ┆ -1. ┆ -1. ┆ -10 ┆ -0. ┆ -10 ┆ 1.1 ┆ -1. ┆ -0. ┆ -1. ┆ 1.1 ┆ -2. ┆ -0. ┆ -1. ┆ 1.0 ┆ 0.3 ┆ 0.3 ┆ 0.3 ┆ 0.3 ┆ -2. ┆ -1. ┆ -1. ┆ -1. ┆ -1. ┆ -0. ┆ -0. ┆ -0. ┆ -5. ┆ -0. ┆ -1. ┆ 0.0 ┆ -2. ┆ -0. ┆ -1. ┆ -0. ┆ -1. ┆ -0. ┆ -1. ┆ 0.0 ┆ -3. ┆ -0. ┆ -1. ┆ 1.1 ┆ -5. ┆ -0. ┆ -1. ┆ 0.4 ┆ -13 ┆ -2. ┆ -10 ┆ 0.6 ┆ -12 ┆ -3. ┆ -10 ┆ -0. ┆ 1.9 ┆ 0.3 ┆ -0. ┆ 1.4 ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 706 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 769 ┆ 519 ┆ 924 ┆ 521 ┆     ┆     ┆     ┆ 865 ┆ 225 ┆ 582 ┆ l   ┆ 174 ┆ l   ┆ 250 ┆ 682 ┆ 127 ┆ l   ┆ 203 ┆ 441 ┆ 788 ┆ 417 ┆ l   ┆ l   ┆ 272 ┆ 809 ┆ 288 ┆ l   ┆ l   ┆ l   ┆ 512 ┆ 414 ┆ 823 ┆ 082 ┆ 184 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ .83 ┆ 002 ┆ 621 ┆ l   ┆ 728 ┆ l   ┆ l   ┆ 625 ┆ l   ┆ 410 ┆ 630 ┆ l   ┆ 883 ┆ 679 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 065 ┆ 133 ┆ 592 ┆ 052 ┆ 393 ┆ 741 ┆ l   ┆ l   ┆ 281 ┆ 182 ┆ 245 ┆ 302 ┆ 036 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 673 ┆ 584 ┆ 788 ┆ 127 ┆     ┆ 333 ┆     ┆     ┆ 749 ┆ 583 ┆ 823 ┆ 414 ┆ .67 ┆ 711 ┆ .83 ┆ 728 ┆ 487 ┆ 495 ┆ 410 ┆ 728 ┆ 245 ┆ 748 ┆ 682 ┆ 630 ┆ 174 ┆ 174 ┆ 174 ┆ 174 ┆ 932 ┆ 466 ┆ 682 ┆ 250 ┆ 012 ┆ 253 ┆ 302 ┆ 182 ┆ 506 ┆ 611 ┆ 065 ┆ 133 ┆ 188 ┆ 729 ┆ 052 ┆ 393 ┆ 645 ┆ 548 ┆ 065 ┆ 133 ┆ 503 ┆ 269 ┆ 823 ┆ 728 ┆ 663 ┆ 566 ┆ 823 ┆ 679 ┆ .14 ┆ 628 ┆ .83 ┆ 769 ┆ .82 ┆ 205 ┆ .83 ┆ 002 ┆ 124 ┆ 824 ┆ 521 ┆ 127 ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 13  ┆     ┆     ┆     ┆     ┆     ┆ 61  ┆ 84  ┆ 65  ┆ 729 ┆     ┆     ┆     ┆ 307 ┆ 629 ┆ 163 ┆     ┆ 67  ┆     ┆ 016 ┆ 929 ┆ 57  ┆     ┆ 78  ┆ 32  ┆ 658 ┆ 76  ┆     ┆     ┆     ┆ 07  ┆ 79  ┆     ┆     ┆     ┆ 286 ┆ 357 ┆ 322 ┆ 763 ┆ 119 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 520 ┆ 704 ┆ 836 ┆     ┆ 36  ┆     ┆     ┆ 862 ┆     ┆ 017 ┆ 13  ┆     ┆ 55  ┆ 94  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 759 ┆ 22  ┆ 855 ┆ 685 ┆ 726 ┆ 603 ┆     ┆     ┆ 207 ┆ 894 ┆ 565 ┆ 441 ┆ 65  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 71  ┆ 21  ┆ 658 ┆ 57  ┆     ┆ 334 ┆     ┆     ┆ 964 ┆ 321 ┆ 322 ┆ 357 ┆ 063 ┆ 375 ┆ 520 ┆ 36  ┆ 198 ┆ 733 ┆ 017 ┆ 36  ┆ 778 ┆ 593 ┆ 929 ┆ 13  ┆ 67  ┆ 67  ┆ 67  ┆ 67  ┆ 945 ┆ 472 ┆ 929 ┆ 016 ┆ 106 ┆ 027 ┆ 441 ┆ 894 ┆ 405 ┆ 823 ┆ 759 ┆ 22  ┆ 014 ┆ 338 ┆ 685 ┆ 726 ┆ 292 ┆ 431 ┆ 759 ┆ 22  ┆ 667 ┆ 513 ┆ 322 ┆ 36  ┆ 682 ┆ 368 ┆ 322 ┆ 94  ┆ 199 ┆ 399 ┆ 520 ┆ 61  ┆ 198 ┆ 497 ┆ 520 ┆ 704 ┆ 38  ┆ 88  ┆ 729 ┆ 57  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 7   ┆     ┆ 7   ┆     ┆ 6   ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 9   ┆ 2.2 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.0 ┆ 0.1 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -2. ┆ 0.6 ┆ nul ┆ 1.5 ┆ 0.6 ┆ -1. ┆ 0.3 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -3. ┆ -4. ┆ nul ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 1.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ 0.3 ┆ 0.3 ┆ -0. ┆ -0. ┆ 2.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.4 ┆ 0.1 ┆ -1. ┆ 1.5 ┆ 94  ┆ 31. ┆ 7   ┆ 76  ┆ -3. ┆ -1. ┆ -2. ┆ -0. ┆ -9. ┆ -0. ┆ -4. ┆ 1.7 ┆ -3. ┆ -1. ┆ -2. ┆ 0.5 ┆ -1. ┆ -0. ┆ -2. ┆ 1.7 ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -3. ┆ -1. ┆ -2. ┆ -1. ┆ 0.4 ┆ 0.1 ┆ -0. ┆ 0.3 ┆ -4. ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ -0. ┆ -7. ┆ -0. ┆ -3. ┆ 0.5 ┆ -10 ┆ -1. ┆ -4. ┆ 0.2 ┆ -2. ┆ -0. ┆ -1. ┆ 1.0 ┆ -10 ┆ -2. ┆ -4. ┆ -1. ┆ 1.3 ┆ 0.2 ┆ -0. ┆ 1.0 ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 856 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 562 ┆ 872 ┆ 499 ┆ 773 ┆     ┆     ┆     ┆ 675 ┆ 199 ┆ 586 ┆ l   ┆ 814 ┆ l   ┆ 296 ┆ 040 ┆ 395 ┆ l   ┆ 973 ┆ 575 ┆ 350 ┆ 642 ┆ l   ┆ l   ┆ 017 ┆ 317 ┆ 122 ┆ l   ┆ l   ┆ l   ┆ 320 ┆ 958 ┆ 436 ┆ 709 ┆ 245 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 420 ┆ 515 ┆ 677 ┆ l   ┆ 358 ┆ l   ┆ l   ┆ 725 ┆ l   ┆ 294 ┆ 645 ┆ l   ┆ 120 ┆ 063 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 882 ┆ 072 ┆ 617 ┆ 863 ┆ 241 ┆ 709 ┆ l   ┆ l   ┆ 771 ┆ 007 ┆ 106 ┆ 096 ┆ 093 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 510 ┆ 813 ┆ 350 ┆ 973 ┆     ┆ 333 ┆     ┆     ┆ 715 ┆ 238 ┆ 436 ┆ 320 ┆ 970 ┆ 664 ┆ 677 ┆ 645 ┆ 055 ┆ 018 ┆ 294 ┆ 358 ┆ 001 ┆ 333 ┆ 040 ┆ 645 ┆ 814 ┆ 814 ┆ 814 ┆ 814 ┆ 337 ┆ 668 ┆ 040 ┆ 296 ┆ 742 ┆ 185 ┆ 106 ┆ 771 ┆ 849 ┆ 538 ┆ 882 ┆ 072 ┆ 815 ┆ 605 ┆ 863 ┆ 241 ┆ 573 ┆ 524 ┆ 882 ┆ 072 ┆ 046 ┆ 542 ┆ 515 ┆ 358 ┆ .00 ┆ 000 ┆ 677 ┆ 499 ┆ 785 ┆ 557 ┆ 420 ┆ 562 ┆ .97 ┆ 743 ┆ 677 ┆ 362 ┆ 599 ┆ 719 ┆ 773 ┆ 562 ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 98  ┆     ┆     ┆     ┆     ┆     ┆ 85  ┆ 27  ┆ 01  ┆ 05  ┆     ┆     ┆     ┆ 719 ┆ 404 ┆ 798 ┆     ┆ 909 ┆     ┆ 782 ┆ 234 ┆ 89  ┆     ┆ 59  ┆ 14  ┆ 148 ┆ 15  ┆     ┆     ┆ 751 ┆ 361 ┆ 379 ┆     ┆     ┆     ┆ 921 ┆ 09  ┆ 589 ┆ 99  ┆ 239 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 632 ┆ 137 ┆ 76  ┆     ┆ 97  ┆     ┆     ┆ 42  ┆     ┆ 17  ┆ 51  ┆     ┆ 789 ┆ 458 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 604 ┆ 482 ┆ 934 ┆ 23  ┆ 892 ┆ 919 ┆     ┆     ┆ 31  ┆ 24  ┆ 842 ┆ 792 ┆ 52  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 39  ┆ 8   ┆ 148 ┆ 59  ┆     ┆ 334 ┆     ┆     ┆ 6   ┆ 533 ┆ 589 ┆ 921 ┆ 796 ┆ 72  ┆ 76  ┆ 51  ┆ 055 ┆ 352 ┆ 17  ┆ 97  ┆ 103 ┆ 701 ┆ 234 ┆ 51  ┆ 909 ┆ 909 ┆ 909 ┆ 909 ┆ 016 ┆ 508 ┆ 234 ┆ 782 ┆ 21  ┆ 55  ┆ 842 ┆ 31  ┆ 982 ┆ 887 ┆ 604 ┆ 482 ┆ 04  ┆ 013 ┆ 23  ┆ 892 ┆ 021 ┆ 34  ┆ 604 ┆ 482 ┆ 564 ┆ 043 ┆ 137 ┆ 97  ┆ 427 ┆ 428 ┆ 76  ┆ 01  ┆ 9   ┆ 18  ┆ 632 ┆ 85  ┆ 576 ┆ 942 ┆ 76  ┆ 24  ┆ 52  ┆ 9   ┆ 05  ┆ 85  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 9   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 9   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 10  ┆ 0.6 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.1 ┆ 0.2 ┆ 0.3 ┆ -1. ┆ 42  ┆ 5   ┆ 150 ┆ -0. ┆ 3.0 ┆ 0.1 ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -0. ┆ 0.2 ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ nul ┆ nul ┆ 0.4 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.3 ┆ 2.6 ┆ 0.6 ┆ nul ┆ 2.4 ┆ nul ┆ nul ┆ 1.3 ┆ nul ┆ -0. ┆ 2.9 ┆ nul ┆ 3.9 ┆ 1.8 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ 1.0 ┆ -0. ┆ -0. ┆ 4.7 ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -3. ┆ -0. ┆ -2. ┆ 0.4 ┆ 197 ┆ 65. ┆ 5   ┆ 150 ┆ -1. ┆ -0. ┆ -1. ┆ 0.5 ┆ 15. ┆ 1.0 ┆ -1. ┆ 3.9 ┆ -0. ┆ -0. ┆ -1. ┆ 2.4 ┆ 3.2 ┆ 1.0 ┆ -0. ┆ 2.9 ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -2. ┆ -1. ┆ -1. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 7.4 ┆ 0.8 ┆ -0. ┆ 4.7 ┆ 4.8 ┆ 1.6 ┆ -0. ┆ 4.7 ┆ 0.1 ┆ 0.0 ┆ -0. ┆ 1.0 ┆ 17. ┆ 1.3 ┆ -1. ┆ 4.7 ┆ 1.1 ┆ 0.1 ┆ -1. ┆ 1.8 ┆ -0. ┆ -0. ┆ -0. ┆ 1.1 ┆ 2.3 ┆ 0.5 ┆ -1. ┆ 2.6 ┆ 0.6 ┆ 0.1 ┆ -1. ┆ 1.1 ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 906 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 393 ┆ 733 ┆ 065 ┆ 262 ┆     ┆     ┆     ┆ 694 ┆ 040 ┆ 148 ┆ l   ┆ 251 ┆ l   ┆ 902 ┆ 979 ┆ 411 ┆ l   ┆ 392 ┆ 224 ┆ 129 ┆ 855 ┆ l   ┆ l   ┆ 041 ┆ 578 ┆ 057 ┆ l   ┆ l   ┆ l   ┆ 441 ┆ 087 ┆ 500 ┆ 201 ┆ 038 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 820 ┆ 691 ┆ 117 ┆ l   ┆ 134 ┆ l   ┆ l   ┆ 132 ┆ l   ┆ 810 ┆ 390 ┆ l   ┆ 888 ┆ 346 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 697 ┆ 743 ┆ 206 ┆ 530 ┆ 652 ┆ 715 ┆ l   ┆ l   ┆ 226 ┆ 251 ┆ 215 ┆ 296 ┆ 141 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 428 ┆ 428 ┆ 129 ┆ 041 ┆     ┆ 666 ┆     ┆     ┆ 043 ┆ 347 ┆ 500 ┆ 441 ┆ 559 ┆ 373 ┆ 262 ┆ 888 ┆ 298 ┆ 099 ┆ 902 ┆ 134 ┆ 727 ┆ 909 ┆ 979 ┆ 390 ┆ 251 ┆ 251 ┆ 251 ┆ 251 ┆ 881 ┆ 440 ┆ 902 ┆ 979 ┆ 990 ┆ 247 ┆ 296 ┆ 215 ┆ 008 ┆ 223 ┆ 697 ┆ 652 ┆ 061 ┆ 020 ┆ 530 ┆ 652 ┆ 697 ┆ 565 ┆ 697 ┆ 743 ┆ 815 ┆ 704 ┆ 500 ┆ 652 ┆ 333 ┆ 133 ┆ 500 ┆ 346 ┆ 400 ┆ 080 ┆ 697 ┆ 393 ┆ 006 ┆ 751 ┆ 362 ┆ 691 ┆ 981 ┆ 396 ┆ 262 ┆ 393 ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 06  ┆     ┆     ┆     ┆     ┆     ┆ 66  ┆ 28  ┆ 49  ┆ 223 ┆     ┆     ┆     ┆ 008 ┆ 91  ┆ 09  ┆     ┆ 882 ┆     ┆ 009 ┆ 447 ┆ 65  ┆     ┆ 359 ┆ 699 ┆ 397 ┆ 287 ┆     ┆     ┆ 42  ┆ 156 ┆ 02  ┆     ┆     ┆     ┆ 38  ┆ 091 ┆ 147 ┆ 288 ┆ 042 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 74  ┆ 35  ┆ 11  ┆     ┆ 15  ┆     ┆     ┆ 03  ┆     ┆ 125 ┆ 22  ┆     ┆ 01  ┆ 61  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 595 ┆ 09  ┆ 929 ┆ 602 ┆ 15  ┆ 54  ┆     ┆     ┆ 891 ┆ 412 ┆ 522 ┆ 244 ┆ 37  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 889 ┆ 611 ┆ 397 ┆ 42  ┆     ┆ 664 ┆     ┆     ┆ 1   ┆ 7   ┆ 147 ┆ 38  ┆ 587 ┆ 06  ┆ 223 ┆ 01  ┆ 719 ┆ 573 ┆ 009 ┆ 15  ┆ 79  ┆ 26  ┆ 447 ┆ 22  ┆ 882 ┆ 882 ┆ 882 ┆ 882 ┆ 456 ┆ 728 ┆ 009 ┆ 447 ┆ 069 ┆ 517 ┆ 244 ┆ 522 ┆ 44  ┆ 16  ┆ 595 ┆ 15  ┆ 67  ┆ 56  ┆ 602 ┆ 15  ┆ 85  ┆ 95  ┆ 595 ┆ 09  ┆ 304 ┆ 08  ┆ 147 ┆ 15  ┆ 51  ┆ 35  ┆ 147 ┆ 61  ┆ 764 ┆ 153 ┆ 595 ┆ 66  ┆ 8   ┆ 7   ┆ 24  ┆ 35  ┆ 85  ┆ 37  ┆ 223 ┆ 66  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 14  ┆ 0.4 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.9 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ 44  ┆ 3   ┆ 16  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.6 ┆ nul ┆ -1. ┆ -1. ┆ -0. ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ -1. ┆ nul ┆ nul ┆ 0.0 ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -2. ┆ -2. ┆ -3. ┆ nul ┆ 1.2 ┆ nul ┆ nul ┆ 0.4 ┆ nul ┆ -0. ┆ 2.8 ┆ nul ┆ 1.3 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ 3.6 ┆ 2.7 ┆ 2.6 ┆ 3.4 ┆ -3. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -4. ┆ -0. ┆ -1. ┆ 0.0 ┆ 63  ┆ 21. ┆ 3   ┆ 44  ┆ -3. ┆ -1. ┆ -2. ┆ -0. ┆ -2. ┆ -0. ┆ -3. ┆ 2.8 ┆ -1. ┆ -0. ┆ -1. ┆ 1.2 ┆ 1.7 ┆ 0.5 ┆ -1. ┆ 2.8 ┆ 0.6 ┆ 0.6 ┆ 0.6 ┆ 0.6 ┆ -3. ┆ -1. ┆ -1. ┆ -1. ┆ 12. ┆ 3.1 ┆ 2.6 ┆ 3.6 ┆ -4. ┆ -0. ┆ -1. ┆ 0.0 ┆ -1. ┆ -0. ┆ -1. ┆ 0.0 ┆ -1. ┆ -0. ┆ -0. ┆ -0. ┆ 5.3 ┆ 0.4 ┆ -2. ┆ 3.6 ┆ -2. ┆ -0. ┆ -3. ┆ 3.4 ┆ -4. ┆ -0. ┆ -2. ┆ 0.9 ┆ -9. ┆ -2. ┆ -3. ┆ -1. ┆ 0.7 ┆ 0.1 ┆ -0. ┆ 0.9 ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 405 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 552 ┆ 624 ┆ 444 ┆ 613 ┆     ┆     ┆     ┆ 947 ┆ 030 ┆ 502 ┆ l   ┆ 460 ┆ l   ┆ 844 ┆ 586 ┆ 182 ┆ l   ┆ 969 ┆ 673 ┆ 282 ┆ 399 ┆ l   ┆ l   ┆ 438 ┆ 320 ┆ 031 ┆ l   ┆ l   ┆ l   ┆ 088 ┆ 995 ┆ 635 ┆ 196 ┆ 618 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 014 ┆ 321 ┆ 711 ┆ l   ┆ 539 ┆ l   ┆ l   ┆ 761 ┆ l   ┆ 771 ┆ 434 ┆ l   ┆ 798 ┆ 118 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 948 ┆ 136 ┆ 447 ┆ 141 ┆ 996 ┆ 661 ┆ l   ┆ l   ┆ 780 ┆ 935 ┆ 182 ┆ 181 ┆ 572 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 815 ┆ 601 ┆ 399 ┆ 438 ┆     ┆ 0   ┆     ┆     ┆ 718 ┆ 239 ┆ 635 ┆ 088 ┆ 320 ┆ 154 ┆ 711 ┆ 434 ┆ 362 ┆ 454 ┆ 844 ┆ 539 ┆ 330 ┆ 776 ┆ 586 ┆ 434 ┆ 460 ┆ 460 ┆ 460 ┆ 460 ┆ 431 ┆ 715 ┆ 844 ┆ 586 ┆ 508 ┆ 270 ┆ 182 ┆ 780 ┆ 716 ┆ 524 ┆ 141 ┆ 996 ┆ 704 ┆ 568 ┆ 141 ┆ 996 ┆ 533 ┆ 511 ┆ 948 ┆ 136 ┆ 780 ┆ 136 ┆ 635 ┆ 780 ┆ 160 ┆ 216 ┆ 711 ┆ 181 ┆ 097 ┆ 819 ┆ 014 ┆ 552 ┆ 409 ┆ 352 ┆ 711 ┆ 362 ┆ 662 ┆ 532 ┆ 613 ┆ 552 ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   ┆     ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆ 04  ┆ 57  ┆ 813 ┆     ┆     ┆     ┆ 351 ┆ 018 ┆ 379 ┆     ┆ 86  ┆     ┆ 685 ┆ 56  ┆ 024 ┆     ┆ 949 ┆ 813 ┆ 132 ┆ 894 ┆     ┆     ┆ 15  ┆ 225 ┆ 713 ┆     ┆     ┆     ┆ 42  ┆ 003 ┆ 336 ┆ 461 ┆ 719 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 6   ┆ 076 ┆ 265 ┆     ┆ 02  ┆     ┆     ┆ 95  ┆     ┆ 732 ┆ 21  ┆     ┆ 15  ┆ 27  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 601 ┆ 814 ┆ 704 ┆ 761 ┆ 31  ┆ 928 ┆     ┆     ┆ 76  ┆ 81  ┆ 5   ┆ 33  ┆ 82  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 935 ┆ 992 ┆ 894 ┆ 15  ┆     ┆     ┆     ┆     ┆ 76  ┆ 586 ┆ 336 ┆ 42  ┆ 445 ┆ 696 ┆ 265 ┆ 21  ┆ 515 ┆ 172 ┆ 685 ┆ 02  ┆ 56  ┆ 85  ┆ 56  ┆ 21  ┆ 86  ┆ 86  ┆ 86  ┆ 86  ┆ 245 ┆ 623 ┆ 685 ┆ 56  ┆ 041 ┆ 1   ┆ 5   ┆ 76  ┆ 927 ┆ 103 ┆ 761 ┆ 31  ┆ 059 ┆ 02  ┆ 761 ┆ 31  ┆ 119 ┆ 04  ┆ 601 ┆ 814 ┆ 25  ┆ 94  ┆ 336 ┆ 76  ┆ 948 ┆ 095 ┆ 265 ┆ 33  ┆ 114 ┆ 423 ┆ 6   ┆     ┆ 181 ┆ 295 ┆ 265 ┆ 24  ┆ 24  ┆ 45  ┆ 813 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = create_responders_tag_features(train_df)\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3834f8e8-0f10-4891-a325-5d288f99b503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.672483076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.estimated_size() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be3ffe03-76cd-4ee5-bf7c-940de4646a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = path + 'my_folder/models/20250105_10/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e04716-a5a1-471c-b452-0a8b5f7a7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_online_learning(train_data):\n",
    "    weights = train_data['weight'].to_pandas()\n",
    "    y = train_data['responder_6'].to_pandas()\n",
    "\n",
    "    unique_date_ids = train_data['date_id'].unique()    \n",
    "    train_date_id_cut = 1300\n",
    "\n",
    "    print('max date:', unique_date_ids.max())\n",
    "    print('date id cut:', train_date_id_cut)\n",
    "\n",
    "    X_train = train_data.filter(pl.col('date_id') <= train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()#.sample(frac=0.01)\n",
    "    X_val = train_data.filter(pl.col('date_id') > train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "\n",
    "    print(X_train.shape[0] / train_data.shape[0])\n",
    "\n",
    "    y_train = y.loc[X_train.index]\n",
    "    y_val = y[-X_val.shape[0]:]\n",
    "\n",
    "    weights_train = weights.loc[X_train.index]\n",
    "    weights_val = weights[-X_val.shape[0]:]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    display(X_train.head())\n",
    "    display(X_train.tail())    \n",
    "\n",
    "    #train_dataset = lgb.Dataset(data=X_train, label=y_train, weight=weights_train)\n",
    "    #val_dataset = lgb.Dataset(data=X_val, label=y_val, weight=weights_val)\n",
    "\n",
    "    base_params = {\n",
    "        'verbosity': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'device': 'gpu',\n",
    "        'early_stopping_round': 30,\n",
    "        'lambda_l2': 100,\n",
    "        #'metric': 'r2',\n",
    "        #'seed': 42\n",
    "    }\n",
    "\n",
    "    '''model = lgb.train(\n",
    "        params=base_params,\n",
    "        train_set=train_dataset,\n",
    "        num_boost_round=90\n",
    "    )'''\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=90000\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)])#, init_model=current_model)\n",
    "    #model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "    best_iteration = model.best_iteration_\n",
    "    print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "    plt.figure()\n",
    "    lgb.plot_metric(model)\n",
    "    plt.ylim(0, 2)\n",
    "    plt.show()\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "\n",
    "    print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "    return model\n",
    "\n",
    "    sample_val = X_val.sample(frac=0.01)\n",
    "    sample_y = y_val.iloc[sample_val.index]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X=sample_val, y=sample_y)\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "    return model, shap_importance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    val_date_ids = sorted(train_data.filter(pl.col('date_id') > train_date_id_cut)['date_id'].unique())\n",
    "    \n",
    "    for date_id_v in val_date_ids:\n",
    "        for time_id_v in sorted(train_data.filter(pl.col('date_id') == date_id_v)['time_id'].unique()):\n",
    "            time_id_df = train_data.filter((pl.col('date_id') == date_id_v) & (pl.col('time_id') == time_id_v))\n",
    "\n",
    "            print(time_id_df.shape)\n",
    "            display(time_id_df)\n",
    "\n",
    "            time_id_X_train = time_id_df.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "            time_id_y_train = time_id_df['responder_6'].to_pandas()\n",
    "            time_id_weights_train = time_id_df['weight'].to_pandas()\n",
    "\n",
    "            val_data_df = train_data.filter(pl.col('date_id') >= date_id_v)[time_id_df.shape[0]:]\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return\n",
    "    \n",
    "    '''weights = train_data['weight']\n",
    "    y = train_data['responder_6']\n",
    "    \n",
    "    unique_date_ids = train_data['date_id'].unique()\n",
    "    train_date_id_cut = int(unique_date_ids.max() - 10)\n",
    "\n",
    "    print('max date:', unique_date_ids.max())\n",
    "    print('date id cut:', train_date_id_cut)\n",
    "    \n",
    "    X_train = train_data.filter(pl.col('date_id') <= train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "    X_val = train_data.filter(pl.col('date_id') > train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "\n",
    "    print(X_train.shape[0] / train_data.shape[0])\n",
    "    \n",
    "    y_train = y[:X_train.shape[0]].to_pandas()\n",
    "    y_val = y[X_train.shape[0]:].to_pandas()\n",
    "    \n",
    "    weights_train = weights[:X_train.shape[0]].to_pandas()\n",
    "    weights_val = weights[X_train.shape[0]:].to_pandas()\n",
    "\n",
    "    print(X_train.shape)\n",
    "    display(X_train.head())\n",
    "\n",
    "    base_params = {\n",
    "        'verbosity': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'device': 'gpu',\n",
    "        'early_stopping_round': 30,\n",
    "        'lambda_l2': 100\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=100000\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=50)])#, categorical_feature=['symbol_id'])\n",
    "\n",
    "    best_iteration = model.best_iteration_\n",
    "    print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "\n",
    "    plt.figure()\n",
    "    lgb.plot_metric(model)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()    \n",
    "\n",
    "    if not os.path.exists(models_path):\n",
    "        os.makedirs(models_path)\n",
    "\n",
    "    with open(models_path + \"lgb_model.pkl\", 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "    sample_val = X_val.sample(frac=0.001)\n",
    "    sample_y = y_val.loc[sample_val.index]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X=sample_val, y=sample_y)\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "    del X_train, y_train, X_val, y_val, weights_train, weights_val\n",
    "    gc.collect()\n",
    "\n",
    "    # Retraining on the full dataset using best_iteration\n",
    "    X_full = train_data.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "    y_full = y.to_pandas()\n",
    "    weights_full = weights.to_pandas()\n",
    "\n",
    "    base_params.pop('early_stopping_round')\n",
    "\n",
    "    model_full = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=best_iteration\n",
    "    )\n",
    "    \n",
    "    model_full.fit(X_full, y_full, sample_weight=weights_full)\n",
    "\n",
    "    with open(models_path + \"lgb_model_full.pkl\", 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    print(\"Retraining complete. Model saved as 'lgb_model_full.pkl'.\")\n",
    "\n",
    "    return shap_importance'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f11640b-066f-4b04-9b5d-344b1c861b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max date: 1698\n",
      "date id cut: 1300\n",
      "0.6895364639521969\n",
      "(32496018, 176)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>feature_07</th>\n",
       "      <th>feature_08</th>\n",
       "      <th>feature_09</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>feature_51</th>\n",
       "      <th>feature_52</th>\n",
       "      <th>feature_53</th>\n",
       "      <th>feature_54</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>feature_63</th>\n",
       "      <th>feature_64</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_0_lag_1</th>\n",
       "      <th>responder_1_lag_1</th>\n",
       "      <th>responder_2_lag_1</th>\n",
       "      <th>responder_3_lag_1</th>\n",
       "      <th>responder_4_lag_1</th>\n",
       "      <th>responder_5_lag_1</th>\n",
       "      <th>responder_6_lag_1</th>\n",
       "      <th>responder_7_lag_1</th>\n",
       "      <th>responder_8_lag_1</th>\n",
       "      <th>feature_tag_0_sum</th>\n",
       "      <th>feature_tag_0_mean</th>\n",
       "      <th>feature_tag_0_min</th>\n",
       "      <th>feature_tag_0_max</th>\n",
       "      <th>feature_tag_1_sum</th>\n",
       "      <th>feature_tag_1_mean</th>\n",
       "      <th>feature_tag_1_min</th>\n",
       "      <th>feature_tag_1_max</th>\n",
       "      <th>feature_tag_2_sum</th>\n",
       "      <th>feature_tag_2_mean</th>\n",
       "      <th>feature_tag_2_min</th>\n",
       "      <th>feature_tag_2_max</th>\n",
       "      <th>feature_tag_3_sum</th>\n",
       "      <th>feature_tag_3_mean</th>\n",
       "      <th>feature_tag_3_min</th>\n",
       "      <th>feature_tag_3_max</th>\n",
       "      <th>feature_tag_4_sum</th>\n",
       "      <th>feature_tag_4_mean</th>\n",
       "      <th>feature_tag_4_min</th>\n",
       "      <th>feature_tag_4_max</th>\n",
       "      <th>feature_tag_5_sum</th>\n",
       "      <th>feature_tag_5_mean</th>\n",
       "      <th>feature_tag_5_min</th>\n",
       "      <th>feature_tag_5_max</th>\n",
       "      <th>feature_tag_6_sum</th>\n",
       "      <th>feature_tag_6_mean</th>\n",
       "      <th>feature_tag_6_min</th>\n",
       "      <th>feature_tag_6_max</th>\n",
       "      <th>feature_tag_7_sum</th>\n",
       "      <th>feature_tag_7_mean</th>\n",
       "      <th>feature_tag_7_min</th>\n",
       "      <th>feature_tag_7_max</th>\n",
       "      <th>feature_tag_8_sum</th>\n",
       "      <th>feature_tag_8_mean</th>\n",
       "      <th>feature_tag_8_min</th>\n",
       "      <th>feature_tag_8_max</th>\n",
       "      <th>feature_tag_9_sum</th>\n",
       "      <th>feature_tag_9_mean</th>\n",
       "      <th>feature_tag_9_min</th>\n",
       "      <th>feature_tag_9_max</th>\n",
       "      <th>feature_tag_10_sum</th>\n",
       "      <th>feature_tag_10_mean</th>\n",
       "      <th>feature_tag_10_min</th>\n",
       "      <th>feature_tag_10_max</th>\n",
       "      <th>feature_tag_11_sum</th>\n",
       "      <th>feature_tag_11_mean</th>\n",
       "      <th>feature_tag_11_min</th>\n",
       "      <th>feature_tag_11_max</th>\n",
       "      <th>feature_tag_12_sum</th>\n",
       "      <th>feature_tag_12_mean</th>\n",
       "      <th>feature_tag_12_min</th>\n",
       "      <th>feature_tag_12_max</th>\n",
       "      <th>feature_tag_13_sum</th>\n",
       "      <th>feature_tag_13_mean</th>\n",
       "      <th>feature_tag_13_min</th>\n",
       "      <th>feature_tag_13_max</th>\n",
       "      <th>feature_tag_14_sum</th>\n",
       "      <th>feature_tag_14_mean</th>\n",
       "      <th>feature_tag_14_min</th>\n",
       "      <th>feature_tag_14_max</th>\n",
       "      <th>feature_tag_15_sum</th>\n",
       "      <th>feature_tag_15_mean</th>\n",
       "      <th>feature_tag_15_min</th>\n",
       "      <th>feature_tag_15_max</th>\n",
       "      <th>feature_tag_16_sum</th>\n",
       "      <th>feature_tag_16_mean</th>\n",
       "      <th>feature_tag_16_min</th>\n",
       "      <th>feature_tag_16_max</th>\n",
       "      <th>responder_tag_0_sum</th>\n",
       "      <th>responder_tag_0_mean</th>\n",
       "      <th>responder_tag_0_min</th>\n",
       "      <th>responder_tag_0_max</th>\n",
       "      <th>responder_tag_1_sum</th>\n",
       "      <th>responder_tag_1_mean</th>\n",
       "      <th>responder_tag_1_min</th>\n",
       "      <th>responder_tag_1_max</th>\n",
       "      <th>responder_tag_2_sum</th>\n",
       "      <th>responder_tag_2_mean</th>\n",
       "      <th>responder_tag_2_min</th>\n",
       "      <th>responder_tag_2_max</th>\n",
       "      <th>responder_tag_3_sum</th>\n",
       "      <th>responder_tag_3_mean</th>\n",
       "      <th>responder_tag_3_min</th>\n",
       "      <th>responder_tag_3_max</th>\n",
       "      <th>responder_tag_4_sum</th>\n",
       "      <th>responder_tag_4_mean</th>\n",
       "      <th>responder_tag_4_min</th>\n",
       "      <th>responder_tag_4_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851033</td>\n",
       "      <td>0.242971</td>\n",
       "      <td>0.263400</td>\n",
       "      <td>-0.891687</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.883028</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>-0.744703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.169586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.335938</td>\n",
       "      <td>-1.707803</td>\n",
       "      <td>0.910130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.636431</td>\n",
       "      <td>1.522133</td>\n",
       "      <td>-1.551398</td>\n",
       "      <td>-0.229627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.378301</td>\n",
       "      <td>-0.283712</td>\n",
       "      <td>0.123196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.281180</td>\n",
       "      <td>0.269163</td>\n",
       "      <td>0.349028</td>\n",
       "      <td>-0.012596</td>\n",
       "      <td>-0.225932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.073602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.181716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.564021</td>\n",
       "      <td>2.088506</td>\n",
       "      <td>0.832022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.808103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.037683</td>\n",
       "      <td>0.727661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.989118</td>\n",
       "      <td>-0.345213</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.251104</td>\n",
       "      <td>-0.110252</td>\n",
       "      <td>-0.491157</td>\n",
       "      <td>-1.022690</td>\n",
       "      <td>0.152241</td>\n",
       "      <td>-0.659864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.261412</td>\n",
       "      <td>-0.211486</td>\n",
       "      <td>-0.335556</td>\n",
       "      <td>-0.281498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.505453</td>\n",
       "      <td>0.438182</td>\n",
       "      <td>-1.551398</td>\n",
       "      <td>1.636431</td>\n",
       "      <td>94</td>\n",
       "      <td>31.333334</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>0.899371</td>\n",
       "      <td>0.299790</td>\n",
       "      <td>0.269163</td>\n",
       "      <td>0.349028</td>\n",
       "      <td>-0.791240</td>\n",
       "      <td>-0.046544</td>\n",
       "      <td>-2.037683</td>\n",
       "      <td>2.088506</td>\n",
       "      <td>-4.242425</td>\n",
       "      <td>-1.060606</td>\n",
       "      <td>-2.037683</td>\n",
       "      <td>0.204797</td>\n",
       "      <td>-1.969960</td>\n",
       "      <td>-0.492490</td>\n",
       "      <td>-1.707803</td>\n",
       "      <td>0.727661</td>\n",
       "      <td>-0.169586</td>\n",
       "      <td>-0.169586</td>\n",
       "      <td>-0.169586</td>\n",
       "      <td>-0.169586</td>\n",
       "      <td>-3.043740</td>\n",
       "      <td>-1.521870</td>\n",
       "      <td>-1.707803</td>\n",
       "      <td>-1.335938</td>\n",
       "      <td>-1.089952</td>\n",
       "      <td>-0.272488</td>\n",
       "      <td>-0.335556</td>\n",
       "      <td>-0.211486</td>\n",
       "      <td>-5.007490</td>\n",
       "      <td>-0.556388</td>\n",
       "      <td>-1.251104</td>\n",
       "      <td>0.152241</td>\n",
       "      <td>-1.530313</td>\n",
       "      <td>-0.510104</td>\n",
       "      <td>-1.022690</td>\n",
       "      <td>0.152241</td>\n",
       "      <td>-1.852513</td>\n",
       "      <td>-0.617504</td>\n",
       "      <td>-1.251104</td>\n",
       "      <td>-0.110252</td>\n",
       "      <td>-0.483484</td>\n",
       "      <td>-0.032232</td>\n",
       "      <td>-1.073602</td>\n",
       "      <td>2.088506</td>\n",
       "      <td>-1.144378</td>\n",
       "      <td>-0.114438</td>\n",
       "      <td>-0.744703</td>\n",
       "      <td>0.832022</td>\n",
       "      <td>-1.741769</td>\n",
       "      <td>-0.348354</td>\n",
       "      <td>-1.251104</td>\n",
       "      <td>0.851033</td>\n",
       "      <td>0.866990</td>\n",
       "      <td>0.144498</td>\n",
       "      <td>-1.362240</td>\n",
       "      <td>2.088506</td>\n",
       "      <td>1.375848</td>\n",
       "      <td>0.275170</td>\n",
       "      <td>-0.891687</td>\n",
       "      <td>0.910130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676961</td>\n",
       "      <td>0.151984</td>\n",
       "      <td>0.192465</td>\n",
       "      <td>-0.521729</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.865307</td>\n",
       "      <td>-0.225629</td>\n",
       "      <td>-0.582163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.250016</td>\n",
       "      <td>-1.682929</td>\n",
       "      <td>1.412757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520378</td>\n",
       "      <td>0.744132</td>\n",
       "      <td>-0.788658</td>\n",
       "      <td>0.641776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227200</td>\n",
       "      <td>0.580907</td>\n",
       "      <td>1.128879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.512286</td>\n",
       "      <td>-1.414357</td>\n",
       "      <td>-1.823322</td>\n",
       "      <td>-0.082763</td>\n",
       "      <td>-0.184119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.835207</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.621836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.172836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.625862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.410017</td>\n",
       "      <td>1.063013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888355</td>\n",
       "      <td>0.467994</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.065759</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.592855</td>\n",
       "      <td>-1.052685</td>\n",
       "      <td>-0.393726</td>\n",
       "      <td>-0.741603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.281207</td>\n",
       "      <td>-0.182894</td>\n",
       "      <td>-0.245565</td>\n",
       "      <td>-0.302441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.467371</td>\n",
       "      <td>0.558421</td>\n",
       "      <td>-0.788658</td>\n",
       "      <td>1.412757</td>\n",
       "      <td>94</td>\n",
       "      <td>31.333334</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-4.749964</td>\n",
       "      <td>-1.583321</td>\n",
       "      <td>-1.823322</td>\n",
       "      <td>-1.414357</td>\n",
       "      <td>-10.670630</td>\n",
       "      <td>-0.711375</td>\n",
       "      <td>-10.835207</td>\n",
       "      <td>1.172836</td>\n",
       "      <td>-1.487198</td>\n",
       "      <td>-0.495733</td>\n",
       "      <td>-1.410017</td>\n",
       "      <td>1.172836</td>\n",
       "      <td>-2.245778</td>\n",
       "      <td>-0.748593</td>\n",
       "      <td>-1.682929</td>\n",
       "      <td>1.063013</td>\n",
       "      <td>0.317467</td>\n",
       "      <td>0.317467</td>\n",
       "      <td>0.317467</td>\n",
       "      <td>0.317467</td>\n",
       "      <td>-2.932945</td>\n",
       "      <td>-1.466472</td>\n",
       "      <td>-1.682929</td>\n",
       "      <td>-1.250016</td>\n",
       "      <td>-1.012106</td>\n",
       "      <td>-0.253027</td>\n",
       "      <td>-0.302441</td>\n",
       "      <td>-0.182894</td>\n",
       "      <td>-5.506405</td>\n",
       "      <td>-0.611823</td>\n",
       "      <td>-1.065759</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-2.188014</td>\n",
       "      <td>-0.729338</td>\n",
       "      <td>-1.052685</td>\n",
       "      <td>-0.393726</td>\n",
       "      <td>-1.645292</td>\n",
       "      <td>-0.548431</td>\n",
       "      <td>-1.065759</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-3.503667</td>\n",
       "      <td>-0.269513</td>\n",
       "      <td>-1.823322</td>\n",
       "      <td>1.172836</td>\n",
       "      <td>-5.663682</td>\n",
       "      <td>-0.566368</td>\n",
       "      <td>-1.823322</td>\n",
       "      <td>0.467994</td>\n",
       "      <td>-13.141997</td>\n",
       "      <td>-2.628399</td>\n",
       "      <td>-10.835207</td>\n",
       "      <td>0.676961</td>\n",
       "      <td>-12.821986</td>\n",
       "      <td>-3.205497</td>\n",
       "      <td>-10.835207</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>1.912438</td>\n",
       "      <td>0.382488</td>\n",
       "      <td>-0.521729</td>\n",
       "      <td>1.412757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.056285</td>\n",
       "      <td>0.187227</td>\n",
       "      <td>0.249901</td>\n",
       "      <td>-0.773050</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-0.675719</td>\n",
       "      <td>-0.199404</td>\n",
       "      <td>-0.586798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.814909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.296782</td>\n",
       "      <td>-2.040234</td>\n",
       "      <td>0.639589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.597359</td>\n",
       "      <td>0.657514</td>\n",
       "      <td>-1.350148</td>\n",
       "      <td>0.364215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017751</td>\n",
       "      <td>-0.317361</td>\n",
       "      <td>-0.122379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.320921</td>\n",
       "      <td>-0.958090</td>\n",
       "      <td>-2.436589</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>-0.245239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.420632</td>\n",
       "      <td>-3.515137</td>\n",
       "      <td>-4.677760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.725420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.294170</td>\n",
       "      <td>1.764551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.120789</td>\n",
       "      <td>-0.063458</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.882604</td>\n",
       "      <td>-0.072482</td>\n",
       "      <td>-0.617934</td>\n",
       "      <td>-0.863230</td>\n",
       "      <td>-0.241892</td>\n",
       "      <td>-0.709919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.300724</td>\n",
       "      <td>-0.106842</td>\n",
       "      <td>-0.096792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.451039</td>\n",
       "      <td>0.181380</td>\n",
       "      <td>-1.350148</td>\n",
       "      <td>1.597359</td>\n",
       "      <td>94</td>\n",
       "      <td>31.333334</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-3.715600</td>\n",
       "      <td>-1.238533</td>\n",
       "      <td>-2.436589</td>\n",
       "      <td>-0.320921</td>\n",
       "      <td>-9.970796</td>\n",
       "      <td>-0.664720</td>\n",
       "      <td>-4.677760</td>\n",
       "      <td>1.764551</td>\n",
       "      <td>-3.055055</td>\n",
       "      <td>-1.018352</td>\n",
       "      <td>-2.294170</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>-1.001103</td>\n",
       "      <td>-0.333701</td>\n",
       "      <td>-2.040234</td>\n",
       "      <td>1.764551</td>\n",
       "      <td>-0.814909</td>\n",
       "      <td>-0.814909</td>\n",
       "      <td>-0.814909</td>\n",
       "      <td>-0.814909</td>\n",
       "      <td>-3.337016</td>\n",
       "      <td>-1.668508</td>\n",
       "      <td>-2.040234</td>\n",
       "      <td>-1.296782</td>\n",
       "      <td>0.474221</td>\n",
       "      <td>0.118555</td>\n",
       "      <td>-0.106842</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>-4.849982</td>\n",
       "      <td>-0.538887</td>\n",
       "      <td>-0.882604</td>\n",
       "      <td>-0.072482</td>\n",
       "      <td>-1.815040</td>\n",
       "      <td>-0.605013</td>\n",
       "      <td>-0.863230</td>\n",
       "      <td>-0.241892</td>\n",
       "      <td>-1.573021</td>\n",
       "      <td>-0.524340</td>\n",
       "      <td>-0.882604</td>\n",
       "      <td>-0.072482</td>\n",
       "      <td>-7.046564</td>\n",
       "      <td>-0.542043</td>\n",
       "      <td>-3.515137</td>\n",
       "      <td>0.535897</td>\n",
       "      <td>-10.004279</td>\n",
       "      <td>-1.000428</td>\n",
       "      <td>-4.677760</td>\n",
       "      <td>0.249901</td>\n",
       "      <td>-2.785900</td>\n",
       "      <td>-0.557180</td>\n",
       "      <td>-1.420632</td>\n",
       "      <td>1.056285</td>\n",
       "      <td>-10.975769</td>\n",
       "      <td>-2.743942</td>\n",
       "      <td>-4.677760</td>\n",
       "      <td>-1.362240</td>\n",
       "      <td>1.359952</td>\n",
       "      <td>0.271990</td>\n",
       "      <td>-0.773050</td>\n",
       "      <td>1.056285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.139366</td>\n",
       "      <td>0.273328</td>\n",
       "      <td>0.306549</td>\n",
       "      <td>-1.262223</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.694008</td>\n",
       "      <td>3.004091</td>\n",
       "      <td>0.114809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.251882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.902009</td>\n",
       "      <td>-0.979447</td>\n",
       "      <td>0.241165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.392359</td>\n",
       "      <td>-0.224699</td>\n",
       "      <td>-2.129397</td>\n",
       "      <td>-0.855287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404142</td>\n",
       "      <td>-0.578156</td>\n",
       "      <td>0.105702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.544138</td>\n",
       "      <td>-0.087091</td>\n",
       "      <td>-1.500147</td>\n",
       "      <td>-0.201288</td>\n",
       "      <td>-0.038042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382074</td>\n",
       "      <td>2.669135</td>\n",
       "      <td>0.611711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.413415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.313203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.810125</td>\n",
       "      <td>2.939022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.988801</td>\n",
       "      <td>1.834661</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.697595</td>\n",
       "      <td>1.074309</td>\n",
       "      <td>-0.206929</td>\n",
       "      <td>-0.530602</td>\n",
       "      <td>4.765215</td>\n",
       "      <td>0.571554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.226891</td>\n",
       "      <td>-0.251412</td>\n",
       "      <td>-0.215522</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.428889</td>\n",
       "      <td>-0.428611</td>\n",
       "      <td>-2.129397</td>\n",
       "      <td>0.404142</td>\n",
       "      <td>197</td>\n",
       "      <td>65.666664</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>-1.043100</td>\n",
       "      <td>-0.347700</td>\n",
       "      <td>-1.500147</td>\n",
       "      <td>0.544138</td>\n",
       "      <td>15.559587</td>\n",
       "      <td>1.037306</td>\n",
       "      <td>-1.262223</td>\n",
       "      <td>3.988801</td>\n",
       "      <td>-0.298719</td>\n",
       "      <td>-0.099573</td>\n",
       "      <td>-1.902009</td>\n",
       "      <td>2.413415</td>\n",
       "      <td>3.272779</td>\n",
       "      <td>1.090926</td>\n",
       "      <td>-0.979447</td>\n",
       "      <td>2.939022</td>\n",
       "      <td>-0.251882</td>\n",
       "      <td>-0.251882</td>\n",
       "      <td>-0.251882</td>\n",
       "      <td>-0.251882</td>\n",
       "      <td>-2.881456</td>\n",
       "      <td>-1.440728</td>\n",
       "      <td>-1.902009</td>\n",
       "      <td>-0.979447</td>\n",
       "      <td>-0.990069</td>\n",
       "      <td>-0.247517</td>\n",
       "      <td>-0.296244</td>\n",
       "      <td>-0.215522</td>\n",
       "      <td>7.400844</td>\n",
       "      <td>0.822316</td>\n",
       "      <td>-0.697595</td>\n",
       "      <td>4.765215</td>\n",
       "      <td>4.806167</td>\n",
       "      <td>1.602056</td>\n",
       "      <td>-0.530602</td>\n",
       "      <td>4.765215</td>\n",
       "      <td>0.169785</td>\n",
       "      <td>0.056595</td>\n",
       "      <td>-0.697595</td>\n",
       "      <td>1.074309</td>\n",
       "      <td>17.815304</td>\n",
       "      <td>1.370408</td>\n",
       "      <td>-1.500147</td>\n",
       "      <td>4.765215</td>\n",
       "      <td>1.133351</td>\n",
       "      <td>0.113335</td>\n",
       "      <td>-1.500147</td>\n",
       "      <td>1.834661</td>\n",
       "      <td>-0.400764</td>\n",
       "      <td>-0.080153</td>\n",
       "      <td>-0.697595</td>\n",
       "      <td>1.139366</td>\n",
       "      <td>2.300680</td>\n",
       "      <td>0.575170</td>\n",
       "      <td>-1.362240</td>\n",
       "      <td>2.669135</td>\n",
       "      <td>0.698185</td>\n",
       "      <td>0.139637</td>\n",
       "      <td>-1.262223</td>\n",
       "      <td>1.139366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>0.262404</td>\n",
       "      <td>0.344457</td>\n",
       "      <td>-0.613813</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.947351</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>-0.502379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.844685</td>\n",
       "      <td>-1.586560</td>\n",
       "      <td>-0.182024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.969949</td>\n",
       "      <td>-0.673813</td>\n",
       "      <td>-1.282132</td>\n",
       "      <td>-1.399894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043815</td>\n",
       "      <td>-0.320225</td>\n",
       "      <td>-0.031713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.088420</td>\n",
       "      <td>-0.995003</td>\n",
       "      <td>-2.635336</td>\n",
       "      <td>-0.196461</td>\n",
       "      <td>-0.618719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.014600</td>\n",
       "      <td>-2.321076</td>\n",
       "      <td>-3.711265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.253902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.771732</td>\n",
       "      <td>2.843421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.379815</td>\n",
       "      <td>0.411827</td>\n",
       "      <td>-1.36224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.948601</td>\n",
       "      <td>-0.136814</td>\n",
       "      <td>-0.447704</td>\n",
       "      <td>-1.141761</td>\n",
       "      <td>0.099631</td>\n",
       "      <td>-0.661928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.678076</td>\n",
       "      <td>2.793581</td>\n",
       "      <td>2.618250</td>\n",
       "      <td>3.418133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.815935</td>\n",
       "      <td>-0.601992</td>\n",
       "      <td>-1.399894</td>\n",
       "      <td>0.043815</td>\n",
       "      <td>63</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>-3.718760</td>\n",
       "      <td>-1.239586</td>\n",
       "      <td>-2.635336</td>\n",
       "      <td>-0.088420</td>\n",
       "      <td>-2.320445</td>\n",
       "      <td>-0.154696</td>\n",
       "      <td>-3.711265</td>\n",
       "      <td>2.843421</td>\n",
       "      <td>-1.362515</td>\n",
       "      <td>-0.454172</td>\n",
       "      <td>-1.844685</td>\n",
       "      <td>1.253902</td>\n",
       "      <td>1.733056</td>\n",
       "      <td>0.577685</td>\n",
       "      <td>-1.586560</td>\n",
       "      <td>2.843421</td>\n",
       "      <td>0.646086</td>\n",
       "      <td>0.646086</td>\n",
       "      <td>0.646086</td>\n",
       "      <td>0.646086</td>\n",
       "      <td>-3.431245</td>\n",
       "      <td>-1.715623</td>\n",
       "      <td>-1.844685</td>\n",
       "      <td>-1.586560</td>\n",
       "      <td>12.508041</td>\n",
       "      <td>3.127010</td>\n",
       "      <td>2.618250</td>\n",
       "      <td>3.678076</td>\n",
       "      <td>-4.716927</td>\n",
       "      <td>-0.524103</td>\n",
       "      <td>-1.141761</td>\n",
       "      <td>0.099631</td>\n",
       "      <td>-1.704059</td>\n",
       "      <td>-0.568020</td>\n",
       "      <td>-1.141761</td>\n",
       "      <td>0.099631</td>\n",
       "      <td>-1.533119</td>\n",
       "      <td>-0.511040</td>\n",
       "      <td>-0.948601</td>\n",
       "      <td>-0.136814</td>\n",
       "      <td>5.378025</td>\n",
       "      <td>0.413694</td>\n",
       "      <td>-2.635336</td>\n",
       "      <td>3.678076</td>\n",
       "      <td>-2.160948</td>\n",
       "      <td>-0.216095</td>\n",
       "      <td>-3.711265</td>\n",
       "      <td>3.418133</td>\n",
       "      <td>-4.097114</td>\n",
       "      <td>-0.819423</td>\n",
       "      <td>-2.014600</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>-9.409181</td>\n",
       "      <td>-2.352295</td>\n",
       "      <td>-3.711265</td>\n",
       "      <td>-1.362240</td>\n",
       "      <td>0.766224</td>\n",
       "      <td>0.153245</td>\n",
       "      <td>-0.613813</td>\n",
       "      <td>0.955200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_00  feature_01  feature_02  feature_03  feature_04  feature_05  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN    0.851033   \n",
       "1         NaN         NaN         NaN         NaN         NaN    0.676961   \n",
       "2         NaN         NaN         NaN         NaN         NaN    1.056285   \n",
       "3         NaN         NaN         NaN         NaN         NaN    1.139366   \n",
       "4         NaN         NaN         NaN         NaN         NaN    0.955200   \n",
       "\n",
       "   feature_06  feature_07  feature_08  feature_09  feature_10  feature_11  \\\n",
       "0    0.242971    0.263400   -0.891687          11           7          76   \n",
       "1    0.151984    0.192465   -0.521729          11           7          76   \n",
       "2    0.187227    0.249901   -0.773050          11           7          76   \n",
       "3    0.273328    0.306549   -1.262223          42           5         150   \n",
       "4    0.262404    0.344457   -0.613813          44           3          16   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  feature_16  feature_17  \\\n",
       "0   -0.883028    0.003067   -0.744703         NaN   -0.169586         NaN   \n",
       "1   -0.865307   -0.225629   -0.582163         NaN    0.317467         NaN   \n",
       "2   -0.675719   -0.199404   -0.586798         NaN   -0.814909         NaN   \n",
       "3   -0.694008    3.004091    0.114809         NaN   -0.251882         NaN   \n",
       "4   -0.947351   -0.030018   -0.502379         NaN    0.646086         NaN   \n",
       "\n",
       "   feature_18  feature_19  feature_20  feature_21  feature_22  feature_23  \\\n",
       "0   -1.335938   -1.707803    0.910130         NaN    1.636431    1.522133   \n",
       "1   -1.250016   -1.682929    1.412757         NaN    0.520378    0.744132   \n",
       "2   -1.296782   -2.040234    0.639589         NaN    1.597359    0.657514   \n",
       "3   -1.902009   -0.979447    0.241165         NaN   -0.392359   -0.224699   \n",
       "4   -1.844685   -1.586560   -0.182024         NaN   -0.969949   -0.673813   \n",
       "\n",
       "   feature_24  feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "0   -1.551398   -0.229627         NaN         NaN    1.378301   -0.283712   \n",
       "1   -0.788658    0.641776         NaN         NaN    0.227200    0.580907   \n",
       "2   -1.350148    0.364215         NaN         NaN   -0.017751   -0.317361   \n",
       "3   -2.129397   -0.855287         NaN         NaN    0.404142   -0.578156   \n",
       "4   -1.282132   -1.399894         NaN         NaN    0.043815   -0.320225   \n",
       "\n",
       "   feature_30  feature_31  feature_32  feature_33  feature_34  feature_35  \\\n",
       "0    0.123196         NaN         NaN         NaN    0.281180    0.269163   \n",
       "1    1.128879         NaN         NaN         NaN   -1.512286   -1.414357   \n",
       "2   -0.122379         NaN         NaN         NaN   -0.320921   -0.958090   \n",
       "3    0.105702         NaN         NaN         NaN    0.544138   -0.087091   \n",
       "4   -0.031713         NaN         NaN         NaN   -0.088420   -0.995003   \n",
       "\n",
       "   feature_36  feature_37  feature_38  feature_39  feature_40  feature_41  \\\n",
       "0    0.349028   -0.012596   -0.225932         NaN   -1.073602         NaN   \n",
       "1   -1.823322   -0.082763   -0.184119         NaN         NaN         NaN   \n",
       "2   -2.436589    0.070999   -0.245239         NaN         NaN         NaN   \n",
       "3   -1.500147   -0.201288   -0.038042         NaN         NaN         NaN   \n",
       "4   -2.635336   -0.196461   -0.618719         NaN         NaN         NaN   \n",
       "\n",
       "   feature_42  feature_43  feature_44  feature_45  feature_46  feature_47  \\\n",
       "0         NaN   -0.181716         NaN         NaN         NaN    0.564021   \n",
       "1         NaN         NaN         NaN         NaN         NaN  -10.835207   \n",
       "2         NaN         NaN         NaN         NaN         NaN   -1.420632   \n",
       "3         NaN         NaN         NaN         NaN         NaN    0.382074   \n",
       "4         NaN         NaN         NaN         NaN         NaN   -2.014600   \n",
       "\n",
       "   feature_48  feature_49  feature_50  feature_51  feature_52  feature_53  \\\n",
       "0    2.088506    0.832022         NaN    0.204797         NaN         NaN   \n",
       "1   -0.002704   -0.621836         NaN    1.172836         NaN         NaN   \n",
       "2   -3.515137   -4.677760         NaN    0.535897         NaN         NaN   \n",
       "3    2.669135    0.611711         NaN    2.413415         NaN         NaN   \n",
       "4   -2.321076   -3.711265         NaN    1.253902         NaN         NaN   \n",
       "\n",
       "   feature_54  feature_55  feature_56  feature_57  feature_58  feature_59  \\\n",
       "0   -0.808103         NaN   -2.037683    0.727661         NaN   -0.989118   \n",
       "1   -1.625862         NaN   -1.410017    1.063013         NaN    0.888355   \n",
       "2   -0.725420         NaN   -2.294170    1.764551         NaN   -0.120789   \n",
       "3    1.313203         NaN   -0.810125    2.939022         NaN    3.988801   \n",
       "4    0.476195         NaN   -0.771732    2.843421         NaN    1.379815   \n",
       "\n",
       "   feature_60  feature_61  feature_62  feature_63  feature_64  feature_65  \\\n",
       "0   -0.345213    -1.36224         NaN         NaN         NaN         NaN   \n",
       "1    0.467994    -1.36224         NaN         NaN         NaN         NaN   \n",
       "2   -0.063458    -1.36224         NaN         NaN         NaN         NaN   \n",
       "3    1.834661    -1.36224         NaN         NaN         NaN         NaN   \n",
       "4    0.411827    -1.36224         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   feature_66  feature_67  feature_68  feature_69  feature_70  feature_71  \\\n",
       "0         NaN   -1.251104   -0.110252   -0.491157   -1.022690    0.152241   \n",
       "1         NaN   -1.065759    0.013322   -0.592855   -1.052685   -0.393726   \n",
       "2         NaN   -0.882604   -0.072482   -0.617934   -0.863230   -0.241892   \n",
       "3         NaN   -0.697595    1.074309   -0.206929   -0.530602    4.765215   \n",
       "4         NaN   -0.948601   -0.136814   -0.447704   -1.141761    0.099631   \n",
       "\n",
       "   feature_72  feature_73  feature_74  feature_75  feature_76  feature_77  \\\n",
       "0   -0.659864         NaN         NaN   -0.261412   -0.211486   -0.335556   \n",
       "1   -0.741603         NaN         NaN   -0.281207   -0.182894   -0.245565   \n",
       "2   -0.709919         NaN         NaN    0.377131    0.300724   -0.106842   \n",
       "3    0.571554         NaN         NaN   -0.226891   -0.251412   -0.215522   \n",
       "4   -0.661928         NaN         NaN    3.678076    2.793581    2.618250   \n",
       "\n",
       "   feature_78  responder_0_lag_1  responder_1_lag_1  responder_2_lag_1  \\\n",
       "0   -0.281498                NaN                NaN                NaN   \n",
       "1   -0.302441                NaN                NaN                NaN   \n",
       "2   -0.096792                NaN                NaN                NaN   \n",
       "3   -0.296244                NaN                NaN                NaN   \n",
       "4    3.418133                NaN                NaN                NaN   \n",
       "\n",
       "   responder_3_lag_1  responder_4_lag_1  responder_5_lag_1  responder_6_lag_1  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   responder_7_lag_1  responder_8_lag_1  feature_tag_0_sum  \\\n",
       "0                NaN                NaN           3.505453   \n",
       "1                NaN                NaN           4.467371   \n",
       "2                NaN                NaN           1.451039   \n",
       "3                NaN                NaN          -3.428889   \n",
       "4                NaN                NaN          -4.815935   \n",
       "\n",
       "   feature_tag_0_mean  feature_tag_0_min  feature_tag_0_max  \\\n",
       "0            0.438182          -1.551398           1.636431   \n",
       "1            0.558421          -0.788658           1.412757   \n",
       "2            0.181380          -1.350148           1.597359   \n",
       "3           -0.428611          -2.129397           0.404142   \n",
       "4           -0.601992          -1.399894           0.043815   \n",
       "\n",
       "   feature_tag_1_sum  feature_tag_1_mean  feature_tag_1_min  \\\n",
       "0                 94           31.333334                  7   \n",
       "1                 94           31.333334                  7   \n",
       "2                 94           31.333334                  7   \n",
       "3                197           65.666664                  5   \n",
       "4                 63           21.000000                  3   \n",
       "\n",
       "   feature_tag_1_max  feature_tag_2_sum  feature_tag_2_mean  \\\n",
       "0                 76           0.899371            0.299790   \n",
       "1                 76          -4.749964           -1.583321   \n",
       "2                 76          -3.715600           -1.238533   \n",
       "3                150          -1.043100           -0.347700   \n",
       "4                 44          -3.718760           -1.239586   \n",
       "\n",
       "   feature_tag_2_min  feature_tag_2_max  feature_tag_3_sum  \\\n",
       "0           0.269163           0.349028          -0.791240   \n",
       "1          -1.823322          -1.414357         -10.670630   \n",
       "2          -2.436589          -0.320921          -9.970796   \n",
       "3          -1.500147           0.544138          15.559587   \n",
       "4          -2.635336          -0.088420          -2.320445   \n",
       "\n",
       "   feature_tag_3_mean  feature_tag_3_min  feature_tag_3_max  \\\n",
       "0           -0.046544          -2.037683           2.088506   \n",
       "1           -0.711375         -10.835207           1.172836   \n",
       "2           -0.664720          -4.677760           1.764551   \n",
       "3            1.037306          -1.262223           3.988801   \n",
       "4           -0.154696          -3.711265           2.843421   \n",
       "\n",
       "   feature_tag_4_sum  feature_tag_4_mean  feature_tag_4_min  \\\n",
       "0          -4.242425           -1.060606          -2.037683   \n",
       "1          -1.487198           -0.495733          -1.410017   \n",
       "2          -3.055055           -1.018352          -2.294170   \n",
       "3          -0.298719           -0.099573          -1.902009   \n",
       "4          -1.362515           -0.454172          -1.844685   \n",
       "\n",
       "   feature_tag_4_max  feature_tag_5_sum  feature_tag_5_mean  \\\n",
       "0           0.204797          -1.969960           -0.492490   \n",
       "1           1.172836          -2.245778           -0.748593   \n",
       "2           0.535897          -1.001103           -0.333701   \n",
       "3           2.413415           3.272779            1.090926   \n",
       "4           1.253902           1.733056            0.577685   \n",
       "\n",
       "   feature_tag_5_min  feature_tag_5_max  feature_tag_6_sum  \\\n",
       "0          -1.707803           0.727661          -0.169586   \n",
       "1          -1.682929           1.063013           0.317467   \n",
       "2          -2.040234           1.764551          -0.814909   \n",
       "3          -0.979447           2.939022          -0.251882   \n",
       "4          -1.586560           2.843421           0.646086   \n",
       "\n",
       "   feature_tag_6_mean  feature_tag_6_min  feature_tag_6_max  \\\n",
       "0           -0.169586          -0.169586          -0.169586   \n",
       "1            0.317467           0.317467           0.317467   \n",
       "2           -0.814909          -0.814909          -0.814909   \n",
       "3           -0.251882          -0.251882          -0.251882   \n",
       "4            0.646086           0.646086           0.646086   \n",
       "\n",
       "   feature_tag_7_sum  feature_tag_7_mean  feature_tag_7_min  \\\n",
       "0          -3.043740           -1.521870          -1.707803   \n",
       "1          -2.932945           -1.466472          -1.682929   \n",
       "2          -3.337016           -1.668508          -2.040234   \n",
       "3          -2.881456           -1.440728          -1.902009   \n",
       "4          -3.431245           -1.715623          -1.844685   \n",
       "\n",
       "   feature_tag_7_max  feature_tag_8_sum  feature_tag_8_mean  \\\n",
       "0          -1.335938          -1.089952           -0.272488   \n",
       "1          -1.250016          -1.012106           -0.253027   \n",
       "2          -1.296782           0.474221            0.118555   \n",
       "3          -0.979447          -0.990069           -0.247517   \n",
       "4          -1.586560          12.508041            3.127010   \n",
       "\n",
       "   feature_tag_8_min  feature_tag_8_max  feature_tag_9_sum  \\\n",
       "0          -0.335556          -0.211486          -5.007490   \n",
       "1          -0.302441          -0.182894          -5.506405   \n",
       "2          -0.106842           0.377131          -4.849982   \n",
       "3          -0.296244          -0.215522           7.400844   \n",
       "4           2.618250           3.678076          -4.716927   \n",
       "\n",
       "   feature_tag_9_mean  feature_tag_9_min  feature_tag_9_max  \\\n",
       "0           -0.556388          -1.251104           0.152241   \n",
       "1           -0.611823          -1.065759           0.013322   \n",
       "2           -0.538887          -0.882604          -0.072482   \n",
       "3            0.822316          -0.697595           4.765215   \n",
       "4           -0.524103          -1.141761           0.099631   \n",
       "\n",
       "   feature_tag_10_sum  feature_tag_10_mean  feature_tag_10_min  \\\n",
       "0           -1.530313            -0.510104           -1.022690   \n",
       "1           -2.188014            -0.729338           -1.052685   \n",
       "2           -1.815040            -0.605013           -0.863230   \n",
       "3            4.806167             1.602056           -0.530602   \n",
       "4           -1.704059            -0.568020           -1.141761   \n",
       "\n",
       "   feature_tag_10_max  feature_tag_11_sum  feature_tag_11_mean  \\\n",
       "0            0.152241           -1.852513            -0.617504   \n",
       "1           -0.393726           -1.645292            -0.548431   \n",
       "2           -0.241892           -1.573021            -0.524340   \n",
       "3            4.765215            0.169785             0.056595   \n",
       "4            0.099631           -1.533119            -0.511040   \n",
       "\n",
       "   feature_tag_11_min  feature_tag_11_max  feature_tag_12_sum  \\\n",
       "0           -1.251104           -0.110252           -0.483484   \n",
       "1           -1.065759            0.013322           -3.503667   \n",
       "2           -0.882604           -0.072482           -7.046564   \n",
       "3           -0.697595            1.074309           17.815304   \n",
       "4           -0.948601           -0.136814            5.378025   \n",
       "\n",
       "   feature_tag_12_mean  feature_tag_12_min  feature_tag_12_max  \\\n",
       "0            -0.032232           -1.073602            2.088506   \n",
       "1            -0.269513           -1.823322            1.172836   \n",
       "2            -0.542043           -3.515137            0.535897   \n",
       "3             1.370408           -1.500147            4.765215   \n",
       "4             0.413694           -2.635336            3.678076   \n",
       "\n",
       "   feature_tag_13_sum  feature_tag_13_mean  feature_tag_13_min  \\\n",
       "0           -1.144378            -0.114438           -0.744703   \n",
       "1           -5.663682            -0.566368           -1.823322   \n",
       "2          -10.004279            -1.000428           -4.677760   \n",
       "3            1.133351             0.113335           -1.500147   \n",
       "4           -2.160948            -0.216095           -3.711265   \n",
       "\n",
       "   feature_tag_13_max  feature_tag_14_sum  feature_tag_14_mean  \\\n",
       "0            0.832022           -1.741769            -0.348354   \n",
       "1            0.467994          -13.141997            -2.628399   \n",
       "2            0.249901           -2.785900            -0.557180   \n",
       "3            1.834661           -0.400764            -0.080153   \n",
       "4            3.418133           -4.097114            -0.819423   \n",
       "\n",
       "   feature_tag_14_min  feature_tag_14_max  feature_tag_15_sum  \\\n",
       "0           -1.251104            0.851033            0.866990   \n",
       "1          -10.835207            0.676961          -12.821986   \n",
       "2           -1.420632            1.056285          -10.975769   \n",
       "3           -0.697595            1.139366            2.300680   \n",
       "4           -2.014600            0.955200           -9.409181   \n",
       "\n",
       "   feature_tag_15_mean  feature_tag_15_min  feature_tag_15_max  \\\n",
       "0             0.144498           -1.362240            2.088506   \n",
       "1            -3.205497          -10.835207           -0.002704   \n",
       "2            -2.743942           -4.677760           -1.362240   \n",
       "3             0.575170           -1.362240            2.669135   \n",
       "4            -2.352295           -3.711265           -1.362240   \n",
       "\n",
       "   feature_tag_16_sum  feature_tag_16_mean  feature_tag_16_min  \\\n",
       "0            1.375848             0.275170           -0.891687   \n",
       "1            1.912438             0.382488           -0.521729   \n",
       "2            1.359952             0.271990           -0.773050   \n",
       "3            0.698185             0.139637           -1.262223   \n",
       "4            0.766224             0.153245           -0.613813   \n",
       "\n",
       "   feature_tag_16_max  responder_tag_0_sum  responder_tag_0_mean  \\\n",
       "0            0.910130                  0.0                   NaN   \n",
       "1            1.412757                  0.0                   NaN   \n",
       "2            1.056285                  0.0                   NaN   \n",
       "3            1.139366                  0.0                   NaN   \n",
       "4            0.955200                  0.0                   NaN   \n",
       "\n",
       "   responder_tag_0_min  responder_tag_0_max  responder_tag_1_sum  \\\n",
       "0                  NaN                  NaN                  0.0   \n",
       "1                  NaN                  NaN                  0.0   \n",
       "2                  NaN                  NaN                  0.0   \n",
       "3                  NaN                  NaN                  0.0   \n",
       "4                  NaN                  NaN                  0.0   \n",
       "\n",
       "   responder_tag_1_mean  responder_tag_1_min  responder_tag_1_max  \\\n",
       "0                   NaN                  NaN                  NaN   \n",
       "1                   NaN                  NaN                  NaN   \n",
       "2                   NaN                  NaN                  NaN   \n",
       "3                   NaN                  NaN                  NaN   \n",
       "4                   NaN                  NaN                  NaN   \n",
       "\n",
       "   responder_tag_2_sum  responder_tag_2_mean  responder_tag_2_min  \\\n",
       "0                  0.0                   NaN                  NaN   \n",
       "1                  0.0                   NaN                  NaN   \n",
       "2                  0.0                   NaN                  NaN   \n",
       "3                  0.0                   NaN                  NaN   \n",
       "4                  0.0                   NaN                  NaN   \n",
       "\n",
       "   responder_tag_2_max  responder_tag_3_sum  responder_tag_3_mean  \\\n",
       "0                  NaN                  0.0                   NaN   \n",
       "1                  NaN                  0.0                   NaN   \n",
       "2                  NaN                  0.0                   NaN   \n",
       "3                  NaN                  0.0                   NaN   \n",
       "4                  NaN                  0.0                   NaN   \n",
       "\n",
       "   responder_tag_3_min  responder_tag_3_max  responder_tag_4_sum  \\\n",
       "0                  NaN                  NaN                  0.0   \n",
       "1                  NaN                  NaN                  0.0   \n",
       "2                  NaN                  NaN                  0.0   \n",
       "3                  NaN                  NaN                  0.0   \n",
       "4                  NaN                  NaN                  0.0   \n",
       "\n",
       "   responder_tag_4_mean  responder_tag_4_min  responder_tag_4_max  \n",
       "0                   NaN                  NaN                  NaN  \n",
       "1                   NaN                  NaN                  NaN  \n",
       "2                   NaN                  NaN                  NaN  \n",
       "3                   NaN                  NaN                  NaN  \n",
       "4                   NaN                  NaN                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>feature_07</th>\n",
       "      <th>feature_08</th>\n",
       "      <th>feature_09</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>feature_51</th>\n",
       "      <th>feature_52</th>\n",
       "      <th>feature_53</th>\n",
       "      <th>feature_54</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>feature_58</th>\n",
       "      <th>feature_59</th>\n",
       "      <th>feature_60</th>\n",
       "      <th>feature_61</th>\n",
       "      <th>feature_62</th>\n",
       "      <th>feature_63</th>\n",
       "      <th>feature_64</th>\n",
       "      <th>feature_65</th>\n",
       "      <th>feature_66</th>\n",
       "      <th>feature_67</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_0_lag_1</th>\n",
       "      <th>responder_1_lag_1</th>\n",
       "      <th>responder_2_lag_1</th>\n",
       "      <th>responder_3_lag_1</th>\n",
       "      <th>responder_4_lag_1</th>\n",
       "      <th>responder_5_lag_1</th>\n",
       "      <th>responder_6_lag_1</th>\n",
       "      <th>responder_7_lag_1</th>\n",
       "      <th>responder_8_lag_1</th>\n",
       "      <th>feature_tag_0_sum</th>\n",
       "      <th>feature_tag_0_mean</th>\n",
       "      <th>feature_tag_0_min</th>\n",
       "      <th>feature_tag_0_max</th>\n",
       "      <th>feature_tag_1_sum</th>\n",
       "      <th>feature_tag_1_mean</th>\n",
       "      <th>feature_tag_1_min</th>\n",
       "      <th>feature_tag_1_max</th>\n",
       "      <th>feature_tag_2_sum</th>\n",
       "      <th>feature_tag_2_mean</th>\n",
       "      <th>feature_tag_2_min</th>\n",
       "      <th>feature_tag_2_max</th>\n",
       "      <th>feature_tag_3_sum</th>\n",
       "      <th>feature_tag_3_mean</th>\n",
       "      <th>feature_tag_3_min</th>\n",
       "      <th>feature_tag_3_max</th>\n",
       "      <th>feature_tag_4_sum</th>\n",
       "      <th>feature_tag_4_mean</th>\n",
       "      <th>feature_tag_4_min</th>\n",
       "      <th>feature_tag_4_max</th>\n",
       "      <th>feature_tag_5_sum</th>\n",
       "      <th>feature_tag_5_mean</th>\n",
       "      <th>feature_tag_5_min</th>\n",
       "      <th>feature_tag_5_max</th>\n",
       "      <th>feature_tag_6_sum</th>\n",
       "      <th>feature_tag_6_mean</th>\n",
       "      <th>feature_tag_6_min</th>\n",
       "      <th>feature_tag_6_max</th>\n",
       "      <th>feature_tag_7_sum</th>\n",
       "      <th>feature_tag_7_mean</th>\n",
       "      <th>feature_tag_7_min</th>\n",
       "      <th>feature_tag_7_max</th>\n",
       "      <th>feature_tag_8_sum</th>\n",
       "      <th>feature_tag_8_mean</th>\n",
       "      <th>feature_tag_8_min</th>\n",
       "      <th>feature_tag_8_max</th>\n",
       "      <th>feature_tag_9_sum</th>\n",
       "      <th>feature_tag_9_mean</th>\n",
       "      <th>feature_tag_9_min</th>\n",
       "      <th>feature_tag_9_max</th>\n",
       "      <th>feature_tag_10_sum</th>\n",
       "      <th>feature_tag_10_mean</th>\n",
       "      <th>feature_tag_10_min</th>\n",
       "      <th>feature_tag_10_max</th>\n",
       "      <th>feature_tag_11_sum</th>\n",
       "      <th>feature_tag_11_mean</th>\n",
       "      <th>feature_tag_11_min</th>\n",
       "      <th>feature_tag_11_max</th>\n",
       "      <th>feature_tag_12_sum</th>\n",
       "      <th>feature_tag_12_mean</th>\n",
       "      <th>feature_tag_12_min</th>\n",
       "      <th>feature_tag_12_max</th>\n",
       "      <th>feature_tag_13_sum</th>\n",
       "      <th>feature_tag_13_mean</th>\n",
       "      <th>feature_tag_13_min</th>\n",
       "      <th>feature_tag_13_max</th>\n",
       "      <th>feature_tag_14_sum</th>\n",
       "      <th>feature_tag_14_mean</th>\n",
       "      <th>feature_tag_14_min</th>\n",
       "      <th>feature_tag_14_max</th>\n",
       "      <th>feature_tag_15_sum</th>\n",
       "      <th>feature_tag_15_mean</th>\n",
       "      <th>feature_tag_15_min</th>\n",
       "      <th>feature_tag_15_max</th>\n",
       "      <th>feature_tag_16_sum</th>\n",
       "      <th>feature_tag_16_mean</th>\n",
       "      <th>feature_tag_16_min</th>\n",
       "      <th>feature_tag_16_max</th>\n",
       "      <th>responder_tag_0_sum</th>\n",
       "      <th>responder_tag_0_mean</th>\n",
       "      <th>responder_tag_0_min</th>\n",
       "      <th>responder_tag_0_max</th>\n",
       "      <th>responder_tag_1_sum</th>\n",
       "      <th>responder_tag_1_mean</th>\n",
       "      <th>responder_tag_1_min</th>\n",
       "      <th>responder_tag_1_max</th>\n",
       "      <th>responder_tag_2_sum</th>\n",
       "      <th>responder_tag_2_mean</th>\n",
       "      <th>responder_tag_2_min</th>\n",
       "      <th>responder_tag_2_max</th>\n",
       "      <th>responder_tag_3_sum</th>\n",
       "      <th>responder_tag_3_mean</th>\n",
       "      <th>responder_tag_3_min</th>\n",
       "      <th>responder_tag_3_max</th>\n",
       "      <th>responder_tag_4_sum</th>\n",
       "      <th>responder_tag_4_mean</th>\n",
       "      <th>responder_tag_4_min</th>\n",
       "      <th>responder_tag_4_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32496013</th>\n",
       "      <td>-0.273723</td>\n",
       "      <td>-0.628400</td>\n",
       "      <td>0.021183</td>\n",
       "      <td>0.326928</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.267356</td>\n",
       "      <td>0.739021</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.886931</td>\n",
       "      <td>0.800840</td>\n",
       "      <td>0.619701</td>\n",
       "      <td>-0.944317</td>\n",
       "      <td>-0.731467</td>\n",
       "      <td>-0.826058</td>\n",
       "      <td>1.270973</td>\n",
       "      <td>2.309707</td>\n",
       "      <td>-0.168244</td>\n",
       "      <td>-0.180836</td>\n",
       "      <td>-0.228961</td>\n",
       "      <td>-0.731446</td>\n",
       "      <td>0.499912</td>\n",
       "      <td>-0.058762</td>\n",
       "      <td>-1.233727</td>\n",
       "      <td>0.421452</td>\n",
       "      <td>1.658583</td>\n",
       "      <td>-0.643178</td>\n",
       "      <td>-0.641713</td>\n",
       "      <td>-0.127338</td>\n",
       "      <td>1.012934</td>\n",
       "      <td>-0.808432</td>\n",
       "      <td>0.640629</td>\n",
       "      <td>0.046857</td>\n",
       "      <td>-0.553982</td>\n",
       "      <td>-0.097041</td>\n",
       "      <td>-0.199727</td>\n",
       "      <td>-0.778504</td>\n",
       "      <td>0.546700</td>\n",
       "      <td>0.259686</td>\n",
       "      <td>-0.897121</td>\n",
       "      <td>-0.245391</td>\n",
       "      <td>-0.181529</td>\n",
       "      <td>-0.041429</td>\n",
       "      <td>-0.114340</td>\n",
       "      <td>0.074312</td>\n",
       "      <td>-0.162039</td>\n",
       "      <td>-0.156312</td>\n",
       "      <td>-0.445739</td>\n",
       "      <td>-0.194293</td>\n",
       "      <td>-0.992565</td>\n",
       "      <td>0.026359</td>\n",
       "      <td>0.776747</td>\n",
       "      <td>0.515383</td>\n",
       "      <td>-0.310368</td>\n",
       "      <td>0.715174</td>\n",
       "      <td>0.382011</td>\n",
       "      <td>-0.057844</td>\n",
       "      <td>-0.040984</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.526368</td>\n",
       "      <td>-0.235048</td>\n",
       "      <td>-0.354705</td>\n",
       "      <td>1.505933</td>\n",
       "      <td>1.735560</td>\n",
       "      <td>0.519725</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>0.247436</td>\n",
       "      <td>1.266712</td>\n",
       "      <td>1.023329</td>\n",
       "      <td>1.049752</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-0.234894</td>\n",
       "      <td>-0.328479</td>\n",
       "      <td>-0.167722</td>\n",
       "      <td>-0.107061</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.299852</td>\n",
       "      <td>0.113701</td>\n",
       "      <td>0.191003</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>-0.233323</td>\n",
       "      <td>-0.171773</td>\n",
       "      <td>-0.042368</td>\n",
       "      <td>-0.313162</td>\n",
       "      <td>-1.434256</td>\n",
       "      <td>-0.119521</td>\n",
       "      <td>-1.233727</td>\n",
       "      <td>1.658583</td>\n",
       "      <td>197</td>\n",
       "      <td>65.666664</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.095627</td>\n",
       "      <td>-0.009563</td>\n",
       "      <td>-0.808432</td>\n",
       "      <td>1.012934</td>\n",
       "      <td>-0.335731</td>\n",
       "      <td>-0.011990</td>\n",
       "      <td>-0.992565</td>\n",
       "      <td>0.776747</td>\n",
       "      <td>0.820393</td>\n",
       "      <td>0.082039</td>\n",
       "      <td>-0.992565</td>\n",
       "      <td>1.505933</td>\n",
       "      <td>4.640548</td>\n",
       "      <td>0.464055</td>\n",
       "      <td>-0.897121</td>\n",
       "      <td>2.309707</td>\n",
       "      <td>-3.617962</td>\n",
       "      <td>-0.602994</td>\n",
       "      <td>-0.944317</td>\n",
       "      <td>-0.235048</td>\n",
       "      <td>6.822173</td>\n",
       "      <td>1.705543</td>\n",
       "      <td>1.270973</td>\n",
       "      <td>2.309707</td>\n",
       "      <td>-0.858376</td>\n",
       "      <td>-0.143063</td>\n",
       "      <td>-0.328479</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>6.448441</td>\n",
       "      <td>0.716493</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>1.266712</td>\n",
       "      <td>3.339793</td>\n",
       "      <td>1.113264</td>\n",
       "      <td>1.023329</td>\n",
       "      <td>1.266712</td>\n",
       "      <td>0.801176</td>\n",
       "      <td>0.267059</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>0.519725</td>\n",
       "      <td>1.514229</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.731467</td>\n",
       "      <td>1.023329</td>\n",
       "      <td>-1.364271</td>\n",
       "      <td>-0.068214</td>\n",
       "      <td>-0.992565</td>\n",
       "      <td>1.049752</td>\n",
       "      <td>-1.170940</td>\n",
       "      <td>-0.065052</td>\n",
       "      <td>-0.944317</td>\n",
       "      <td>1.266712</td>\n",
       "      <td>1.226355</td>\n",
       "      <td>0.072139</td>\n",
       "      <td>-0.897121</td>\n",
       "      <td>1.735560</td>\n",
       "      <td>0.681245</td>\n",
       "      <td>0.068125</td>\n",
       "      <td>-0.628400</td>\n",
       "      <td>0.739021</td>\n",
       "      <td>0.426673</td>\n",
       "      <td>0.142224</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.299852</td>\n",
       "      <td>-0.432783</td>\n",
       "      <td>-0.144261</td>\n",
       "      <td>-0.313162</td>\n",
       "      <td>0.113701</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.010783</td>\n",
       "      <td>-0.171773</td>\n",
       "      <td>0.191003</td>\n",
       "      <td>0.348215</td>\n",
       "      <td>0.116072</td>\n",
       "      <td>-0.042368</td>\n",
       "      <td>0.299852</td>\n",
       "      <td>0.048410</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>-0.233323</td>\n",
       "      <td>0.191003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496014</th>\n",
       "      <td>0.516346</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>0.170515</td>\n",
       "      <td>0.457404</td>\n",
       "      <td>0.704279</td>\n",
       "      <td>-0.016830</td>\n",
       "      <td>0.200757</td>\n",
       "      <td>0.196041</td>\n",
       "      <td>1.106106</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>0.569555</td>\n",
       "      <td>0.320779</td>\n",
       "      <td>0.445927</td>\n",
       "      <td>0.833764</td>\n",
       "      <td>0.766083</td>\n",
       "      <td>0.760303</td>\n",
       "      <td>2.978000</td>\n",
       "      <td>0.180232</td>\n",
       "      <td>-0.071296</td>\n",
       "      <td>0.833885</td>\n",
       "      <td>-0.442648</td>\n",
       "      <td>1.909253</td>\n",
       "      <td>1.260226</td>\n",
       "      <td>2.173384</td>\n",
       "      <td>0.124759</td>\n",
       "      <td>-1.742508</td>\n",
       "      <td>-2.060564</td>\n",
       "      <td>2.431904</td>\n",
       "      <td>0.894903</td>\n",
       "      <td>1.336326</td>\n",
       "      <td>0.233143</td>\n",
       "      <td>0.268164</td>\n",
       "      <td>0.180035</td>\n",
       "      <td>-0.047150</td>\n",
       "      <td>-0.035961</td>\n",
       "      <td>1.073607</td>\n",
       "      <td>0.868699</td>\n",
       "      <td>1.179430</td>\n",
       "      <td>0.910744</td>\n",
       "      <td>0.365738</td>\n",
       "      <td>-0.806121</td>\n",
       "      <td>-1.221758</td>\n",
       "      <td>-0.294194</td>\n",
       "      <td>-0.309661</td>\n",
       "      <td>-1.669550</td>\n",
       "      <td>-1.185478</td>\n",
       "      <td>-0.013506</td>\n",
       "      <td>-0.296199</td>\n",
       "      <td>0.629851</td>\n",
       "      <td>1.619304</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>-1.331440</td>\n",
       "      <td>-1.206886</td>\n",
       "      <td>-0.506745</td>\n",
       "      <td>-0.665731</td>\n",
       "      <td>-1.265526</td>\n",
       "      <td>-1.339285</td>\n",
       "      <td>0.179611</td>\n",
       "      <td>-0.155559</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.099937</td>\n",
       "      <td>0.127875</td>\n",
       "      <td>-0.027559</td>\n",
       "      <td>2.582265</td>\n",
       "      <td>-0.386582</td>\n",
       "      <td>1.081167</td>\n",
       "      <td>-0.309833</td>\n",
       "      <td>0.429599</td>\n",
       "      <td>0.702698</td>\n",
       "      <td>0.696585</td>\n",
       "      <td>0.391108</td>\n",
       "      <td>-0.312883</td>\n",
       "      <td>-0.507126</td>\n",
       "      <td>-0.303390</td>\n",
       "      <td>-0.442164</td>\n",
       "      <td>-0.255057</td>\n",
       "      <td>-0.366450</td>\n",
       "      <td>-0.150453</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>-2.491776</td>\n",
       "      <td>0.146255</td>\n",
       "      <td>0.055375</td>\n",
       "      <td>-0.119033</td>\n",
       "      <td>0.025655</td>\n",
       "      <td>0.050160</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>6.647622</td>\n",
       "      <td>0.553968</td>\n",
       "      <td>-2.060564</td>\n",
       "      <td>2.431904</td>\n",
       "      <td>94</td>\n",
       "      <td>31.333334</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>2.088558</td>\n",
       "      <td>0.208856</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>0.704279</td>\n",
       "      <td>-3.824358</td>\n",
       "      <td>-0.136584</td>\n",
       "      <td>-1.669550</td>\n",
       "      <td>1.619304</td>\n",
       "      <td>9.420164</td>\n",
       "      <td>0.942016</td>\n",
       "      <td>-0.665731</td>\n",
       "      <td>2.978000</td>\n",
       "      <td>-8.508570</td>\n",
       "      <td>-0.850857</td>\n",
       "      <td>-1.669550</td>\n",
       "      <td>0.180232</td>\n",
       "      <td>2.360528</td>\n",
       "      <td>0.393421</td>\n",
       "      <td>-0.099937</td>\n",
       "      <td>0.833764</td>\n",
       "      <td>5.353916</td>\n",
       "      <td>1.338479</td>\n",
       "      <td>-0.386582</td>\n",
       "      <td>2.978000</td>\n",
       "      <td>-2.187071</td>\n",
       "      <td>-0.364512</td>\n",
       "      <td>-0.507126</td>\n",
       "      <td>-0.255057</td>\n",
       "      <td>4.327584</td>\n",
       "      <td>0.480843</td>\n",
       "      <td>-0.309833</td>\n",
       "      <td>1.081167</td>\n",
       "      <td>1.790391</td>\n",
       "      <td>0.596797</td>\n",
       "      <td>0.391108</td>\n",
       "      <td>0.702698</td>\n",
       "      <td>1.200932</td>\n",
       "      <td>0.400311</td>\n",
       "      <td>-0.309833</td>\n",
       "      <td>1.081167</td>\n",
       "      <td>2.343069</td>\n",
       "      <td>0.130170</td>\n",
       "      <td>-1.221758</td>\n",
       "      <td>1.619304</td>\n",
       "      <td>1.805695</td>\n",
       "      <td>0.090285</td>\n",
       "      <td>-0.506745</td>\n",
       "      <td>0.760303</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>-1.339285</td>\n",
       "      <td>1.179430</td>\n",
       "      <td>-0.347543</td>\n",
       "      <td>-0.020444</td>\n",
       "      <td>-1.669550</td>\n",
       "      <td>2.582265</td>\n",
       "      <td>2.905105</td>\n",
       "      <td>0.290511</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>1.106106</td>\n",
       "      <td>-1.944628</td>\n",
       "      <td>-0.648209</td>\n",
       "      <td>-2.491776</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>-2.566129</td>\n",
       "      <td>-0.855376</td>\n",
       "      <td>-2.491776</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>-0.150453</td>\n",
       "      <td>0.146255</td>\n",
       "      <td>0.803136</td>\n",
       "      <td>0.267712</td>\n",
       "      <td>0.050160</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.082597</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>-0.119033</td>\n",
       "      <td>0.146255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496015</th>\n",
       "      <td>-0.276064</td>\n",
       "      <td>-0.562562</td>\n",
       "      <td>0.126326</td>\n",
       "      <td>0.341234</td>\n",
       "      <td>0.648612</td>\n",
       "      <td>-0.010778</td>\n",
       "      <td>0.217542</td>\n",
       "      <td>0.150108</td>\n",
       "      <td>0.763144</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>388</td>\n",
       "      <td>-0.154750</td>\n",
       "      <td>0.241596</td>\n",
       "      <td>-0.084922</td>\n",
       "      <td>-0.210215</td>\n",
       "      <td>-0.473479</td>\n",
       "      <td>-0.281191</td>\n",
       "      <td>0.932661</td>\n",
       "      <td>-1.085921</td>\n",
       "      <td>-0.415765</td>\n",
       "      <td>0.663795</td>\n",
       "      <td>-0.465737</td>\n",
       "      <td>1.354075</td>\n",
       "      <td>2.110133</td>\n",
       "      <td>2.677571</td>\n",
       "      <td>-0.370774</td>\n",
       "      <td>-2.367140</td>\n",
       "      <td>-1.442387</td>\n",
       "      <td>0.450709</td>\n",
       "      <td>-0.131176</td>\n",
       "      <td>0.483004</td>\n",
       "      <td>0.787535</td>\n",
       "      <td>-0.551896</td>\n",
       "      <td>0.947080</td>\n",
       "      <td>0.807590</td>\n",
       "      <td>-0.549592</td>\n",
       "      <td>0.100099</td>\n",
       "      <td>0.098323</td>\n",
       "      <td>0.180247</td>\n",
       "      <td>1.340250</td>\n",
       "      <td>-0.481007</td>\n",
       "      <td>1.146693</td>\n",
       "      <td>-0.012450</td>\n",
       "      <td>0.033310</td>\n",
       "      <td>-0.014503</td>\n",
       "      <td>0.447920</td>\n",
       "      <td>0.086581</td>\n",
       "      <td>-0.195873</td>\n",
       "      <td>0.004835</td>\n",
       "      <td>0.530240</td>\n",
       "      <td>-0.618310</td>\n",
       "      <td>-0.746920</td>\n",
       "      <td>0.534145</td>\n",
       "      <td>-0.556152</td>\n",
       "      <td>0.391937</td>\n",
       "      <td>0.606587</td>\n",
       "      <td>1.020363</td>\n",
       "      <td>0.241115</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.080730</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.368261</td>\n",
       "      <td>-0.287799</td>\n",
       "      <td>-0.280969</td>\n",
       "      <td>0.449343</td>\n",
       "      <td>1.240352</td>\n",
       "      <td>-0.351033</td>\n",
       "      <td>0.879358</td>\n",
       "      <td>-0.191713</td>\n",
       "      <td>-0.081830</td>\n",
       "      <td>-0.143664</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>-0.265242</td>\n",
       "      <td>-0.402117</td>\n",
       "      <td>-0.290549</td>\n",
       "      <td>-0.336317</td>\n",
       "      <td>-0.207405</td>\n",
       "      <td>-0.323209</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.286257</td>\n",
       "      <td>1.291592</td>\n",
       "      <td>0.117581</td>\n",
       "      <td>0.050176</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>0.032325</td>\n",
       "      <td>-0.019257</td>\n",
       "      <td>2.546308</td>\n",
       "      <td>0.212192</td>\n",
       "      <td>-2.367140</td>\n",
       "      <td>2.677571</td>\n",
       "      <td>462</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>388</td>\n",
       "      <td>1.718264</td>\n",
       "      <td>0.171826</td>\n",
       "      <td>-0.562562</td>\n",
       "      <td>0.947080</td>\n",
       "      <td>5.274477</td>\n",
       "      <td>0.188374</td>\n",
       "      <td>-0.746920</td>\n",
       "      <td>1.340250</td>\n",
       "      <td>2.178590</td>\n",
       "      <td>0.217859</td>\n",
       "      <td>-0.746920</td>\n",
       "      <td>1.340250</td>\n",
       "      <td>3.160197</td>\n",
       "      <td>0.316020</td>\n",
       "      <td>-1.085921</td>\n",
       "      <td>1.240352</td>\n",
       "      <td>-1.901915</td>\n",
       "      <td>-0.316986</td>\n",
       "      <td>-0.473479</td>\n",
       "      <td>-0.210215</td>\n",
       "      <td>1.536435</td>\n",
       "      <td>0.384109</td>\n",
       "      <td>-1.085921</td>\n",
       "      <td>1.240352</td>\n",
       "      <td>-1.824840</td>\n",
       "      <td>-0.304140</td>\n",
       "      <td>-0.402117</td>\n",
       "      <td>-0.207405</td>\n",
       "      <td>0.138625</td>\n",
       "      <td>0.015403</td>\n",
       "      <td>-0.351033</td>\n",
       "      <td>0.879358</td>\n",
       "      <td>-0.199912</td>\n",
       "      <td>-0.066637</td>\n",
       "      <td>-0.143664</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>0.336612</td>\n",
       "      <td>0.112204</td>\n",
       "      <td>-0.351033</td>\n",
       "      <td>0.879358</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.048493</td>\n",
       "      <td>-0.618310</td>\n",
       "      <td>1.340250</td>\n",
       "      <td>-1.777448</td>\n",
       "      <td>-0.088872</td>\n",
       "      <td>-0.746920</td>\n",
       "      <td>0.807590</td>\n",
       "      <td>0.271808</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>-0.562562</td>\n",
       "      <td>1.146693</td>\n",
       "      <td>4.085620</td>\n",
       "      <td>0.240331</td>\n",
       "      <td>-0.481007</td>\n",
       "      <td>1.340250</td>\n",
       "      <td>0.981798</td>\n",
       "      <td>0.098180</td>\n",
       "      <td>-0.562562</td>\n",
       "      <td>0.763144</td>\n",
       "      <td>1.514069</td>\n",
       "      <td>0.504690</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>1.291592</td>\n",
       "      <td>1.258345</td>\n",
       "      <td>0.419448</td>\n",
       "      <td>-0.019257</td>\n",
       "      <td>1.291592</td>\n",
       "      <td>0.048735</td>\n",
       "      <td>0.016245</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.117581</td>\n",
       "      <td>0.368758</td>\n",
       "      <td>0.122919</td>\n",
       "      <td>0.032325</td>\n",
       "      <td>0.286257</td>\n",
       "      <td>0.153766</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>0.117581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496016</th>\n",
       "      <td>0.048198</td>\n",
       "      <td>-0.705530</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>0.377266</td>\n",
       "      <td>-0.100474</td>\n",
       "      <td>-0.014540</td>\n",
       "      <td>0.407335</td>\n",
       "      <td>0.410498</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>0.412368</td>\n",
       "      <td>1.015218</td>\n",
       "      <td>0.308765</td>\n",
       "      <td>-0.950215</td>\n",
       "      <td>-0.248845</td>\n",
       "      <td>-0.995436</td>\n",
       "      <td>0.486453</td>\n",
       "      <td>1.312123</td>\n",
       "      <td>-1.498882</td>\n",
       "      <td>-0.192676</td>\n",
       "      <td>-0.928796</td>\n",
       "      <td>-1.160311</td>\n",
       "      <td>0.198818</td>\n",
       "      <td>-0.378694</td>\n",
       "      <td>0.325012</td>\n",
       "      <td>-1.749679</td>\n",
       "      <td>-1.901364</td>\n",
       "      <td>-0.891058</td>\n",
       "      <td>-0.919408</td>\n",
       "      <td>-0.148865</td>\n",
       "      <td>-0.459053</td>\n",
       "      <td>-0.338284</td>\n",
       "      <td>0.518999</td>\n",
       "      <td>0.109611</td>\n",
       "      <td>-1.465696</td>\n",
       "      <td>-0.033068</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.565646</td>\n",
       "      <td>-0.376636</td>\n",
       "      <td>-0.389352</td>\n",
       "      <td>0.796484</td>\n",
       "      <td>0.069480</td>\n",
       "      <td>0.411968</td>\n",
       "      <td>0.808051</td>\n",
       "      <td>0.978345</td>\n",
       "      <td>0.280803</td>\n",
       "      <td>0.242483</td>\n",
       "      <td>0.710215</td>\n",
       "      <td>1.463319</td>\n",
       "      <td>-0.488809</td>\n",
       "      <td>0.659116</td>\n",
       "      <td>2.040899</td>\n",
       "      <td>0.413254</td>\n",
       "      <td>1.128831</td>\n",
       "      <td>0.767357</td>\n",
       "      <td>1.831824</td>\n",
       "      <td>0.678784</td>\n",
       "      <td>0.461269</td>\n",
       "      <td>0.819580</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.427502</td>\n",
       "      <td>-0.318685</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.073792</td>\n",
       "      <td>1.567347</td>\n",
       "      <td>0.145724</td>\n",
       "      <td>0.456878</td>\n",
       "      <td>-0.023279</td>\n",
       "      <td>0.530322</td>\n",
       "      <td>1.483768</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>-0.563597</td>\n",
       "      <td>-0.828064</td>\n",
       "      <td>-0.598701</td>\n",
       "      <td>-0.625653</td>\n",
       "      <td>-0.810607</td>\n",
       "      <td>-0.975171</td>\n",
       "      <td>-0.226147</td>\n",
       "      <td>-0.275249</td>\n",
       "      <td>-0.060692</td>\n",
       "      <td>0.117830</td>\n",
       "      <td>0.084099</td>\n",
       "      <td>0.020054</td>\n",
       "      <td>0.030628</td>\n",
       "      <td>0.043376</td>\n",
       "      <td>0.028681</td>\n",
       "      <td>-9.245903</td>\n",
       "      <td>-0.770492</td>\n",
       "      <td>-1.901364</td>\n",
       "      <td>0.325012</td>\n",
       "      <td>252</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>214</td>\n",
       "      <td>-2.015399</td>\n",
       "      <td>-0.201540</td>\n",
       "      <td>-1.465696</td>\n",
       "      <td>0.518999</td>\n",
       "      <td>15.428149</td>\n",
       "      <td>0.551005</td>\n",
       "      <td>-0.488809</td>\n",
       "      <td>2.040899</td>\n",
       "      <td>3.421353</td>\n",
       "      <td>0.342135</td>\n",
       "      <td>-0.488809</td>\n",
       "      <td>1.463319</td>\n",
       "      <td>10.550554</td>\n",
       "      <td>1.055055</td>\n",
       "      <td>0.069480</td>\n",
       "      <td>2.040899</td>\n",
       "      <td>-3.205302</td>\n",
       "      <td>-0.534217</td>\n",
       "      <td>-0.995436</td>\n",
       "      <td>-0.248845</td>\n",
       "      <td>3.292131</td>\n",
       "      <td>0.823033</td>\n",
       "      <td>-0.073792</td>\n",
       "      <td>1.567347</td>\n",
       "      <td>-4.401793</td>\n",
       "      <td>-0.733632</td>\n",
       "      <td>-0.975171</td>\n",
       "      <td>-0.563597</td>\n",
       "      <td>4.966471</td>\n",
       "      <td>0.551830</td>\n",
       "      <td>-0.023279</td>\n",
       "      <td>1.483768</td>\n",
       "      <td>2.650798</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.530322</td>\n",
       "      <td>1.483768</td>\n",
       "      <td>0.579322</td>\n",
       "      <td>0.193107</td>\n",
       "      <td>-0.023279</td>\n",
       "      <td>0.456878</td>\n",
       "      <td>0.844747</td>\n",
       "      <td>0.046930</td>\n",
       "      <td>-1.465696</td>\n",
       "      <td>1.483768</td>\n",
       "      <td>-0.495891</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>-1.465696</td>\n",
       "      <td>1.128831</td>\n",
       "      <td>2.675762</td>\n",
       "      <td>0.148653</td>\n",
       "      <td>-0.950215</td>\n",
       "      <td>2.040899</td>\n",
       "      <td>5.377185</td>\n",
       "      <td>0.316305</td>\n",
       "      <td>-0.427502</td>\n",
       "      <td>1.567347</td>\n",
       "      <td>-0.298527</td>\n",
       "      <td>-0.029853</td>\n",
       "      <td>-1.498882</td>\n",
       "      <td>0.778039</td>\n",
       "      <td>-0.562088</td>\n",
       "      <td>-0.187363</td>\n",
       "      <td>-0.275249</td>\n",
       "      <td>-0.060692</td>\n",
       "      <td>-0.011957</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>-0.060692</td>\n",
       "      <td>0.028681</td>\n",
       "      <td>-0.077689</td>\n",
       "      <td>-0.025896</td>\n",
       "      <td>-0.226147</td>\n",
       "      <td>0.117830</td>\n",
       "      <td>-0.147774</td>\n",
       "      <td>-0.049258</td>\n",
       "      <td>-0.275249</td>\n",
       "      <td>0.084099</td>\n",
       "      <td>0.221983</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.020054</td>\n",
       "      <td>0.117830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32496017</th>\n",
       "      <td>0.726119</td>\n",
       "      <td>-0.738978</td>\n",
       "      <td>-0.543837</td>\n",
       "      <td>-0.127495</td>\n",
       "      <td>0.738317</td>\n",
       "      <td>-0.016428</td>\n",
       "      <td>0.349479</td>\n",
       "      <td>0.261747</td>\n",
       "      <td>1.239655</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>-0.284493</td>\n",
       "      <td>-0.111495</td>\n",
       "      <td>-0.307370</td>\n",
       "      <td>-0.666224</td>\n",
       "      <td>-0.526006</td>\n",
       "      <td>-0.703370</td>\n",
       "      <td>1.702379</td>\n",
       "      <td>-0.828881</td>\n",
       "      <td>-0.261229</td>\n",
       "      <td>-0.142134</td>\n",
       "      <td>1.071015</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.441871</td>\n",
       "      <td>-0.060235</td>\n",
       "      <td>-0.406465</td>\n",
       "      <td>1.331972</td>\n",
       "      <td>1.533296</td>\n",
       "      <td>-0.759594</td>\n",
       "      <td>-0.765753</td>\n",
       "      <td>-0.111876</td>\n",
       "      <td>0.225191</td>\n",
       "      <td>-0.501364</td>\n",
       "      <td>0.095531</td>\n",
       "      <td>0.541944</td>\n",
       "      <td>-0.419761</td>\n",
       "      <td>1.187102</td>\n",
       "      <td>0.986660</td>\n",
       "      <td>-0.395733</td>\n",
       "      <td>0.387021</td>\n",
       "      <td>0.534711</td>\n",
       "      <td>0.483614</td>\n",
       "      <td>-0.260048</td>\n",
       "      <td>0.127165</td>\n",
       "      <td>-0.377836</td>\n",
       "      <td>-0.915420</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.049700</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>-0.492871</td>\n",
       "      <td>-0.406338</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>0.749103</td>\n",
       "      <td>-0.521930</td>\n",
       "      <td>0.799627</td>\n",
       "      <td>-0.034946</td>\n",
       "      <td>-1.414886</td>\n",
       "      <td>0.073785</td>\n",
       "      <td>-0.142013</td>\n",
       "      <td>0.054707</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>-0.452743</td>\n",
       "      <td>-0.292108</td>\n",
       "      <td>-0.404927</td>\n",
       "      <td>1.215832</td>\n",
       "      <td>-0.188363</td>\n",
       "      <td>-0.254359</td>\n",
       "      <td>-0.146385</td>\n",
       "      <td>-0.454595</td>\n",
       "      <td>-0.273597</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.223208</td>\n",
       "      <td>-0.366105</td>\n",
       "      <td>-0.271781</td>\n",
       "      <td>-0.175845</td>\n",
       "      <td>-0.219294</td>\n",
       "      <td>-0.326256</td>\n",
       "      <td>-0.485207</td>\n",
       "      <td>0.461096</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>-0.010951</td>\n",
       "      <td>-0.541191</td>\n",
       "      <td>-0.296320</td>\n",
       "      <td>-0.021512</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.061172</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>1.965883</td>\n",
       "      <td>0.163824</td>\n",
       "      <td>-0.765753</td>\n",
       "      <td>1.533296</td>\n",
       "      <td>573</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>-0.004333</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.738978</td>\n",
       "      <td>0.738317</td>\n",
       "      <td>2.170988</td>\n",
       "      <td>0.077535</td>\n",
       "      <td>-1.414886</td>\n",
       "      <td>1.239655</td>\n",
       "      <td>2.089128</td>\n",
       "      <td>0.208913</td>\n",
       "      <td>-0.492871</td>\n",
       "      <td>1.702379</td>\n",
       "      <td>-1.970019</td>\n",
       "      <td>-0.197002</td>\n",
       "      <td>-1.414886</td>\n",
       "      <td>0.799627</td>\n",
       "      <td>-3.045378</td>\n",
       "      <td>-0.507563</td>\n",
       "      <td>-0.703370</td>\n",
       "      <td>-0.292108</td>\n",
       "      <td>1.900967</td>\n",
       "      <td>0.475242</td>\n",
       "      <td>-0.828881</td>\n",
       "      <td>1.702379</td>\n",
       "      <td>-1.844489</td>\n",
       "      <td>-0.307415</td>\n",
       "      <td>-0.485207</td>\n",
       "      <td>-0.175845</td>\n",
       "      <td>-2.043974</td>\n",
       "      <td>-0.227108</td>\n",
       "      <td>-0.454595</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.485276</td>\n",
       "      <td>-0.161759</td>\n",
       "      <td>-0.273597</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>-0.855340</td>\n",
       "      <td>-0.285113</td>\n",
       "      <td>-0.454595</td>\n",
       "      <td>-0.146385</td>\n",
       "      <td>-2.232885</td>\n",
       "      <td>-0.124049</td>\n",
       "      <td>-0.543837</td>\n",
       "      <td>0.738317</td>\n",
       "      <td>-1.663682</td>\n",
       "      <td>-0.083184</td>\n",
       "      <td>-0.738978</td>\n",
       "      <td>0.799627</td>\n",
       "      <td>-2.462735</td>\n",
       "      <td>-0.136819</td>\n",
       "      <td>-0.738978</td>\n",
       "      <td>0.749103</td>\n",
       "      <td>0.216266</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>-0.915420</td>\n",
       "      <td>1.215832</td>\n",
       "      <td>1.627349</td>\n",
       "      <td>0.162735</td>\n",
       "      <td>-0.738978</td>\n",
       "      <td>1.239655</td>\n",
       "      <td>0.605178</td>\n",
       "      <td>0.201726</td>\n",
       "      <td>-0.010951</td>\n",
       "      <td>0.461096</td>\n",
       "      <td>0.104149</td>\n",
       "      <td>0.034716</td>\n",
       "      <td>-0.021512</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>-0.034673</td>\n",
       "      <td>-0.011558</td>\n",
       "      <td>-0.541191</td>\n",
       "      <td>0.461096</td>\n",
       "      <td>-0.080114</td>\n",
       "      <td>-0.026705</td>\n",
       "      <td>-0.296320</td>\n",
       "      <td>0.155033</td>\n",
       "      <td>-0.859022</td>\n",
       "      <td>-0.286341</td>\n",
       "      <td>-0.541191</td>\n",
       "      <td>-0.021512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature_00  feature_01  feature_02  feature_03  feature_04  \\\n",
       "32496013   -0.273723   -0.628400    0.021183    0.326928    0.120378   \n",
       "32496014    0.516346   -0.358216    0.170515    0.457404    0.704279   \n",
       "32496015   -0.276064   -0.562562    0.126326    0.341234    0.648612   \n",
       "32496016    0.048198   -0.705530   -0.000436    0.377266   -0.100474   \n",
       "32496017    0.726119   -0.738978   -0.543837   -0.127495    0.738317   \n",
       "\n",
       "          feature_05  feature_06  feature_07  feature_08  feature_09  \\\n",
       "32496013   -0.017101    0.293846    0.267356    0.739021          42   \n",
       "32496014   -0.016830    0.200757    0.196041    1.106106          11   \n",
       "32496015   -0.010778    0.217542    0.150108    0.763144          68   \n",
       "32496016   -0.014540    0.407335    0.410498    0.778039          34   \n",
       "32496017   -0.016428    0.349479    0.261747    1.239655          50   \n",
       "\n",
       "          feature_10  feature_11  feature_12  feature_13  feature_14  \\\n",
       "32496013           5         150    0.886931    0.800840    0.619701   \n",
       "32496014           7          76    0.569555    0.320779    0.445927   \n",
       "32496015           6         388   -0.154750    0.241596   -0.084922   \n",
       "32496016           4         214    0.412368    1.015218    0.308765   \n",
       "32496017           1         522   -0.284493   -0.111495   -0.307370   \n",
       "\n",
       "          feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
       "32496013   -0.944317   -0.731467   -0.826058    1.270973    2.309707   \n",
       "32496014    0.833764    0.766083    0.760303    2.978000    0.180232   \n",
       "32496015   -0.210215   -0.473479   -0.281191    0.932661   -1.085921   \n",
       "32496016   -0.950215   -0.248845   -0.995436    0.486453    1.312123   \n",
       "32496017   -0.666224   -0.526006   -0.703370    1.702379   -0.828881   \n",
       "\n",
       "          feature_20  feature_21  feature_22  feature_23  feature_24  \\\n",
       "32496013   -0.168244   -0.180836   -0.228961   -0.731446    0.499912   \n",
       "32496014   -0.071296    0.833885   -0.442648    1.909253    1.260226   \n",
       "32496015   -0.415765    0.663795   -0.465737    1.354075    2.110133   \n",
       "32496016   -1.498882   -0.192676   -0.928796   -1.160311    0.198818   \n",
       "32496017   -0.261229   -0.142134    1.071015    0.095017    0.441871   \n",
       "\n",
       "          feature_25  feature_26  feature_27  feature_28  feature_29  \\\n",
       "32496013   -0.058762   -1.233727    0.421452    1.658583   -0.643178   \n",
       "32496014    2.173384    0.124759   -1.742508   -2.060564    2.431904   \n",
       "32496015    2.677571   -0.370774   -2.367140   -1.442387    0.450709   \n",
       "32496016   -0.378694    0.325012   -1.749679   -1.901364   -0.891058   \n",
       "32496017   -0.060235   -0.406465    1.331972    1.533296   -0.759594   \n",
       "\n",
       "          feature_30  feature_31  feature_32  feature_33  feature_34  \\\n",
       "32496013   -0.641713   -0.127338    1.012934   -0.808432    0.640629   \n",
       "32496014    0.894903    1.336326    0.233143    0.268164    0.180035   \n",
       "32496015   -0.131176    0.483004    0.787535   -0.551896    0.947080   \n",
       "32496016   -0.919408   -0.148865   -0.459053   -0.338284    0.518999   \n",
       "32496017   -0.765753   -0.111876    0.225191   -0.501364    0.095531   \n",
       "\n",
       "          feature_35  feature_36  feature_37  feature_38  feature_39  \\\n",
       "32496013    0.046857   -0.553982   -0.097041   -0.199727   -0.778504   \n",
       "32496014   -0.047150   -0.035961    1.073607    0.868699    1.179430   \n",
       "32496015    0.807590   -0.549592    0.100099    0.098323    0.180247   \n",
       "32496016    0.109611   -1.465696   -0.033068    0.006976    0.565646   \n",
       "32496017    0.541944   -0.419761    1.187102    0.986660   -0.395733   \n",
       "\n",
       "          feature_40  feature_41  feature_42  feature_43  feature_44  \\\n",
       "32496013    0.546700    0.259686   -0.897121   -0.245391   -0.181529   \n",
       "32496014    0.910744    0.365738   -0.806121   -1.221758   -0.294194   \n",
       "32496015    1.340250   -0.481007    1.146693   -0.012450    0.033310   \n",
       "32496016   -0.376636   -0.389352    0.796484    0.069480    0.411968   \n",
       "32496017    0.387021    0.534711    0.483614   -0.260048    0.127165   \n",
       "\n",
       "          feature_45  feature_46  feature_47  feature_48  feature_49  \\\n",
       "32496013   -0.041429   -0.114340    0.074312   -0.162039   -0.156312   \n",
       "32496014   -0.309661   -1.669550   -1.185478   -0.013506   -0.296199   \n",
       "32496015   -0.014503    0.447920    0.086581   -0.195873    0.004835   \n",
       "32496016    0.808051    0.978345    0.280803    0.242483    0.710215   \n",
       "32496017   -0.377836   -0.915420   -0.005872   -0.049700    0.013723   \n",
       "\n",
       "          feature_50  feature_51  feature_52  feature_53  feature_54  \\\n",
       "32496013   -0.445739   -0.194293   -0.992565    0.026359    0.776747   \n",
       "32496014    0.629851    1.619304    0.130224   -1.331440   -1.206886   \n",
       "32496015    0.530240   -0.618310   -0.746920    0.534145   -0.556152   \n",
       "32496016    1.463319   -0.488809    0.659116    2.040899    0.413254   \n",
       "32496017   -0.492871   -0.406338   -0.043089    0.749103   -0.521930   \n",
       "\n",
       "          feature_55  feature_56  feature_57  feature_58  feature_59  \\\n",
       "32496013    0.515383   -0.310368    0.715174    0.382011   -0.057844   \n",
       "32496014   -0.506745   -0.665731   -1.265526   -1.339285    0.179611   \n",
       "32496015    0.391937    0.606587    1.020363    0.241115   -0.063700   \n",
       "32496016    1.128831    0.767357    1.831824    0.678784    0.461269   \n",
       "32496017    0.799627   -0.034946   -1.414886    0.073785   -0.142013   \n",
       "\n",
       "          feature_60  feature_61  feature_62  feature_63  feature_64  \\\n",
       "32496013   -0.040984    0.796951   -0.526368   -0.235048   -0.354705   \n",
       "32496014   -0.155559    0.796951   -0.099937    0.127875   -0.027559   \n",
       "32496015    0.080730    0.796951   -0.368261   -0.287799   -0.280969   \n",
       "32496016    0.819580    0.796951   -0.427502   -0.318685   -0.264619   \n",
       "32496017    0.054707    0.796951   -0.452743   -0.292108   -0.404927   \n",
       "\n",
       "          feature_65  feature_66  feature_67  feature_68  feature_69  \\\n",
       "32496013    1.505933    1.735560    0.519725    0.034015    0.247436   \n",
       "32496014    2.582265   -0.386582    1.081167   -0.309833    0.429599   \n",
       "32496015    0.449343    1.240352   -0.351033    0.879358   -0.191713   \n",
       "32496016   -0.073792    1.567347    0.145724    0.456878   -0.023279   \n",
       "32496017    1.215832   -0.188363   -0.254359   -0.146385   -0.454595   \n",
       "\n",
       "          feature_70  feature_71  feature_72  feature_73  feature_74  \\\n",
       "32496013    1.266712    1.023329    1.049752   -0.020475    0.000255   \n",
       "32496014    0.702698    0.696585    0.391108   -0.312883   -0.507126   \n",
       "32496015   -0.081830   -0.143664    0.025583   -0.265242   -0.402117   \n",
       "32496016    0.530322    1.483768    0.636709   -0.563597   -0.828064   \n",
       "32496017   -0.273597    0.011529   -0.223208   -0.366105   -0.271781   \n",
       "\n",
       "          feature_75  feature_76  feature_77  feature_78  responder_0_lag_1  \\\n",
       "32496013   -0.234894   -0.328479   -0.167722   -0.107061           0.013119   \n",
       "32496014   -0.303390   -0.442164   -0.255057   -0.366450          -0.150453   \n",
       "32496015   -0.290549   -0.336317   -0.207405   -0.323209          -0.063781   \n",
       "32496016   -0.598701   -0.625653   -0.810607   -0.975171          -0.226147   \n",
       "32496017   -0.175845   -0.219294   -0.326256   -0.485207           0.461096   \n",
       "\n",
       "          responder_1_lag_1  responder_2_lag_1  responder_3_lag_1  \\\n",
       "32496013           0.299852           0.113701           0.191003   \n",
       "32496014           0.697600          -2.491776           0.146255   \n",
       "32496015           0.286257           1.291592           0.117581   \n",
       "32496016          -0.275249          -0.060692           0.117830   \n",
       "32496017           0.155033          -0.010951          -0.541191   \n",
       "\n",
       "          responder_4_lag_1  responder_5_lag_1  responder_6_lag_1  \\\n",
       "32496013           0.090730          -0.233323          -0.171773   \n",
       "32496014           0.055375          -0.119033           0.025655   \n",
       "32496015           0.050176          -0.013990          -0.005065   \n",
       "32496016           0.084099           0.020054           0.030628   \n",
       "32496017          -0.296320          -0.021512           0.045422   \n",
       "\n",
       "          responder_7_lag_1  responder_8_lag_1  feature_tag_0_sum  \\\n",
       "32496013          -0.042368          -0.313162          -1.434256   \n",
       "32496014           0.050160           0.044680           6.647622   \n",
       "32496015           0.032325          -0.019257           2.546308   \n",
       "32496016           0.043376           0.028681          -9.245903   \n",
       "32496017           0.061172           0.136612           1.965883   \n",
       "\n",
       "          feature_tag_0_mean  feature_tag_0_min  feature_tag_0_max  \\\n",
       "32496013           -0.119521          -1.233727           1.658583   \n",
       "32496014            0.553968          -2.060564           2.431904   \n",
       "32496015            0.212192          -2.367140           2.677571   \n",
       "32496016           -0.770492          -1.901364           0.325012   \n",
       "32496017            0.163824          -0.765753           1.533296   \n",
       "\n",
       "          feature_tag_1_sum  feature_tag_1_mean  feature_tag_1_min  \\\n",
       "32496013                197           65.666664                  5   \n",
       "32496014                 94           31.333334                  7   \n",
       "32496015                462          154.000000                  6   \n",
       "32496016                252           84.000000                  4   \n",
       "32496017                573          191.000000                  1   \n",
       "\n",
       "          feature_tag_1_max  feature_tag_2_sum  feature_tag_2_mean  \\\n",
       "32496013                150          -0.095627           -0.009563   \n",
       "32496014                 76           2.088558            0.208856   \n",
       "32496015                388           1.718264            0.171826   \n",
       "32496016                214          -2.015399           -0.201540   \n",
       "32496017                522          -0.004333           -0.000433   \n",
       "\n",
       "          feature_tag_2_min  feature_tag_2_max  feature_tag_3_sum  \\\n",
       "32496013          -0.808432           1.012934          -0.335731   \n",
       "32496014          -0.358216           0.704279          -3.824358   \n",
       "32496015          -0.562562           0.947080           5.274477   \n",
       "32496016          -1.465696           0.518999          15.428149   \n",
       "32496017          -0.738978           0.738317           2.170988   \n",
       "\n",
       "          feature_tag_3_mean  feature_tag_3_min  feature_tag_3_max  \\\n",
       "32496013           -0.011990          -0.992565           0.776747   \n",
       "32496014           -0.136584          -1.669550           1.619304   \n",
       "32496015            0.188374          -0.746920           1.340250   \n",
       "32496016            0.551005          -0.488809           2.040899   \n",
       "32496017            0.077535          -1.414886           1.239655   \n",
       "\n",
       "          feature_tag_4_sum  feature_tag_4_mean  feature_tag_4_min  \\\n",
       "32496013           0.820393            0.082039          -0.992565   \n",
       "32496014           9.420164            0.942016          -0.665731   \n",
       "32496015           2.178590            0.217859          -0.746920   \n",
       "32496016           3.421353            0.342135          -0.488809   \n",
       "32496017           2.089128            0.208913          -0.492871   \n",
       "\n",
       "          feature_tag_4_max  feature_tag_5_sum  feature_tag_5_mean  \\\n",
       "32496013           1.505933           4.640548            0.464055   \n",
       "32496014           2.978000          -8.508570           -0.850857   \n",
       "32496015           1.340250           3.160197            0.316020   \n",
       "32496016           1.463319          10.550554            1.055055   \n",
       "32496017           1.702379          -1.970019           -0.197002   \n",
       "\n",
       "          feature_tag_5_min  feature_tag_5_max  feature_tag_6_sum  \\\n",
       "32496013          -0.897121           2.309707          -3.617962   \n",
       "32496014          -1.669550           0.180232           2.360528   \n",
       "32496015          -1.085921           1.240352          -1.901915   \n",
       "32496016           0.069480           2.040899          -3.205302   \n",
       "32496017          -1.414886           0.799627          -3.045378   \n",
       "\n",
       "          feature_tag_6_mean  feature_tag_6_min  feature_tag_6_max  \\\n",
       "32496013           -0.602994          -0.944317          -0.235048   \n",
       "32496014            0.393421          -0.099937           0.833764   \n",
       "32496015           -0.316986          -0.473479          -0.210215   \n",
       "32496016           -0.534217          -0.995436          -0.248845   \n",
       "32496017           -0.507563          -0.703370          -0.292108   \n",
       "\n",
       "          feature_tag_7_sum  feature_tag_7_mean  feature_tag_7_min  \\\n",
       "32496013           6.822173            1.705543           1.270973   \n",
       "32496014           5.353916            1.338479          -0.386582   \n",
       "32496015           1.536435            0.384109          -1.085921   \n",
       "32496016           3.292131            0.823033          -0.073792   \n",
       "32496017           1.900967            0.475242          -0.828881   \n",
       "\n",
       "          feature_tag_7_max  feature_tag_8_sum  feature_tag_8_mean  \\\n",
       "32496013           2.309707          -0.858376           -0.143063   \n",
       "32496014           2.978000          -2.187071           -0.364512   \n",
       "32496015           1.240352          -1.824840           -0.304140   \n",
       "32496016           1.567347          -4.401793           -0.733632   \n",
       "32496017           1.702379          -1.844489           -0.307415   \n",
       "\n",
       "          feature_tag_8_min  feature_tag_8_max  feature_tag_9_sum  \\\n",
       "32496013          -0.328479           0.000255           6.448441   \n",
       "32496014          -0.507126          -0.255057           4.327584   \n",
       "32496015          -0.402117          -0.207405           0.138625   \n",
       "32496016          -0.975171          -0.563597           4.966471   \n",
       "32496017          -0.485207          -0.175845          -2.043974   \n",
       "\n",
       "          feature_tag_9_mean  feature_tag_9_min  feature_tag_9_max  \\\n",
       "32496013            0.716493           0.034015           1.266712   \n",
       "32496014            0.480843          -0.309833           1.081167   \n",
       "32496015            0.015403          -0.351033           0.879358   \n",
       "32496016            0.551830          -0.023279           1.483768   \n",
       "32496017           -0.227108          -0.454595           0.011529   \n",
       "\n",
       "          feature_tag_10_sum  feature_tag_10_mean  feature_tag_10_min  \\\n",
       "32496013            3.339793             1.113264            1.023329   \n",
       "32496014            1.790391             0.596797            0.391108   \n",
       "32496015           -0.199912            -0.066637           -0.143664   \n",
       "32496016            2.650798             0.883599            0.530322   \n",
       "32496017           -0.485276            -0.161759           -0.273597   \n",
       "\n",
       "          feature_tag_10_max  feature_tag_11_sum  feature_tag_11_mean  \\\n",
       "32496013            1.266712            0.801176             0.267059   \n",
       "32496014            0.702698            1.200932             0.400311   \n",
       "32496015            0.025583            0.336612             0.112204   \n",
       "32496016            1.483768            0.579322             0.193107   \n",
       "32496017            0.011529           -0.855340            -0.285113   \n",
       "\n",
       "          feature_tag_11_min  feature_tag_11_max  feature_tag_12_sum  \\\n",
       "32496013            0.034015            0.519725            1.514229   \n",
       "32496014           -0.309833            1.081167            2.343069   \n",
       "32496015           -0.351033            0.879358            0.872881   \n",
       "32496016           -0.023279            0.456878            0.844747   \n",
       "32496017           -0.454595           -0.146385           -2.232885   \n",
       "\n",
       "          feature_tag_12_mean  feature_tag_12_min  feature_tag_12_max  \\\n",
       "32496013             0.084124           -0.731467            1.023329   \n",
       "32496014             0.130170           -1.221758            1.619304   \n",
       "32496015             0.048493           -0.618310            1.340250   \n",
       "32496016             0.046930           -1.465696            1.483768   \n",
       "32496017            -0.124049           -0.543837            0.738317   \n",
       "\n",
       "          feature_tag_13_sum  feature_tag_13_mean  feature_tag_13_min  \\\n",
       "32496013           -1.364271            -0.068214           -0.992565   \n",
       "32496014            1.805695             0.090285           -0.506745   \n",
       "32496015           -1.777448            -0.088872           -0.746920   \n",
       "32496016           -0.495891            -0.024795           -1.465696   \n",
       "32496017           -1.663682            -0.083184           -0.738978   \n",
       "\n",
       "          feature_tag_13_max  feature_tag_14_sum  feature_tag_14_mean  \\\n",
       "32496013            1.049752           -1.170940            -0.065052   \n",
       "32496014            0.760303            0.056800             0.003156   \n",
       "32496015            0.807590            0.271808             0.015100   \n",
       "32496016            1.128831            2.675762             0.148653   \n",
       "32496017            0.799627           -2.462735            -0.136819   \n",
       "\n",
       "          feature_tag_14_min  feature_tag_14_max  feature_tag_15_sum  \\\n",
       "32496013           -0.944317            1.266712            1.226355   \n",
       "32496014           -1.339285            1.179430           -0.347543   \n",
       "32496015           -0.562562            1.146693            4.085620   \n",
       "32496016           -0.950215            2.040899            5.377185   \n",
       "32496017           -0.738978            0.749103            0.216266   \n",
       "\n",
       "          feature_tag_15_mean  feature_tag_15_min  feature_tag_15_max  \\\n",
       "32496013             0.072139           -0.897121            1.735560   \n",
       "32496014            -0.020444           -1.669550            2.582265   \n",
       "32496015             0.240331           -0.481007            1.340250   \n",
       "32496016             0.316305           -0.427502            1.567347   \n",
       "32496017             0.012722           -0.915420            1.215832   \n",
       "\n",
       "          feature_tag_16_sum  feature_tag_16_mean  feature_tag_16_min  \\\n",
       "32496013            0.681245             0.068125           -0.628400   \n",
       "32496014            2.905105             0.290511           -0.358216   \n",
       "32496015            0.981798             0.098180           -0.562562   \n",
       "32496016           -0.298527            -0.029853           -1.498882   \n",
       "32496017            1.627349             0.162735           -0.738978   \n",
       "\n",
       "          feature_tag_16_max  responder_tag_0_sum  responder_tag_0_mean  \\\n",
       "32496013            0.739021             0.426673              0.142224   \n",
       "32496014            1.106106            -1.944628             -0.648209   \n",
       "32496015            0.763144             1.514069              0.504690   \n",
       "32496016            0.778039            -0.562088             -0.187363   \n",
       "32496017            1.239655             0.605178              0.201726   \n",
       "\n",
       "          responder_tag_0_min  responder_tag_0_max  responder_tag_1_sum  \\\n",
       "32496013             0.013119             0.299852            -0.432783   \n",
       "32496014            -2.491776             0.697600            -2.566129   \n",
       "32496015            -0.063781             1.291592             1.258345   \n",
       "32496016            -0.275249            -0.060692            -0.011957   \n",
       "32496017            -0.010951             0.461096             0.104149   \n",
       "\n",
       "          responder_tag_1_mean  responder_tag_1_min  responder_tag_1_max  \\\n",
       "32496013             -0.144261            -0.313162             0.113701   \n",
       "32496014             -0.855376            -2.491776             0.044680   \n",
       "32496015              0.419448            -0.019257             1.291592   \n",
       "32496016             -0.003986            -0.060692             0.028681   \n",
       "32496017              0.034716            -0.021512             0.136612   \n",
       "\n",
       "          responder_tag_2_sum  responder_tag_2_mean  responder_tag_2_min  \\\n",
       "32496013             0.032349              0.010783            -0.171773   \n",
       "32496014             0.021457              0.007152            -0.150453   \n",
       "32496015             0.048735              0.016245            -0.063781   \n",
       "32496016            -0.077689             -0.025896            -0.226147   \n",
       "32496017            -0.034673             -0.011558            -0.541191   \n",
       "\n",
       "          responder_tag_2_max  responder_tag_3_sum  responder_tag_3_mean  \\\n",
       "32496013             0.191003             0.348215              0.116072   \n",
       "32496014             0.146255             0.803136              0.267712   \n",
       "32496015             0.117581             0.368758              0.122919   \n",
       "32496016             0.117830            -0.147774             -0.049258   \n",
       "32496017             0.461096            -0.080114             -0.026705   \n",
       "\n",
       "          responder_tag_3_min  responder_tag_3_max  responder_tag_4_sum  \\\n",
       "32496013            -0.042368             0.299852             0.048410   \n",
       "32496014             0.050160             0.697600             0.082597   \n",
       "32496015             0.032325             0.286257             0.153766   \n",
       "32496016            -0.275249             0.084099             0.221983   \n",
       "32496017            -0.296320             0.155033            -0.859022   \n",
       "\n",
       "          responder_tag_4_mean  responder_tag_4_min  responder_tag_4_max  \n",
       "32496013              0.016137            -0.233323             0.191003  \n",
       "32496014              0.027532            -0.119033             0.146255  \n",
       "32496015              0.051255            -0.013990             0.117581  \n",
       "32496016              0.073994             0.020054             0.117830  \n",
       "32496017             -0.286341            -0.541191            -0.021512  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's l2: 0.752728\tvalid_1's l2: 0.662547\n",
      "[20]\ttraining's l2: 0.750678\tvalid_1's l2: 0.661368\n",
      "[30]\ttraining's l2: 0.749285\tvalid_1's l2: 0.660442\n",
      "[40]\ttraining's l2: 0.748214\tvalid_1's l2: 0.659759\n",
      "[50]\ttraining's l2: 0.747242\tvalid_1's l2: 0.659081\n",
      "[60]\ttraining's l2: 0.746448\tvalid_1's l2: 0.658688\n",
      "[70]\ttraining's l2: 0.745753\tvalid_1's l2: 0.658353\n",
      "[80]\ttraining's l2: 0.7451\tvalid_1's l2: 0.658154\n",
      "[90]\ttraining's l2: 0.744484\tvalid_1's l2: 0.657973\n",
      "[100]\ttraining's l2: 0.743828\tvalid_1's l2: 0.657822\n",
      "[110]\ttraining's l2: 0.743307\tvalid_1's l2: 0.657693\n",
      "[120]\ttraining's l2: 0.742814\tvalid_1's l2: 0.657598\n",
      "[130]\ttraining's l2: 0.74232\tvalid_1's l2: 0.657543\n",
      "[140]\ttraining's l2: 0.741719\tvalid_1's l2: 0.657459\n",
      "[150]\ttraining's l2: 0.74115\tvalid_1's l2: 0.657464\n",
      "[160]\ttraining's l2: 0.740626\tvalid_1's l2: 0.65751\n",
      "[170]\ttraining's l2: 0.740244\tvalid_1's l2: 0.657467\n",
      "[180]\ttraining's l2: 0.739768\tvalid_1's l2: 0.657459\n",
      "[190]\ttraining's l2: 0.739412\tvalid_1's l2: 0.657419\n",
      "[200]\ttraining's l2: 0.739066\tvalid_1's l2: 0.657375\n",
      "[210]\ttraining's l2: 0.738678\tvalid_1's l2: 0.657341\n",
      "[220]\ttraining's l2: 0.738243\tvalid_1's l2: 0.657302\n",
      "[230]\ttraining's l2: 0.737912\tvalid_1's l2: 0.657325\n",
      "[240]\ttraining's l2: 0.737603\tvalid_1's l2: 0.657328\n",
      "[250]\ttraining's l2: 0.737305\tvalid_1's l2: 0.657317\n",
      "Best iteration: 221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Weighted R2 score is: 0.010636682826810406\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb_online_learning(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d5b42e-8908-4589-9756-d4fb977ef6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Kaggle\\kaggle_venvs\\ml\\Lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The LGBMRegressor or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(device=&#x27;gpu&#x27;, early_stopping_round=30, feature_fraction=0.8,\n",
       "              lambda_l2=100, learning_rate=0.05, n_estimators=90000,\n",
       "              verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMRegressor</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(device=&#x27;gpu&#x27;, early_stopping_round=30, feature_fraction=0.8,\n",
       "              lambda_l2=100, learning_rate=0.05, n_estimators=90000,\n",
       "              verbosity=-1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(device='gpu', early_stopping_round=30, feature_fraction=0.8,\n",
       "              lambda_l2=100, learning_rate=0.05, n_estimators=90000,\n",
       "              verbosity=-1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bc310b8-2089-42ee-8c3b-80545060deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(models_path):\n",
    "    os.makedirs(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35c3859c-b79e-426f-9799-fffdb93d3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(models_path + \"lgb_model.pkl\", 'wb') as file:\n",
    "    pickle.dump(lgb_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39434e67-a55d-4d4a-8ee4-95be6fcdec87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc23fa-424a-4619-8c83-a498bbd31ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24574fb2-f835-4e8b-81ca-d2f95aa1820f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea131c-3689-4487-839d-294d6cc766b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6481689-dd74-4926-963a-ae87a57dfb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aeb52f-e56a-42bc-bd7e-1159380dfd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88c1a0-44a4-4faa-b018-40a4540e5297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f63de2-58ea-4fa8-8498-3a80e0685540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d54162-0ff9-4e50-ba3e-c132603c5f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c40b8d-078f-4bf2-bf0e-f56f2a9ec278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb4278-3b73-4eb5-8949-01b02095e5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e433b1-b971-497d-9c2c-947b734a5ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb20dd-2150-426f-8739-2f63402dc7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4651e-f019-4e55-8ce4-b03aae6c1c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c8234-33e1-4891-9527-58d15c529e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47aa04-b2ad-48db-a1b4-1939520ab885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6684c-98f8-447c-8b58-28f1d21aef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open(f\"{models_path}/lgb_model.pkl\", \"rb\") as f:\n",
    "    lgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df7914-ec21-4603-9388-57043c98ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = train_df.filter(pl.col('date_id') > 1300)\n",
    "print(val_df.shape)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1e705-b82e-45f8-b992-bdb9595408a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389887f7-ef29-40d3-9595-f4af0b63b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_online_learning(val_data, current_model, optuna_n_trials):\n",
    "    val_data = val_data.clone()\n",
    "    print('this is the initial validation data')\n",
    "    print(val_data.shape)\n",
    "    display(val_data.head())\n",
    "    display(val_data.tail())\n",
    "    i = 0\n",
    "    val_date_ids = sorted(val_data['date_id'].unique())\n",
    "    for date_id_v in val_date_ids:\n",
    "        date_id_df = val_data.filter(pl.col('date_id') == date_id_v)\n",
    "        print('this is date_id_df')\n",
    "        print(date_id_df.shape)\n",
    "        display(date_id_df.head())\n",
    "        display(date_id_df.tail())\n",
    "        \n",
    "        X_train = date_id_df.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "        y_train = date_id_df['responder_6'].to_pandas()\n",
    "        weights_train = date_id_df['weight'].to_pandas()\n",
    "\n",
    "        #train_dataset = lgb.Dataset(data=X_train, label=y_train, weight=weights_train)\n",
    "\n",
    "        val_data = val_data[date_id_df.shape[0]:]\n",
    "        print('this is updated validation data')\n",
    "        print(val_data.shape)\n",
    "        display(val_data.head())\n",
    "        display(val_data.tail())\n",
    "\n",
    "        X_val = val_data.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "        y_val = val_data['responder_6'].to_pandas()\n",
    "        weights_val = val_data['weight'].to_pandas()\n",
    "\n",
    "        #val_dataset = lgb.Dataset(data=X_val, label=y_val, weight=weights_val)\n",
    "\n",
    "        '''base_params = {\n",
    "            'verbosity': -1,\n",
    "            'learning_rate': 1,\n",
    "            #'feature_fraction': 0.8,\n",
    "            'device': 'gpu',\n",
    "            'early_stopping_round': 30,\n",
    "            #'lambda_l2': 100\n",
    "        }'''\n",
    "\n",
    "        '''updated_model = lgb.train(\n",
    "            params=base_params,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=[train_dataset, val_dataset],\n",
    "            num_boost_round=90,\n",
    "            init_model=current_model,\n",
    "            callbacks=[log_evaluation(period=50), record_evaluation()]\n",
    "        )'''\n",
    "    \n",
    "        '''online_model = LGBMRegressor(\n",
    "            **base_params,\n",
    "            n_estimators=100000\n",
    "        )'''\n",
    "\n",
    "        '''current_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "        #current_model.fit(X_val, y_val, sample_weight=weights_val, eval_set=[(X_val, y_val), (X_train, y_train)], eval_sample_weight=[weights_val, weights_train], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "        #display(online_model)\n",
    "\n",
    "        plt.figure()\n",
    "        lgb.plot_metric(current_model)\n",
    "        plt.ylim(0, 2)\n",
    "        plt.show()\n",
    "        \n",
    "        val_preds = current_model.predict(X_val)\n",
    "        \n",
    "        return current_model'''\n",
    "\n",
    "        base_params = {\n",
    "            'verbosity': -1,\n",
    "            #'learning_rate': 0.05,\n",
    "            #'feature_fraction': 0.8,\n",
    "            'device': 'gpu',\n",
    "            'early_stopping_round': 10,\n",
    "            #'lambda_l2': 100,\n",
    "            'seed': 42\n",
    "        }\n",
    "\n",
    "        def objective(trial):\n",
    "\n",
    "            params_to_tune = {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.03),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 300),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 4000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 2, 3),\n",
    "                'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 0.3),\n",
    "                'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "                'lambda_l2': trial.suggest_float('lambda_l2', 1000, 2000)\n",
    "            }\n",
    "\n",
    "            online_model = LGBMRegressor(\n",
    "                **base_params,\n",
    "                **params_to_tune,\n",
    "                n_estimators=100000\n",
    "            )\n",
    "\n",
    "            online_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], init_model=current_model)\n",
    "            #online_model.fit(X_val, y_val, sample_weight=weights_val, eval_set=[(X_val, y_val), (X_train, y_train)], eval_sample_weight=[weights_val, weights_train], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "            '''plt.figure()\n",
    "            lgb.plot_metric(online_model)\n",
    "            plt.ylim(0, 2)\n",
    "            plt.show()'''\n",
    "\n",
    "            #best_iteration = online_model.best_iteration_\n",
    "            #print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "            val_preds = online_model.predict(X_val)\n",
    "\n",
    "            val_r2_score = r2_score(y_val, val_preds, sample_weight=weights_val)\n",
    "\n",
    "            return val_r2_score\n",
    "\n",
    "        with tqdm(total=optuna_n_trials, desc=\"Optimizing\", unit=\"trial\") as pbar:\n",
    "    \n",
    "            # Define a callback function to update the progress bar\n",
    "            def progress_bar_callback(study, trial):\n",
    "                pbar.update(1)\n",
    "        \n",
    "            study = optuna.create_study(direction=\"maximize\")\n",
    "            study.optimize(objective, n_trials=optuna_n_trials, callbacks=[progress_bar_callback])\n",
    "\n",
    "        return study\n",
    "    \n",
    "        best_params = study.best_params\n",
    "\n",
    "        online_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "        display(online_model)\n",
    "\n",
    "        plt.figure()\n",
    "        lgb.plot_metric(online_model)\n",
    "        plt.ylim(0, 2)\n",
    "        plt.show()\n",
    "        \n",
    "        val_preds = online_model.predict(X_val)\n",
    "\n",
    "        print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "        return online_model\n",
    "\n",
    "        if i > 20:\n",
    "            return\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82f864-8066-48e1-9afb-184bc933850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study = val_online_learning(val_df, lgb_model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd780c53-9568-480d-bc02-b28fc79566d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in lgb_study.best_params.keys():\n",
    "    fig = plot_slice(lgb_study, params=[param])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae940b42-2237-4577-bbe4-5a3b08bec314",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(lgb_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157c449-2f9c-45ae-a31a-c7a2e4c7c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5b2e5-0bce-41c2-8fcc-dd6e22a00aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa6a0f-3cc5-45a6-a111-d7f054c262be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_df = pd.DataFrame({k:[lgb_study.best_params[k]] for k in lgb_study.best_params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e7532-c40e-4ea6-8e4d-f4a0d96650d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69b03b-80e1-45c0-b742-063d9e9ee361",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_df.to_csv(models_path + 'lgb_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b4c48-301e-4940-934e-b471272dd261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params_dict(params_df):\n",
    "    params_dict = {}\n",
    "    for col in params_df.columns:\n",
    "        v = params_df[col][0]\n",
    "        if type(v) == np.int64:\n",
    "            v = int(v)\n",
    "        params_dict[col] = v\n",
    "\n",
    "    return params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e61b03-9287-4a98-bee1-0259004823b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params_dict = create_params_dict(lgb_params_df)\n",
    "lgb_params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd110dc-19db-4002-9675-c5206b3ba329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b6282-1d42-4d92-a501-529f7da27e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119ec0b-151f-4c3e-a44f-909c59d8b25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66242a14-9e00-4e9c-96a9-f7b2c09d3ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e0e9d-517b-4ee8-8998-438e28026201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f98a4-a2dc-475d-ac3e-14c62606e802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321b527-d9a1-4977-94bf-661d62e83be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5bfc2-0c8d-4dc5-9c1f-a02595836d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_df.drop(['date_id', 'time_id', 'symbol_id']).columns\n",
    "imp_df = pd.DataFrame(sorted(zip(cols, first_shap_importance)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459cef0-80a6-4b90-9918-332b449c380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506da0e-1120-4d22-99b8-31da7adc1a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7e244-dc03-4612-a335-bd7366f6a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 40))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(imp_df['Feature'], imp_df['Importance'])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c5ce2-6075-47e7-8bf5-98468f451b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_df = imp_df[imp_df['Importance'] <= imp_df['Importance'].quantile(0.3)]\n",
    "unimportant_cols = unimportant_df['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc98e4-b6c4-41a2-b1bf-e63e16828ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected_df = train_df.drop(unimportant_cols)\n",
    "print(train_selected_df.shape)\n",
    "train_selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8c121-661f-4c90-8e3b-c9aa62bf2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_shap_importance = lgb_train(train_selected_df, y_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c749891-7ec2-4ea7-b4a3-40691e436f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
