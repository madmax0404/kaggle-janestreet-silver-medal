{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6e3e10-78d2-413c-87c3-f256294da062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor, log_evaluation, record_evaluation\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.impute import IterativeImputer\n",
    "import pickle\n",
    "import optuna\n",
    "import shap\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "pl.Config.set_fmt_str_lengths(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5a256f-c55b-415d-8d12-e753283ffee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'I:/Kaggle/jane-street-real-time-market-data-forecasting/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d215c3-e2a4-4ea2-8125-708737b10ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features.csv',\n",
       " 'kaggle_evaluation',\n",
       " 'lags.parquet',\n",
       " 'my_folder',\n",
       " 'responders.csv',\n",
       " 'sample_submission.csv',\n",
       " 'team_folder',\n",
       " 'test.parquet',\n",
       " 'train.parquet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab47b6d-409b-41a7-a443-fcddc750f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47127338, 93)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_39</th><th>feature_40</th><th>feature_41</th><th>feature_42</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>3.889038</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.851033</td><td>0.242971</td><td>0.2634</td><td>-0.891687</td><td>11</td><td>7</td><td>76</td><td>-0.883028</td><td>0.003067</td><td>-0.744703</td><td>null</td><td>-0.169586</td><td>null</td><td>-1.335938</td><td>-1.707803</td><td>0.91013</td><td>null</td><td>1.636431</td><td>1.522133</td><td>-1.551398</td><td>-0.229627</td><td>null</td><td>null</td><td>1.378301</td><td>-0.283712</td><td>0.123196</td><td>null</td><td>null</td><td>null</td><td>0.28118</td><td>0.269163</td><td>0.349028</td><td>-0.012596</td><td>-0.225932</td><td>null</td><td>-1.073602</td><td>null</td><td>null</td><td>-0.181716</td><td>null</td><td>null</td><td>null</td><td>0.564021</td><td>2.088506</td><td>0.832022</td><td>null</td><td>0.204797</td><td>null</td><td>null</td><td>-0.808103</td><td>null</td><td>-2.037683</td><td>0.727661</td><td>null</td><td>-0.989118</td><td>-0.345213</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.251104</td><td>-0.110252</td><td>-0.491157</td><td>-1.02269</td><td>0.152241</td><td>-0.659864</td><td>null</td><td>null</td><td>-0.261412</td><td>-0.211486</td><td>-0.335556</td><td>-0.281498</td><td>0.775981</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>7</td><td>1.370613</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.676961</td><td>0.151984</td><td>0.192465</td><td>-0.521729</td><td>11</td><td>7</td><td>76</td><td>-0.865307</td><td>-0.225629</td><td>-0.582163</td><td>null</td><td>0.317467</td><td>null</td><td>-1.250016</td><td>-1.682929</td><td>1.412757</td><td>null</td><td>0.520378</td><td>0.744132</td><td>-0.788658</td><td>0.641776</td><td>null</td><td>null</td><td>0.2272</td><td>0.580907</td><td>1.128879</td><td>null</td><td>null</td><td>null</td><td>-1.512286</td><td>-1.414357</td><td>-1.823322</td><td>-0.082763</td><td>-0.184119</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-10.835207</td><td>-0.002704</td><td>-0.621836</td><td>null</td><td>1.172836</td><td>null</td><td>null</td><td>-1.625862</td><td>null</td><td>-1.410017</td><td>1.063013</td><td>null</td><td>0.888355</td><td>0.467994</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.065759</td><td>0.013322</td><td>-0.592855</td><td>-1.052685</td><td>-0.393726</td><td>-0.741603</td><td>null</td><td>null</td><td>-0.281207</td><td>-0.182894</td><td>-0.245565</td><td>-0.302441</td><td>0.703665</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>9</td><td>2.285698</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.056285</td><td>0.187227</td><td>0.249901</td><td>-0.77305</td><td>11</td><td>7</td><td>76</td><td>-0.675719</td><td>-0.199404</td><td>-0.586798</td><td>null</td><td>-0.814909</td><td>null</td><td>-1.296782</td><td>-2.040234</td><td>0.639589</td><td>null</td><td>1.597359</td><td>0.657514</td><td>-1.350148</td><td>0.364215</td><td>null</td><td>null</td><td>-0.017751</td><td>-0.317361</td><td>-0.122379</td><td>null</td><td>null</td><td>null</td><td>-0.320921</td><td>-0.95809</td><td>-2.436589</td><td>0.070999</td><td>-0.245239</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.420632</td><td>-3.515137</td><td>-4.67776</td><td>null</td><td>0.535897</td><td>null</td><td>null</td><td>-0.72542</td><td>null</td><td>-2.29417</td><td>1.764551</td><td>null</td><td>-0.120789</td><td>-0.063458</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.882604</td><td>-0.072482</td><td>-0.617934</td><td>-0.86323</td><td>-0.241892</td><td>-0.709919</td><td>null</td><td>null</td><td>0.377131</td><td>0.300724</td><td>-0.106842</td><td>-0.096792</td><td>2.109352</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>10</td><td>0.690606</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.139366</td><td>0.273328</td><td>0.306549</td><td>-1.262223</td><td>42</td><td>5</td><td>150</td><td>-0.694008</td><td>3.004091</td><td>0.114809</td><td>null</td><td>-0.251882</td><td>null</td><td>-1.902009</td><td>-0.979447</td><td>0.241165</td><td>null</td><td>-0.392359</td><td>-0.224699</td><td>-2.129397</td><td>-0.855287</td><td>null</td><td>null</td><td>0.404142</td><td>-0.578156</td><td>0.105702</td><td>null</td><td>null</td><td>null</td><td>0.544138</td><td>-0.087091</td><td>-1.500147</td><td>-0.201288</td><td>-0.038042</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.382074</td><td>2.669135</td><td>0.611711</td><td>null</td><td>2.413415</td><td>null</td><td>null</td><td>1.313203</td><td>null</td><td>-0.810125</td><td>2.939022</td><td>null</td><td>3.988801</td><td>1.834661</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.697595</td><td>1.074309</td><td>-0.206929</td><td>-0.530602</td><td>4.765215</td><td>0.571554</td><td>null</td><td>null</td><td>-0.226891</td><td>-0.251412</td><td>-0.215522</td><td>-0.296244</td><td>1.114137</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>0</td><td>0</td><td>14</td><td>0.44057</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.9552</td><td>0.262404</td><td>0.344457</td><td>-0.613813</td><td>44</td><td>3</td><td>16</td><td>-0.947351</td><td>-0.030018</td><td>-0.502379</td><td>null</td><td>0.646086</td><td>null</td><td>-1.844685</td><td>-1.58656</td><td>-0.182024</td><td>null</td><td>-0.969949</td><td>-0.673813</td><td>-1.282132</td><td>-1.399894</td><td>null</td><td>null</td><td>0.043815</td><td>-0.320225</td><td>-0.031713</td><td>null</td><td>null</td><td>null</td><td>-0.08842</td><td>-0.995003</td><td>-2.635336</td><td>-0.196461</td><td>-0.618719</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-2.0146</td><td>-2.321076</td><td>-3.711265</td><td>null</td><td>1.253902</td><td>null</td><td>null</td><td>0.476195</td><td>null</td><td>-0.771732</td><td>2.843421</td><td>null</td><td>1.379815</td><td>0.411827</td><td>-1.36224</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.948601</td><td>-0.136814</td><td>-0.447704</td><td>-1.141761</td><td>0.099631</td><td>-0.661928</td><td>null</td><td>null</td><td>3.678076</td><td>2.793581</td><td>2.61825</td><td>3.418133</td><td>-3.57282</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 93)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ dat ┆ tim ┆ sym ┆ wei ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res │\n",
       "│ e_i ┆ e_i ┆ bol ┆ ght ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon │\n",
       "│ d   ┆ d   ┆ _id ┆ --- ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der │\n",
       "│ --- ┆ --- ┆ --- ┆ f32 ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ _6  ┆ _0_ ┆ _1_ ┆ _2_ ┆ _3_ ┆ _4_ ┆ _5_ ┆ _6_ ┆ _7_ ┆ _8_ │\n",
       "│ i16 ┆ i16 ┆ i8  ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag │\n",
       "│     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ i8  ┆ i8  ┆ i16 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 0   ┆ 0   ┆ 1   ┆ 3.8 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.8 ┆ 0.2 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ 0.0 ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -1. ┆ 0.9 ┆ nul ┆ 1.6 ┆ 1.5 ┆ -1. ┆ -0. ┆ nul ┆ nul ┆ 1.3 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.2 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ -0. ┆ nul ┆ -1. ┆ nul ┆ nul ┆ -0. ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ 2.0 ┆ 0.8 ┆ nul ┆ 0.2 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 0.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -0. ┆ -0. ┆ -1. ┆ 0.1 ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 890 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 510 ┆ 429 ┆ 634 ┆ 891 ┆     ┆     ┆     ┆ 883 ┆ 030 ┆ 744 ┆ l   ┆ 169 ┆ l   ┆ 335 ┆ 707 ┆ 101 ┆ l   ┆ 364 ┆ 221 ┆ 551 ┆ 229 ┆ l   ┆ l   ┆ 783 ┆ 283 ┆ 231 ┆ l   ┆ l   ┆ l   ┆ 811 ┆ 691 ┆ 490 ┆ 012 ┆ 225 ┆ l   ┆ 073 ┆ l   ┆ l   ┆ 181 ┆ l   ┆ l   ┆ l   ┆ 640 ┆ 885 ┆ 320 ┆ l   ┆ 047 ┆ l   ┆ l   ┆ 808 ┆ l   ┆ 037 ┆ 276 ┆ l   ┆ 989 ┆ 345 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 251 ┆ 110 ┆ 491 ┆ 022 ┆ 522 ┆ 659 ┆ l   ┆ l   ┆ 261 ┆ 211 ┆ 335 ┆ 281 ┆ 759 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 38  ┆     ┆     ┆     ┆     ┆     ┆ 33  ┆ 71  ┆     ┆ 687 ┆     ┆     ┆     ┆ 028 ┆ 67  ┆ 703 ┆     ┆ 586 ┆     ┆ 938 ┆ 803 ┆ 3   ┆     ┆ 31  ┆ 33  ┆ 398 ┆ 627 ┆     ┆     ┆ 01  ┆ 712 ┆ 96  ┆     ┆     ┆     ┆ 8   ┆ 63  ┆ 28  ┆ 596 ┆ 932 ┆     ┆ 602 ┆     ┆     ┆ 716 ┆     ┆     ┆     ┆ 21  ┆ 06  ┆ 22  ┆     ┆ 97  ┆     ┆     ┆ 103 ┆     ┆ 683 ┆ 61  ┆     ┆ 118 ┆ 213 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 104 ┆ 252 ┆ 157 ┆ 69  ┆ 41  ┆ 864 ┆     ┆     ┆ 412 ┆ 486 ┆ 556 ┆ 498 ┆ 81  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 7   ┆ 1.3 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.6 ┆ 0.1 ┆ 0.1 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.3 ┆ nul ┆ -1. ┆ -1. ┆ 1.4 ┆ nul ┆ 0.5 ┆ 0.7 ┆ -0. ┆ 0.6 ┆ nul ┆ nul ┆ 0.2 ┆ 0.5 ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -1. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -10 ┆ -0. ┆ -0. ┆ nul ┆ 1.1 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 1.0 ┆ nul ┆ 0.8 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ 0.0 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 706 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 769 ┆ 519 ┆ 924 ┆ 521 ┆     ┆     ┆     ┆ 865 ┆ 225 ┆ 582 ┆ l   ┆ 174 ┆ l   ┆ 250 ┆ 682 ┆ 127 ┆ l   ┆ 203 ┆ 441 ┆ 788 ┆ 417 ┆ l   ┆ l   ┆ 272 ┆ 809 ┆ 288 ┆ l   ┆ l   ┆ l   ┆ 512 ┆ 414 ┆ 823 ┆ 082 ┆ 184 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ .83 ┆ 002 ┆ 621 ┆ l   ┆ 728 ┆ l   ┆ l   ┆ 625 ┆ l   ┆ 410 ┆ 630 ┆ l   ┆ 883 ┆ 679 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 065 ┆ 133 ┆ 592 ┆ 052 ┆ 393 ┆ 741 ┆ l   ┆ l   ┆ 281 ┆ 182 ┆ 245 ┆ 302 ┆ 036 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 13  ┆     ┆     ┆     ┆     ┆     ┆ 61  ┆ 84  ┆ 65  ┆ 729 ┆     ┆     ┆     ┆ 307 ┆ 629 ┆ 163 ┆     ┆ 67  ┆     ┆ 016 ┆ 929 ┆ 57  ┆     ┆ 78  ┆ 32  ┆ 658 ┆ 76  ┆     ┆     ┆     ┆ 07  ┆ 79  ┆     ┆     ┆     ┆ 286 ┆ 357 ┆ 322 ┆ 763 ┆ 119 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 520 ┆ 704 ┆ 836 ┆     ┆ 36  ┆     ┆     ┆ 862 ┆     ┆ 017 ┆ 13  ┆     ┆ 55  ┆ 94  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 759 ┆ 22  ┆ 855 ┆ 685 ┆ 726 ┆ 603 ┆     ┆     ┆ 207 ┆ 894 ┆ 565 ┆ 441 ┆ 65  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 9   ┆ 2.2 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.0 ┆ 0.1 ┆ 0.2 ┆ -0. ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -2. ┆ 0.6 ┆ nul ┆ 1.5 ┆ 0.6 ┆ -1. ┆ 0.3 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -1. ┆ -3. ┆ -4. ┆ nul ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 1.7 ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ 0.3 ┆ 0.3 ┆ -0. ┆ -0. ┆ 2.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 856 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 562 ┆ 872 ┆ 499 ┆ 773 ┆     ┆     ┆     ┆ 675 ┆ 199 ┆ 586 ┆ l   ┆ 814 ┆ l   ┆ 296 ┆ 040 ┆ 395 ┆ l   ┆ 973 ┆ 575 ┆ 350 ┆ 642 ┆ l   ┆ l   ┆ 017 ┆ 317 ┆ 122 ┆ l   ┆ l   ┆ l   ┆ 320 ┆ 958 ┆ 436 ┆ 709 ┆ 245 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 420 ┆ 515 ┆ 677 ┆ l   ┆ 358 ┆ l   ┆ l   ┆ 725 ┆ l   ┆ 294 ┆ 645 ┆ l   ┆ 120 ┆ 063 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 882 ┆ 072 ┆ 617 ┆ 863 ┆ 241 ┆ 709 ┆ l   ┆ l   ┆ 771 ┆ 007 ┆ 106 ┆ 096 ┆ 093 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 98  ┆     ┆     ┆     ┆     ┆     ┆ 85  ┆ 27  ┆ 01  ┆ 05  ┆     ┆     ┆     ┆ 719 ┆ 404 ┆ 798 ┆     ┆ 909 ┆     ┆ 782 ┆ 234 ┆ 89  ┆     ┆ 59  ┆ 14  ┆ 148 ┆ 15  ┆     ┆     ┆ 751 ┆ 361 ┆ 379 ┆     ┆     ┆     ┆ 921 ┆ 09  ┆ 589 ┆ 99  ┆ 239 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 632 ┆ 137 ┆ 76  ┆     ┆ 97  ┆     ┆     ┆ 42  ┆     ┆ 17  ┆ 51  ┆     ┆ 789 ┆ 458 ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 604 ┆ 482 ┆ 934 ┆ 23  ┆ 892 ┆ 919 ┆     ┆     ┆ 31  ┆ 24  ┆ 842 ┆ 792 ┆ 52  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 10  ┆ 0.6 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 1.1 ┆ 0.2 ┆ 0.3 ┆ -1. ┆ 42  ┆ 5   ┆ 150 ┆ -0. ┆ 3.0 ┆ 0.1 ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -0. ┆ 0.2 ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ nul ┆ nul ┆ 0.4 ┆ -0. ┆ 0.1 ┆ nul ┆ nul ┆ nul ┆ 0.5 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.3 ┆ 2.6 ┆ 0.6 ┆ nul ┆ 2.4 ┆ nul ┆ nul ┆ 1.3 ┆ nul ┆ -0. ┆ 2.9 ┆ nul ┆ 3.9 ┆ 1.8 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ 1.0 ┆ -0. ┆ -0. ┆ 4.7 ┆ 0.5 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 1.1 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 906 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 393 ┆ 733 ┆ 065 ┆ 262 ┆     ┆     ┆     ┆ 694 ┆ 040 ┆ 148 ┆ l   ┆ 251 ┆ l   ┆ 902 ┆ 979 ┆ 411 ┆ l   ┆ 392 ┆ 224 ┆ 129 ┆ 855 ┆ l   ┆ l   ┆ 041 ┆ 578 ┆ 057 ┆ l   ┆ l   ┆ l   ┆ 441 ┆ 087 ┆ 500 ┆ 201 ┆ 038 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 820 ┆ 691 ┆ 117 ┆ l   ┆ 134 ┆ l   ┆ l   ┆ 132 ┆ l   ┆ 810 ┆ 390 ┆ l   ┆ 888 ┆ 346 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 697 ┆ 743 ┆ 206 ┆ 530 ┆ 652 ┆ 715 ┆ l   ┆ l   ┆ 226 ┆ 251 ┆ 215 ┆ 296 ┆ 141 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 06  ┆     ┆     ┆     ┆     ┆     ┆ 66  ┆ 28  ┆ 49  ┆ 223 ┆     ┆     ┆     ┆ 008 ┆ 91  ┆ 09  ┆     ┆ 882 ┆     ┆ 009 ┆ 447 ┆ 65  ┆     ┆ 359 ┆ 699 ┆ 397 ┆ 287 ┆     ┆     ┆ 42  ┆ 156 ┆ 02  ┆     ┆     ┆     ┆ 38  ┆ 091 ┆ 147 ┆ 288 ┆ 042 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 74  ┆ 35  ┆ 11  ┆     ┆ 15  ┆     ┆     ┆ 03  ┆     ┆ 125 ┆ 22  ┆     ┆ 01  ┆ 61  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 595 ┆ 09  ┆ 929 ┆ 602 ┆ 15  ┆ 54  ┆     ┆     ┆ 891 ┆ 412 ┆ 522 ┆ 244 ┆ 37  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 0   ┆ 0   ┆ 14  ┆ 0.4 ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ 0.9 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ 44  ┆ 3   ┆ 16  ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.6 ┆ nul ┆ -1. ┆ -1. ┆ -0. ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ -1. ┆ nul ┆ nul ┆ 0.0 ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -2. ┆ -2. ┆ -3. ┆ nul ┆ 1.2 ┆ nul ┆ nul ┆ 0.4 ┆ nul ┆ -0. ┆ 2.8 ┆ nul ┆ 1.3 ┆ 0.4 ┆ -1. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ 0.0 ┆ -0. ┆ nul ┆ nul ┆ 3.6 ┆ 2.7 ┆ 2.6 ┆ 3.4 ┆ -3. ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul ┆ nul │\n",
       "│     ┆     ┆     ┆ 405 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 552 ┆ 624 ┆ 444 ┆ 613 ┆     ┆     ┆     ┆ 947 ┆ 030 ┆ 502 ┆ l   ┆ 460 ┆ l   ┆ 844 ┆ 586 ┆ 182 ┆ l   ┆ 969 ┆ 673 ┆ 282 ┆ 399 ┆ l   ┆ l   ┆ 438 ┆ 320 ┆ 031 ┆ l   ┆ l   ┆ l   ┆ 088 ┆ 995 ┆ 635 ┆ 196 ┆ 618 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 014 ┆ 321 ┆ 711 ┆ l   ┆ 539 ┆ l   ┆ l   ┆ 761 ┆ l   ┆ 771 ┆ 434 ┆ l   ┆ 798 ┆ 118 ┆ 362 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ 948 ┆ 136 ┆ 447 ┆ 141 ┆ 996 ┆ 661 ┆ l   ┆ l   ┆ 780 ┆ 935 ┆ 182 ┆ 181 ┆ 572 ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   ┆ l   │\n",
       "│     ┆     ┆     ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆     ┆ 04  ┆ 57  ┆ 813 ┆     ┆     ┆     ┆ 351 ┆ 018 ┆ 379 ┆     ┆ 86  ┆     ┆ 685 ┆ 56  ┆ 024 ┆     ┆ 949 ┆ 813 ┆ 132 ┆ 894 ┆     ┆     ┆ 15  ┆ 225 ┆ 713 ┆     ┆     ┆     ┆ 42  ┆ 003 ┆ 336 ┆ 461 ┆ 719 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 6   ┆ 076 ┆ 265 ┆     ┆ 02  ┆     ┆     ┆ 95  ┆     ┆ 732 ┆ 21  ┆     ┆ 15  ┆ 27  ┆ 24  ┆     ┆     ┆     ┆     ┆     ┆ 601 ┆ 814 ┆ 704 ┆ 761 ┆ 31  ┆ 928 ┆     ┆     ┆ 76  ┆ 81  ┆ 5   ┆ 33  ┆ 82  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pl.read_parquet(path + 'train.parquet/').select(pl.all().shrink_dtype())\n",
    "lags_df = train_df.with_columns(pl.col('date_id') + 1).drop(['weight', 'partition_id'] + [col for col in train_df.columns if 'feature' in col]).rename({f'responder_{x}': f'responder_{x}_lag_1' for x in range(9)})\n",
    "train_df = train_df.drop(['responder_0', 'responder_1', 'responder_2', 'responder_3', 'responder_4', 'responder_5', 'responder_7', 'responder_8', 'partition_id']).select(pl.all().shrink_dtype())\n",
    "train_df = train_df.join(lags_df, on=['date_id', 'time_id', 'symbol_id'], how='left').select(pl.all().shrink_dtype())\n",
    "del lags_df\n",
    "gc.collect()\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7434dcc6-f9b9-4e8a-aa41-50c724fd1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scan = pl.scan_parquet(path + 'train.parquet/')\n",
    "test_scan = pl.scan_parquet(path + 'test.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93569971-385d-4e5a-b362-ff4fbf80cf6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_symbol_ids_list = sorted(train_scan.select('symbol_id').unique().collect()['symbol_id'].to_list())\n",
    "test_symbol_ids_list = sorted(test_scan.select('symbol_id').unique().collect()['symbol_id'].to_list())\n",
    "unique_symbol_ids_list = sorted(list(set(train_symbol_ids_list + test_symbol_ids_list)))\n",
    "unique_symbol_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d27779c-c935-48d8-a8ce-42a39e8e1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_cat_cols(df):\n",
    "    for v in tqdm(unique_symbol_ids_list):\n",
    "        new_col_name = 'symbol_id_' + str(v)\n",
    "        #df[new_col_name] = (df['symbol_id'] == v).astype(int)\n",
    "        df = df.with_columns((pl.col('symbol_id') == v).cast(pl.Int8).alias(new_col_name))\n",
    "\n",
    "    \n",
    "    #df = df.drop('symbol_id', axis=1)\n",
    "\n",
    "    return df.select(pl.all().shrink_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3834f8e8-0f10-4891-a325-5d288f99b503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.032444032"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.estimated_size() / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be3ffe03-76cd-4ee5-bf7c-940de4646a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = path + 'my_folder/models/20250104_01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e04716-a5a1-471c-b452-0a8b5f7a7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_online_learning(train_data):\n",
    "    weights = train_data['weight']\n",
    "    y = train_data['responder_6']\n",
    "\n",
    "    unique_date_ids = train_data['date_id'].unique()    \n",
    "    train_date_id_cut = int(unique_date_ids.max() / 2)\n",
    "\n",
    "    print('max date:', unique_date_ids.max())\n",
    "    print('date id cut:', train_date_id_cut)\n",
    "\n",
    "    X_train = train_data.filter(pl.col('date_id') <= train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "    X_val = train_data.filter(pl.col('date_id') > train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "\n",
    "    print(X_train.shape[0] / train_data.shape[0])\n",
    "\n",
    "    y_train = y[:X_train.shape[0]].to_pandas()\n",
    "    y_val = y[X_train.shape[0]:].to_pandas()\n",
    "\n",
    "    weights_train = weights[:X_train.shape[0]].to_pandas()\n",
    "    weights_val = weights[X_train.shape[0]:].to_pandas()\n",
    "\n",
    "    print(X_train.shape)\n",
    "    display(X_train.head())\n",
    "    display(X_train.tail())\n",
    "    \n",
    "\n",
    "    #train_dataset = lgb.Dataset(data=X_train, label=y_train, weight=weights_train)\n",
    "    #val_dataset = lgb.Dataset(data=X_val, label=y_val, weight=weights_val)\n",
    "\n",
    "    base_params = {\n",
    "        'verbosity': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'device': 'gpu',\n",
    "        'early_stopping_round': 30,\n",
    "        'lambda_l2': 100,\n",
    "        #'metric': 'r2',\n",
    "        #'seed': 42\n",
    "    }\n",
    "\n",
    "    '''model = lgb.train(\n",
    "        params=base_params,\n",
    "        train_set=train_dataset,\n",
    "        num_boost_round=90\n",
    "    )'''\n",
    "\n",
    "    model = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=90000\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)])#, init_model=current_model)\n",
    "    #model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "    best_iteration = model.best_iteration_\n",
    "    print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "    plt.figure()\n",
    "    lgb.plot_metric(model)\n",
    "    plt.ylim(0, 2)\n",
    "    plt.show()\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "\n",
    "    print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "    return model\n",
    "\n",
    "    val_date_ids = sorted(train_data.filter(pl.col('date_id') > train_date_id_cut)['date_id'].unique())\n",
    "    \n",
    "    for date_id_v in val_date_ids:\n",
    "        for time_id_v in sorted(train_data.filter(pl.col('date_id') == date_id_v)['time_id'].unique()):\n",
    "            time_id_df = train_data.filter((pl.col('date_id') == date_id_v) & (pl.col('time_id') == time_id_v))\n",
    "\n",
    "            print(time_id_df.shape)\n",
    "            display(time_id_df)\n",
    "\n",
    "            time_id_X_train = time_id_df.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "            time_id_y_train = time_id_df['responder_6'].to_pandas()\n",
    "            time_id_weights_train = time_id_df['weight'].to_pandas()\n",
    "\n",
    "            val_data_df = train_data.filter(pl.col('date_id') >= date_id_v)[time_id_df.shape[0]:]\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return\n",
    "    \n",
    "    '''weights = train_data['weight']\n",
    "    y = train_data['responder_6']\n",
    "    \n",
    "    unique_date_ids = train_data['date_id'].unique()\n",
    "    train_date_id_cut = int(unique_date_ids.max() - 10)\n",
    "\n",
    "    print('max date:', unique_date_ids.max())\n",
    "    print('date id cut:', train_date_id_cut)\n",
    "    \n",
    "    X_train = train_data.filter(pl.col('date_id') <= train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "    X_val = train_data.filter(pl.col('date_id') > train_date_id_cut).drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "\n",
    "    print(X_train.shape[0] / train_data.shape[0])\n",
    "    \n",
    "    y_train = y[:X_train.shape[0]].to_pandas()\n",
    "    y_val = y[X_train.shape[0]:].to_pandas()\n",
    "    \n",
    "    weights_train = weights[:X_train.shape[0]].to_pandas()\n",
    "    weights_val = weights[X_train.shape[0]:].to_pandas()\n",
    "\n",
    "    print(X_train.shape)\n",
    "    display(X_train.head())\n",
    "\n",
    "    base_params = {\n",
    "        'verbosity': -1,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'device': 'gpu',\n",
    "        'early_stopping_round': 30,\n",
    "        'lambda_l2': 100\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=100000\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=50)])#, categorical_feature=['symbol_id'])\n",
    "\n",
    "    best_iteration = model.best_iteration_\n",
    "    print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "    val_preds = model.predict(X_val)\n",
    "\n",
    "    plt.figure()\n",
    "    lgb.plot_metric(model)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()    \n",
    "\n",
    "    if not os.path.exists(models_path):\n",
    "        os.makedirs(models_path)\n",
    "\n",
    "    with open(models_path + \"lgb_model.pkl\", 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "    sample_val = X_val.sample(frac=0.001)\n",
    "    sample_y = y_val.loc[sample_val.index]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X=sample_val, y=sample_y)\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "    del X_train, y_train, X_val, y_val, weights_train, weights_val\n",
    "    gc.collect()\n",
    "\n",
    "    # Retraining on the full dataset using best_iteration\n",
    "    X_full = train_data.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "    y_full = y.to_pandas()\n",
    "    weights_full = weights.to_pandas()\n",
    "\n",
    "    base_params.pop('early_stopping_round')\n",
    "\n",
    "    model_full = LGBMRegressor(\n",
    "        **base_params,\n",
    "        n_estimators=best_iteration\n",
    "    )\n",
    "    \n",
    "    model_full.fit(X_full, y_full, sample_weight=weights_full)\n",
    "\n",
    "    with open(models_path + \"lgb_model_full.pkl\", 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    print(\"Retraining complete. Model saved as 'lgb_model_full.pkl'.\")\n",
    "\n",
    "    return shap_importance'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11640b-066f-4b04-9b5d-344b1c861b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb_online_learning(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5b42e-8908-4589-9756-d4fb977ef6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8d3dc-c225-4c0d-a41f-3da3b887045f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20efbf23-81e0-4e6f-a346-3e01ee558f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746715e-6673-4ba1-953c-41d00f590a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb20dd-2150-426f-8739-2f63402dc7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4651e-f019-4e55-8ce4-b03aae6c1c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c8234-33e1-4891-9527-58d15c529e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47aa04-b2ad-48db-a1b4-1939520ab885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc310b8-2089-42ee-8c3b-80545060deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(models_path):\n",
    "    os.makedirs(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b34869-0c65-42dd-95c1-e9f867276f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3859c-b79e-426f-9799-fffdb93d3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(models_path + \"lgb_model.pkl\", 'wb') as file:\n",
    "    pickle.dump(lgb_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d6684c-98f8-447c-8b58-28f1d21aef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open(f\"{models_path}/lgb_model.pkl\", \"rb\") as f:\n",
    "    lgb_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86df7914-ec21-4603-9388-57043c98ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30302272, 93)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 93)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>feature_35</th><th>feature_36</th><th>feature_37</th><th>feature_38</th><th>feature_39</th><th>feature_40</th><th>feature_41</th><th>feature_42</th><th>feature_43</th><th>feature_44</th><th>feature_45</th><th>feature_46</th><th>feature_47</th><th>feature_48</th><th>feature_49</th><th>feature_50</th><th>feature_51</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_6</th><th>responder_0_lag_1</th><th>responder_1_lag_1</th><th>responder_2_lag_1</th><th>responder_3_lag_1</th><th>responder_4_lag_1</th><th>responder_5_lag_1</th><th>responder_6_lag_1</th><th>responder_7_lag_1</th><th>responder_8_lag_1</th></tr><tr><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>850</td><td>0</td><td>0</td><td>2.087724</td><td>-0.276877</td><td>-2.385324</td><td>-1.086325</td><td>0.049463</td><td>3.427029</td><td>-4.671824</td><td>0.054977</td><td>-0.259751</td><td>1.343003</td><td>11</td><td>7</td><td>76</td><td>-0.793587</td><td>2.523406</td><td>0.303231</td><td>null</td><td>0.523913</td><td>null</td><td>-1.567069</td><td>-0.965586</td><td>0.014156</td><td>-0.171976</td><td>1.015679</td><td>0.746074</td><td>-1.633316</td><td>-1.309486</td><td>0.965614</td><td>1.612443</td><td>0.82306</td><td>-0.027811</td><td>0.72484</td><td>-0.184198</td><td>null</td><td>null</td><td>-0.187675</td><td>-0.346574</td><td>-1.421471</td><td>0.093479</td><td>1.387856</td><td>null</td><td>1.254196</td><td>null</td><td>null</td><td>0.050192</td><td>null</td><td>-0.954613</td><td>2.004981</td><td>-1.557791</td><td>0.678891</td><td>-0.066386</td><td>null</td><td>2.456588</td><td>null</td><td>null</td><td>-1.159385</td><td>null</td><td>-0.889724</td><td>1.428067</td><td>null</td><td>0.817551</td><td>0.299599</td><td>0.352903</td><td>-0.328996</td><td>-0.151735</td><td>-0.224472</td><td>-1.477134</td><td>-1.643559</td><td>-0.556531</td><td>2.815019</td><td>0.356358</td><td>-0.527251</td><td>1.609195</td><td>0.076337</td><td>null</td><td>null</td><td>-0.228297</td><td>-0.273781</td><td>-0.277999</td><td>-0.295312</td><td>1.461546</td><td>0.402863</td><td>0.074029</td><td>0.36344</td><td>-0.558883</td><td>-0.419728</td><td>-0.238446</td><td>-1.213885</td><td>-0.616817</td><td>-1.411242</td></tr><tr><td>850</td><td>0</td><td>1</td><td>3.752097</td><td>-0.168178</td><td>-2.161023</td><td>-0.511679</td><td>0.192425</td><td>3.162096</td><td>-4.386098</td><td>0.130385</td><td>-0.368283</td><td>1.913416</td><td>11</td><td>7</td><td>76</td><td>-0.660111</td><td>3.052153</td><td>0.071869</td><td>null</td><td>0.001913</td><td>null</td><td>-0.625688</td><td>-1.11523</td><td>0.185483</td><td>0.019226</td><td>1.916643</td><td>0.710887</td><td>-1.102333</td><td>-0.981141</td><td>0.521467</td><td>1.665925</td><td>1.461316</td><td>-0.358575</td><td>0.058004</td><td>0.021168</td><td>null</td><td>null</td><td>-0.641563</td><td>-0.482115</td><td>-2.396556</td><td>-0.121039</td><td>1.409137</td><td>null</td><td>0.932519</td><td>null</td><td>null</td><td>1.311157</td><td>null</td><td>-0.749923</td><td>1.793136</td><td>-2.108881</td><td>1.227915</td><td>-0.146708</td><td>null</td><td>0.888707</td><td>null</td><td>null</td><td>-1.427895</td><td>null</td><td>-1.575317</td><td>0.556004</td><td>null</td><td>0.321817</td><td>0.406464</td><td>0.352903</td><td>-0.388503</td><td>-0.100457</td><td>-0.201082</td><td>-1.926849</td><td>-1.763679</td><td>-0.612577</td><td>1.61283</td><td>-0.051637</td><td>-0.97052</td><td>2.79455</td><td>0.353143</td><td>null</td><td>null</td><td>-0.157027</td><td>-0.163802</td><td>-0.277016</td><td>-0.444008</td><td>0.789595</td><td>-0.240175</td><td>-0.445871</td><td>0.125748</td><td>0.264227</td><td>0.088307</td><td>-0.649466</td><td>0.597718</td><td>0.500387</td><td>-1.605249</td></tr><tr><td>850</td><td>0</td><td>2</td><td>1.225099</td><td>-0.520426</td><td>-1.718115</td><td>-0.817358</td><td>-0.270528</td><td>3.314825</td><td>-2.578923</td><td>0.1102</td><td>-0.20174</td><td>2.072351</td><td>81</td><td>2</td><td>59</td><td>-0.528026</td><td>3.354508</td><td>0.327966</td><td>null</td><td>-0.215615</td><td>null</td><td>-1.260532</td><td>-2.04301</td><td>-1.31462</td><td>-0.239955</td><td>0.017958</td><td>-0.27587</td><td>-0.705935</td><td>-0.782762</td><td>0.268385</td><td>1.391267</td><td>1.265022</td><td>-0.539895</td><td>-0.351402</td><td>-0.209022</td><td>null</td><td>null</td><td>-0.164031</td><td>-0.517534</td><td>0.71262</td><td>0.418721</td><td>1.150448</td><td>null</td><td>-0.361983</td><td>null</td><td>null</td><td>-1.394171</td><td>null</td><td>-1.067848</td><td>0.734942</td><td>-2.05364</td><td>-1.888152</td><td>-0.688585</td><td>null</td><td>-0.588629</td><td>null</td><td>null</td><td>-2.212862</td><td>null</td><td>-2.015984</td><td>0.025982</td><td>null</td><td>-4.632971</td><td>-2.559358</td><td>0.352903</td><td>-0.316812</td><td>-0.264718</td><td>-0.248274</td><td>-1.383873</td><td>-2.433391</td><td>-0.728091</td><td>4.478824</td><td>0.497227</td><td>-0.449675</td><td>1.648489</td><td>-0.001233</td><td>null</td><td>null</td><td>-0.012737</td><td>-0.081892</td><td>-0.209053</td><td>-0.267447</td><td>-2.848316</td><td>-0.198698</td><td>-0.217445</td><td>0.086082</td><td>-0.509062</td><td>-0.734032</td><td>0.970075</td><td>-0.747389</td><td>-0.662997</td><td>1.603958</td></tr><tr><td>850</td><td>0</td><td>3</td><td>1.467042</td><td>-0.061985</td><td>-1.818735</td><td>-0.990254</td><td>0.274284</td><td>3.810929</td><td>-1.11177</td><td>0.043842</td><td>-0.090386</td><td>0.777759</td><td>4</td><td>3</td><td>11</td><td>-1.218813</td><td>1.769522</td><td>-0.076559</td><td>null</td><td>-0.461771</td><td>null</td><td>-1.905882</td><td>-2.141612</td><td>-0.347407</td><td>0.201398</td><td>0.629975</td><td>-0.282367</td><td>3.053007</td><td>2.292672</td><td>-0.312745</td><td>-0.370565</td><td>-0.473996</td><td>-0.535461</td><td>-0.979823</td><td>0.209806</td><td>null</td><td>null</td><td>-1.742934</td><td>-1.835673</td><td>1.511821</td><td>0.155715</td><td>0.446925</td><td>null</td><td>0.255243</td><td>null</td><td>null</td><td>-0.066129</td><td>null</td><td>-2.102276</td><td>1.224973</td><td>-0.932835</td><td>-0.402716</td><td>-0.369551</td><td>null</td><td>0.237087</td><td>null</td><td>null</td><td>-1.359047</td><td>null</td><td>-1.917404</td><td>1.456003</td><td>null</td><td>-1.652316</td><td>-0.545286</td><td>0.352903</td><td>-0.646065</td><td>-0.38281</td><td>-0.345414</td><td>-1.605209</td><td>-1.561482</td><td>-0.529622</td><td>1.397832</td><td>-0.131058</td><td>-0.717516</td><td>2.507538</td><td>0.020102</td><td>null</td><td>null</td><td>0.377517</td><td>0.284319</td><td>-0.06742</td><td>-0.157564</td><td>-0.749164</td><td>0.170911</td><td>-0.580147</td><td>0.440651</td><td>-0.154337</td><td>-0.523854</td><td>-0.754856</td><td>-0.248197</td><td>-0.220052</td><td>-1.16779</td></tr><tr><td>850</td><td>0</td><td>5</td><td>3.144071</td><td>-0.321442</td><td>-1.964041</td><td>-0.409452</td><td>-0.343893</td><td>3.069664</td><td>-2.929145</td><td>0.084903</td><td>-0.214164</td><td>1.247011</td><td>2</td><td>10</td><td>171</td><td>-0.674077</td><td>2.17874</td><td>-0.058749</td><td>null</td><td>-0.656464</td><td>null</td><td>-1.158764</td><td>-1.013156</td><td>0.694589</td><td>0.229134</td><td>1.647839</td><td>0.301107</td><td>0.018292</td><td>0.099487</td><td>-0.772632</td><td>0.932901</td><td>1.751187</td><td>-0.621377</td><td>-0.6756</td><td>0.216979</td><td>null</td><td>null</td><td>-0.43032</td><td>0.001558</td><td>1.253969</td><td>0.103685</td><td>0.657733</td><td>null</td><td>0.493284</td><td>null</td><td>null</td><td>-1.426275</td><td>null</td><td>-1.534382</td><td>1.102636</td><td>-0.859073</td><td>0.555257</td><td>0.348532</td><td>null</td><td>0.229975</td><td>null</td><td>null</td><td>-0.513925</td><td>null</td><td>-2.259789</td><td>1.537998</td><td>null</td><td>-1.00717</td><td>-0.823392</td><td>0.352903</td><td>-0.480987</td><td>-0.299463</td><td>-0.499426</td><td>-2.79966</td><td>-2.620816</td><td>-0.586428</td><td>2.413169</td><td>0.166888</td><td>-0.904685</td><td>1.361527</td><td>-0.238988</td><td>null</td><td>null</td><td>0.324627</td><td>0.262034</td><td>-0.147552</td><td>-0.138634</td><td>-0.8826</td><td>0.172549</td><td>0.048066</td><td>-0.045807</td><td>1.434816</td><td>0.04118</td><td>0.936963</td><td>1.769305</td><td>0.025372</td><td>1.907083</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 93)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ dat ┆ tim ┆ sym ┆ wei ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ fea ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res ┆ res │\n",
       "│ e_i ┆ e_i ┆ bol ┆ ght ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ tur ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon ┆ pon │\n",
       "│ d   ┆ d   ┆ _id ┆ --- ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_0 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_1 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_2 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_3 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_4 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_5 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_6 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ e_7 ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der ┆ der │\n",
       "│ --- ┆ --- ┆ --- ┆ f32 ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ 9   ┆ 0   ┆ 1   ┆ 2   ┆ 3   ┆ 4   ┆ 5   ┆ 6   ┆ 7   ┆ 8   ┆ _6  ┆ _0_ ┆ _1_ ┆ _2_ ┆ _3_ ┆ _4_ ┆ _5_ ┆ _6_ ┆ _7_ ┆ _8_ │\n",
       "│ i16 ┆ i16 ┆ i8  ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag ┆ lag │\n",
       "│     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ i8  ┆ i8  ┆ i16 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  ┆ _1  │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 ┆ f32 │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 850 ┆ 0   ┆ 0   ┆ 2.0 ┆ -0. ┆ -2. ┆ -1. ┆ 0.0 ┆ 3.4 ┆ -4. ┆ 0.0 ┆ -0. ┆ 1.3 ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ 2.5 ┆ 0.3 ┆ nul ┆ 0.5 ┆ nul ┆ -1. ┆ -0. ┆ 0.0 ┆ -0. ┆ 1.0 ┆ 0.7 ┆ -1. ┆ -1. ┆ 0.9 ┆ 1.6 ┆ 0.8 ┆ -0. ┆ 0.7 ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -1. ┆ 0.0 ┆ 1.3 ┆ nul ┆ 1.2 ┆ nul ┆ nul ┆ 0.0 ┆ nul ┆ -0. ┆ 2.0 ┆ -1. ┆ 0.6 ┆ -0. ┆ nul ┆ 2.4 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -0. ┆ 1.4 ┆ nul ┆ 0.8 ┆ 0.2 ┆ 0.3 ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ -1. ┆ -0. ┆ 2.8 ┆ 0.3 ┆ -0. ┆ 1.6 ┆ 0.0 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 1.4 ┆ 0.4 ┆ 0.0 ┆ 0.3 ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ -0. ┆ -1. │\n",
       "│     ┆     ┆     ┆ 877 ┆ 276 ┆ 385 ┆ 086 ┆ 494 ┆ 270 ┆ 671 ┆ 549 ┆ 259 ┆ 430 ┆     ┆     ┆     ┆ 793 ┆ 234 ┆ 032 ┆ l   ┆ 239 ┆ l   ┆ 567 ┆ 965 ┆ 141 ┆ 171 ┆ 156 ┆ 460 ┆ 633 ┆ 309 ┆ 656 ┆ 124 ┆ 230 ┆ 027 ┆ 248 ┆ 184 ┆ l   ┆ l   ┆ 187 ┆ 346 ┆ 421 ┆ 934 ┆ 878 ┆ l   ┆ 541 ┆ l   ┆ l   ┆ 501 ┆ l   ┆ 954 ┆ 049 ┆ 557 ┆ 788 ┆ 066 ┆ l   ┆ 565 ┆ l   ┆ l   ┆ 159 ┆ l   ┆ 889 ┆ 280 ┆ l   ┆ 175 ┆ 995 ┆ 529 ┆ 328 ┆ 151 ┆ 224 ┆ 477 ┆ 643 ┆ 556 ┆ 150 ┆ 563 ┆ 527 ┆ 091 ┆ 763 ┆ l   ┆ l   ┆ 228 ┆ 273 ┆ 277 ┆ 295 ┆ 615 ┆ 028 ┆ 740 ┆ 634 ┆ 558 ┆ 419 ┆ 238 ┆ 213 ┆ 616 ┆ 411 │\n",
       "│     ┆     ┆     ┆ 24  ┆ 877 ┆ 324 ┆ 325 ┆ 63  ┆ 29  ┆ 824 ┆ 77  ┆ 751 ┆ 03  ┆     ┆     ┆     ┆ 587 ┆ 06  ┆ 31  ┆     ┆ 13  ┆     ┆ 069 ┆ 586 ┆ 56  ┆ 976 ┆ 79  ┆ 74  ┆ 316 ┆ 486 ┆ 14  ┆ 43  ┆ 6   ┆ 811 ┆ 4   ┆ 198 ┆     ┆     ┆ 675 ┆ 574 ┆ 471 ┆ 79  ┆ 56  ┆     ┆ 96  ┆     ┆     ┆ 92  ┆     ┆ 613 ┆ 81  ┆ 791 ┆ 91  ┆ 386 ┆     ┆ 88  ┆     ┆     ┆ 385 ┆     ┆ 724 ┆ 67  ┆     ┆ 51  ┆ 99  ┆ 03  ┆ 996 ┆ 735 ┆ 472 ┆ 134 ┆ 559 ┆ 531 ┆ 19  ┆ 58  ┆ 251 ┆ 95  ┆ 37  ┆     ┆     ┆ 297 ┆ 781 ┆ 999 ┆ 312 ┆ 46  ┆ 63  ┆ 29  ┆ 4   ┆ 883 ┆ 728 ┆ 446 ┆ 885 ┆ 817 ┆ 242 │\n",
       "│ 850 ┆ 0   ┆ 1   ┆ 3.7 ┆ -0. ┆ -2. ┆ -0. ┆ 0.1 ┆ 3.1 ┆ -4. ┆ 0.1 ┆ -0. ┆ 1.9 ┆ 11  ┆ 7   ┆ 76  ┆ -0. ┆ 3.0 ┆ 0.0 ┆ nul ┆ 0.0 ┆ nul ┆ -0. ┆ -1. ┆ 0.1 ┆ 0.0 ┆ 1.9 ┆ 0.7 ┆ -1. ┆ -0. ┆ 0.5 ┆ 1.6 ┆ 1.4 ┆ -0. ┆ 0.0 ┆ 0.0 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ 1.4 ┆ nul ┆ 0.9 ┆ nul ┆ nul ┆ 1.3 ┆ nul ┆ -0. ┆ 1.7 ┆ -2. ┆ 1.2 ┆ -0. ┆ nul ┆ 0.8 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 0.5 ┆ nul ┆ 0.3 ┆ 0.4 ┆ 0.3 ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ -1. ┆ -0. ┆ 1.6 ┆ -0. ┆ -0. ┆ 2.7 ┆ 0.3 ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.7 ┆ -0. ┆ -0. ┆ 0.1 ┆ 0.2 ┆ 0.0 ┆ -0. ┆ 0.5 ┆ 0.5 ┆ -1. │\n",
       "│     ┆     ┆     ┆ 520 ┆ 168 ┆ 161 ┆ 511 ┆ 924 ┆ 620 ┆ 386 ┆ 303 ┆ 368 ┆ 134 ┆     ┆     ┆     ┆ 660 ┆ 521 ┆ 718 ┆ l   ┆ 019 ┆ l   ┆ 625 ┆ 115 ┆ 854 ┆ 192 ┆ 166 ┆ 108 ┆ 102 ┆ 981 ┆ 214 ┆ 659 ┆ 613 ┆ 358 ┆ 580 ┆ 211 ┆ l   ┆ l   ┆ 641 ┆ 482 ┆ 396 ┆ 121 ┆ 091 ┆ l   ┆ 325 ┆ l   ┆ l   ┆ 111 ┆ l   ┆ 749 ┆ 931 ┆ 108 ┆ 279 ┆ 146 ┆ l   ┆ 887 ┆ l   ┆ l   ┆ 427 ┆ l   ┆ 575 ┆ 560 ┆ l   ┆ 218 ┆ 064 ┆ 529 ┆ 388 ┆ 100 ┆ 201 ┆ 926 ┆ 763 ┆ 612 ┆ 128 ┆ 051 ┆ 970 ┆ 945 ┆ 531 ┆ l   ┆ l   ┆ 157 ┆ 163 ┆ 277 ┆ 444 ┆ 895 ┆ 240 ┆ 445 ┆ 257 ┆ 642 ┆ 883 ┆ 649 ┆ 977 ┆ 003 ┆ 605 │\n",
       "│     ┆     ┆     ┆ 97  ┆ 178 ┆ 023 ┆ 679 ┆ 25  ┆ 96  ┆ 098 ┆ 85  ┆ 283 ┆ 16  ┆     ┆     ┆     ┆ 111 ┆ 53  ┆ 69  ┆     ┆ 13  ┆     ┆ 688 ┆ 23  ┆ 83  ┆ 26  ┆ 43  ┆ 87  ┆ 333 ┆ 141 ┆ 67  ┆ 25  ┆ 16  ┆ 575 ┆ 04  ┆ 68  ┆     ┆     ┆ 563 ┆ 115 ┆ 556 ┆ 039 ┆ 37  ┆     ┆ 19  ┆     ┆     ┆ 57  ┆     ┆ 923 ┆ 36  ┆ 881 ┆ 15  ┆ 708 ┆     ┆ 07  ┆     ┆     ┆ 895 ┆     ┆ 317 ┆ 04  ┆     ┆ 17  ┆ 64  ┆ 03  ┆ 503 ┆ 457 ┆ 082 ┆ 849 ┆ 679 ┆ 577 ┆ 3   ┆ 637 ┆ 52  ┆ 5   ┆ 43  ┆     ┆     ┆ 027 ┆ 802 ┆ 016 ┆ 008 ┆ 95  ┆ 175 ┆ 871 ┆ 48  ┆ 27  ┆ 07  ┆ 466 ┆ 18  ┆ 87  ┆ 249 │\n",
       "│ 850 ┆ 0   ┆ 2   ┆ 1.2 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ 3.3 ┆ -2. ┆ 0.1 ┆ -0. ┆ 2.0 ┆ 81  ┆ 2   ┆ 59  ┆ -0. ┆ 3.3 ┆ 0.3 ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -2. ┆ -1. ┆ -0. ┆ 0.0 ┆ -0. ┆ -0. ┆ -0. ┆ 0.2 ┆ 1.3 ┆ 1.2 ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ 0.7 ┆ 0.4 ┆ 1.1 ┆ nul ┆ -0. ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 0.7 ┆ -2. ┆ -1. ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ nul ┆ -2. ┆ nul ┆ -2. ┆ 0.0 ┆ nul ┆ -4. ┆ -2. ┆ 0.3 ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ -2. ┆ -0. ┆ 4.4 ┆ 0.4 ┆ -0. ┆ 1.6 ┆ -0. ┆ nul ┆ nul ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -2. ┆ -0. ┆ -0. ┆ 0.0 ┆ -0. ┆ -0. ┆ 0.9 ┆ -0. ┆ -0. ┆ 1.6 │\n",
       "│     ┆     ┆     ┆ 250 ┆ 520 ┆ 718 ┆ 817 ┆ 270 ┆ 148 ┆ 578 ┆ 102 ┆ 201 ┆ 723 ┆     ┆     ┆     ┆ 528 ┆ 545 ┆ 279 ┆ l   ┆ 215 ┆ l   ┆ 260 ┆ 043 ┆ 314 ┆ 239 ┆ 179 ┆ 275 ┆ 705 ┆ 782 ┆ 683 ┆ 912 ┆ 650 ┆ 539 ┆ 351 ┆ 209 ┆ l   ┆ l   ┆ 164 ┆ 517 ┆ 126 ┆ 187 ┆ 504 ┆ l   ┆ 361 ┆ l   ┆ l   ┆ 394 ┆ l   ┆ 067 ┆ 349 ┆ 053 ┆ 888 ┆ 688 ┆ l   ┆ 588 ┆ l   ┆ l   ┆ 212 ┆ l   ┆ 015 ┆ 259 ┆ l   ┆ 632 ┆ 559 ┆ 529 ┆ 316 ┆ 264 ┆ 248 ┆ 383 ┆ 433 ┆ 728 ┆ 788 ┆ 972 ┆ 449 ┆ 484 ┆ 001 ┆ l   ┆ l   ┆ 012 ┆ 081 ┆ 209 ┆ 267 ┆ 848 ┆ 198 ┆ 217 ┆ 860 ┆ 509 ┆ 734 ┆ 700 ┆ 747 ┆ 662 ┆ 039 │\n",
       "│     ┆     ┆     ┆ 99  ┆ 426 ┆ 115 ┆ 358 ┆ 528 ┆ 25  ┆ 923 ┆     ┆ 74  ┆ 51  ┆     ┆     ┆     ┆ 026 ┆ 08  ┆ 66  ┆     ┆ 615 ┆     ┆ 532 ┆ 01  ┆ 62  ┆ 955 ┆ 58  ┆ 87  ┆ 935 ┆ 762 ┆ 85  ┆ 67  ┆ 22  ┆ 895 ┆ 402 ┆ 022 ┆     ┆     ┆ 031 ┆ 534 ┆ 2   ┆ 21  ┆ 48  ┆     ┆ 983 ┆     ┆     ┆ 171 ┆     ┆ 848 ┆ 42  ┆ 64  ┆ 152 ┆ 585 ┆     ┆ 629 ┆     ┆     ┆ 862 ┆     ┆ 984 ┆ 82  ┆     ┆ 971 ┆ 358 ┆ 03  ┆ 812 ┆ 718 ┆ 274 ┆ 873 ┆ 391 ┆ 091 ┆ 24  ┆ 27  ┆ 675 ┆ 89  ┆ 233 ┆     ┆     ┆ 737 ┆ 892 ┆ 053 ┆ 447 ┆ 316 ┆ 698 ┆ 445 ┆ 82  ┆ 062 ┆ 032 ┆ 75  ┆ 389 ┆ 997 ┆ 58  │\n",
       "│ 850 ┆ 0   ┆ 3   ┆ 1.4 ┆ -0. ┆ -1. ┆ -0. ┆ 0.2 ┆ 3.8 ┆ -1. ┆ 0.0 ┆ -0. ┆ 0.7 ┆ 4   ┆ 3   ┆ 11  ┆ -1. ┆ 1.7 ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -2. ┆ -0. ┆ 0.2 ┆ 0.6 ┆ -0. ┆ 3.0 ┆ 2.2 ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ 0.2 ┆ nul ┆ nul ┆ -1. ┆ -1. ┆ 1.5 ┆ 0.1 ┆ 0.4 ┆ nul ┆ 0.2 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 1.2 ┆ -0. ┆ -0. ┆ -0. ┆ nul ┆ 0.2 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 1.4 ┆ nul ┆ -1. ┆ -0. ┆ 0.3 ┆ -0. ┆ -0. ┆ -0. ┆ -1. ┆ -1. ┆ -0. ┆ 1.3 ┆ -0. ┆ -0. ┆ 2.5 ┆ 0.0 ┆ nul ┆ nul ┆ 0.3 ┆ 0.2 ┆ -0. ┆ -0. ┆ -0. ┆ 0.1 ┆ -0. ┆ 0.4 ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -0. ┆ -1. │\n",
       "│     ┆     ┆     ┆ 670 ┆ 061 ┆ 818 ┆ 990 ┆ 742 ┆ 109 ┆ 111 ┆ 438 ┆ 090 ┆ 777 ┆     ┆     ┆     ┆ 218 ┆ 695 ┆ 076 ┆ l   ┆ 461 ┆ l   ┆ 905 ┆ 141 ┆ 347 ┆ 013 ┆ 299 ┆ 282 ┆ 530 ┆ 926 ┆ 312 ┆ 370 ┆ 473 ┆ 535 ┆ 979 ┆ 098 ┆ l   ┆ l   ┆ 742 ┆ 835 ┆ 118 ┆ 557 ┆ 469 ┆ l   ┆ 552 ┆ l   ┆ l   ┆ 066 ┆ l   ┆ 102 ┆ 249 ┆ 932 ┆ 402 ┆ 369 ┆ l   ┆ 370 ┆ l   ┆ l   ┆ 359 ┆ l   ┆ 917 ┆ 560 ┆ l   ┆ 652 ┆ 545 ┆ 529 ┆ 646 ┆ 382 ┆ 345 ┆ 605 ┆ 561 ┆ 529 ┆ 978 ┆ 131 ┆ 717 ┆ 075 ┆ 201 ┆ l   ┆ l   ┆ 775 ┆ 843 ┆ 067 ┆ 157 ┆ 749 ┆ 709 ┆ 580 ┆ 406 ┆ 154 ┆ 523 ┆ 754 ┆ 248 ┆ 220 ┆ 167 │\n",
       "│     ┆     ┆     ┆ 42  ┆ 985 ┆ 735 ┆ 254 ┆ 84  ┆ 29  ┆ 77  ┆ 42  ┆ 386 ┆ 59  ┆     ┆     ┆     ┆ 813 ┆ 22  ┆ 559 ┆     ┆ 771 ┆     ┆ 882 ┆ 612 ┆ 407 ┆ 98  ┆ 75  ┆ 367 ┆ 07  ┆ 72  ┆ 745 ┆ 565 ┆ 996 ┆ 461 ┆ 823 ┆ 06  ┆     ┆     ┆ 934 ┆ 673 ┆ 21  ┆ 15  ┆ 25  ┆     ┆ 43  ┆     ┆     ┆ 129 ┆     ┆ 276 ┆ 73  ┆ 835 ┆ 716 ┆ 551 ┆     ┆ 87  ┆     ┆     ┆ 047 ┆     ┆ 404 ┆ 03  ┆     ┆ 316 ┆ 286 ┆ 03  ┆ 065 ┆ 81  ┆ 414 ┆ 209 ┆ 482 ┆ 622 ┆ 32  ┆ 058 ┆ 516 ┆ 38  ┆ 02  ┆     ┆     ┆ 17  ┆ 19  ┆ 42  ┆ 564 ┆ 164 ┆ 11  ┆ 147 ┆ 51  ┆ 337 ┆ 854 ┆ 856 ┆ 197 ┆ 052 ┆ 79  │\n",
       "│ 850 ┆ 0   ┆ 5   ┆ 3.1 ┆ -0. ┆ -1. ┆ -0. ┆ -0. ┆ 3.0 ┆ -2. ┆ 0.0 ┆ -0. ┆ 1.2 ┆ 2   ┆ 10  ┆ 171 ┆ -0. ┆ 2.1 ┆ -0. ┆ nul ┆ -0. ┆ nul ┆ -1. ┆ -1. ┆ 0.6 ┆ 0.2 ┆ 1.6 ┆ 0.3 ┆ 0.0 ┆ 0.0 ┆ -0. ┆ 0.9 ┆ 1.7 ┆ -0. ┆ -0. ┆ 0.2 ┆ nul ┆ nul ┆ -0. ┆ 0.0 ┆ 1.2 ┆ 0.1 ┆ 0.6 ┆ nul ┆ 0.4 ┆ nul ┆ nul ┆ -1. ┆ nul ┆ -1. ┆ 1.1 ┆ -0. ┆ 0.5 ┆ 0.3 ┆ nul ┆ 0.2 ┆ nul ┆ nul ┆ -0. ┆ nul ┆ -2. ┆ 1.5 ┆ nul ┆ -1. ┆ -0. ┆ 0.3 ┆ -0. ┆ -0. ┆ -0. ┆ -2. ┆ -2. ┆ -0. ┆ 2.4 ┆ 0.1 ┆ -0. ┆ 1.3 ┆ -0. ┆ nul ┆ nul ┆ 0.3 ┆ 0.2 ┆ -0. ┆ -0. ┆ -0. ┆ 0.1 ┆ 0.0 ┆ -0. ┆ 1.4 ┆ 0.0 ┆ 0.9 ┆ 1.7 ┆ 0.0 ┆ 1.9 │\n",
       "│     ┆     ┆     ┆ 440 ┆ 321 ┆ 964 ┆ 409 ┆ 343 ┆ 696 ┆ 929 ┆ 849 ┆ 214 ┆ 470 ┆     ┆     ┆     ┆ 674 ┆ 787 ┆ 058 ┆ l   ┆ 656 ┆ l   ┆ 158 ┆ 013 ┆ 945 ┆ 291 ┆ 478 ┆ 011 ┆ 182 ┆ 994 ┆ 772 ┆ 329 ┆ 511 ┆ 621 ┆ 675 ┆ 169 ┆ l   ┆ l   ┆ 430 ┆ 015 ┆ 539 ┆ 036 ┆ 577 ┆ l   ┆ 932 ┆ l   ┆ l   ┆ 426 ┆ l   ┆ 534 ┆ 026 ┆ 859 ┆ 552 ┆ 485 ┆ l   ┆ 299 ┆ l   ┆ l   ┆ 513 ┆ l   ┆ 259 ┆ 379 ┆ l   ┆ 007 ┆ 823 ┆ 529 ┆ 480 ┆ 299 ┆ 499 ┆ 799 ┆ 620 ┆ 586 ┆ 131 ┆ 668 ┆ 904 ┆ 615 ┆ 238 ┆ l   ┆ l   ┆ 246 ┆ 620 ┆ 147 ┆ 138 ┆ 882 ┆ 725 ┆ 480 ┆ 045 ┆ 348 ┆ 411 ┆ 369 ┆ 693 ┆ 253 ┆ 070 │\n",
       "│     ┆     ┆     ┆ 71  ┆ 442 ┆ 041 ┆ 452 ┆ 893 ┆ 64  ┆ 145 ┆ 03  ┆ 164 ┆ 11  ┆     ┆     ┆     ┆ 077 ┆ 4   ┆ 749 ┆     ┆ 464 ┆     ┆ 764 ┆ 156 ┆ 89  ┆ 34  ┆ 39  ┆ 07  ┆ 92  ┆ 87  ┆ 632 ┆ 01  ┆ 87  ┆ 377 ┆ 6   ┆ 79  ┆     ┆     ┆ 32  ┆ 58  ┆ 69  ┆ 85  ┆ 33  ┆     ┆ 84  ┆     ┆     ┆ 275 ┆     ┆ 382 ┆ 36  ┆ 073 ┆ 57  ┆ 32  ┆     ┆ 75  ┆     ┆     ┆ 925 ┆     ┆ 789 ┆ 98  ┆     ┆ 17  ┆ 392 ┆ 03  ┆ 987 ┆ 463 ┆ 426 ┆ 66  ┆ 816 ┆ 428 ┆ 69  ┆ 88  ┆ 685 ┆ 27  ┆ 988 ┆     ┆     ┆ 27  ┆ 34  ┆ 552 ┆ 634 ┆ 6   ┆ 49  ┆ 66  ┆ 807 ┆ 16  ┆ 8   ┆ 63  ┆ 05  ┆ 72  ┆ 83  │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = train_df.filter(pl.col('date_id') > 849)\n",
    "print(val_df.shape)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389887f7-ef29-40d3-9595-f4af0b63b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_online_learning(val_data, current_model, optuna_n_trials):\n",
    "    val_data = val_data.clone()\n",
    "    print(val_data.shape)\n",
    "    display(val_data.head())\n",
    "    display(val_data.tail())\n",
    "    i = 0\n",
    "    val_date_ids = sorted(val_data['date_id'].unique())\n",
    "    for date_id_v in val_date_ids:\n",
    "        \n",
    "        for time_id_v in sorted(val_data.filter(pl.col('date_id') == date_id_v)['time_id'].unique()):\n",
    "            time_id_df = val_data.filter((pl.col('date_id') == date_id_v) & (pl.col('time_id') == time_id_v))\n",
    "    \n",
    "            X_train = time_id_df.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "            y_train = time_id_df['responder_6'].to_pandas()\n",
    "            weights_train = time_id_df['weight'].to_pandas()\n",
    "\n",
    "            #train_dataset = lgb.Dataset(data=X_train, label=y_train, weight=weights_train)\n",
    "    \n",
    "            val_data = val_data[time_id_df.shape[0]:]\n",
    "\n",
    "            X_val = val_data.drop(['date_id', 'time_id', 'symbol_id', 'weight', 'responder_6']).select(pl.all().shrink_dtype()).to_pandas()\n",
    "            y_val = val_data['responder_6'].to_pandas()\n",
    "            weights_val = val_data['weight'].to_pandas()\n",
    "\n",
    "            #val_dataset = lgb.Dataset(data=X_val, label=y_val, weight=weights_val)\n",
    "\n",
    "            '''base_params = {\n",
    "                'verbosity': -1,\n",
    "                'learning_rate': 1,\n",
    "                #'feature_fraction': 0.8,\n",
    "                'device': 'gpu',\n",
    "                'early_stopping_round': 30,\n",
    "                #'lambda_l2': 100\n",
    "            }'''\n",
    "\n",
    "            '''updated_model = lgb.train(\n",
    "                params=base_params,\n",
    "                train_set=train_dataset,\n",
    "                valid_sets=[train_dataset, val_dataset],\n",
    "                num_boost_round=90,\n",
    "                init_model=current_model,\n",
    "                callbacks=[log_evaluation(period=50), record_evaluation()]\n",
    "            )'''\n",
    "        \n",
    "            '''online_model = LGBMRegressor(\n",
    "                **base_params,\n",
    "                n_estimators=100000\n",
    "            )'''\n",
    "\n",
    "            '''current_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "            #current_model.fit(X_val, y_val, sample_weight=weights_val, eval_set=[(X_val, y_val), (X_train, y_train)], eval_sample_weight=[weights_val, weights_train], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "            #display(online_model)\n",
    "\n",
    "            plt.figure()\n",
    "            lgb.plot_metric(current_model)\n",
    "            plt.ylim(0, 2)\n",
    "            plt.show()\n",
    "            \n",
    "            val_preds = current_model.predict(X_val)\n",
    "            \n",
    "            return current_model'''\n",
    "\n",
    "            base_params = {\n",
    "                'verbosity': -1,\n",
    "                #'learning_rate': 0.05,\n",
    "                #'feature_fraction': 0.8,\n",
    "                'device': 'gpu',\n",
    "                'early_stopping_round': 10,\n",
    "                #'lambda_l2': 100,\n",
    "                'seed': 42\n",
    "            }\n",
    "\n",
    "            def objective(trial):\n",
    "\n",
    "                params_to_tune = {\n",
    "                    'learning_rate': trial.suggest_float('learning_rate', 0.000001, 0.005),\n",
    "                    'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 300),\n",
    "                    'num_leaves': trial.suggest_int('num_leaves', 20, 10000),\n",
    "                    'max_depth': trial.suggest_int('max_depth', 3, 50),\n",
    "                    'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 0.3),\n",
    "                    'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),\n",
    "                    'lambda_l2': trial.suggest_float('lambda_l2', 0, 2000)\n",
    "                }\n",
    "\n",
    "                online_model = LGBMRegressor(\n",
    "                    **base_params,\n",
    "                    **params_to_tune,\n",
    "                    n_estimators=100000\n",
    "                )\n",
    "\n",
    "                online_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], init_model=current_model)\n",
    "                #online_model.fit(X_val, y_val, sample_weight=weights_val, eval_set=[(X_val, y_val), (X_train, y_train)], eval_sample_weight=[weights_val, weights_train], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "                plt.figure()\n",
    "                lgb.plot_metric(online_model)\n",
    "                plt.ylim(0, 2)\n",
    "                plt.show()\n",
    "\n",
    "                best_iteration = online_model.best_iteration_\n",
    "                print(f\"Best iteration: {best_iteration}\")\n",
    "\n",
    "                val_preds = online_model.predict(X_val)\n",
    "\n",
    "                val_r2_score = r2_score(y_val, val_preds, sample_weight=weights_val)\n",
    "\n",
    "                return val_r2_score\n",
    "\n",
    "            with tqdm(total=optuna_n_trials, desc=\"Optimizing\", unit=\"trial\") as pbar:\n",
    "        \n",
    "                # Define a callback function to update the progress bar\n",
    "                def progress_bar_callback(study, trial):\n",
    "                    pbar.update(1)\n",
    "            \n",
    "                study = optuna.create_study(direction=\"maximize\")\n",
    "                study.optimize(objective, n_trials=optuna_n_trials, callbacks=[progress_bar_callback])\n",
    "\n",
    "            return study\n",
    "        \n",
    "            best_params = study.best_params\n",
    "\n",
    "            online_model.fit(X_train, y_train, sample_weight=weights_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_sample_weight=[weights_train, weights_val], callbacks=[log_evaluation(period=10)], init_model=current_model)\n",
    "\n",
    "            display(online_model)\n",
    "\n",
    "            plt.figure()\n",
    "            lgb.plot_metric(online_model)\n",
    "            plt.ylim(0, 2)\n",
    "            plt.show()\n",
    "            \n",
    "            val_preds = online_model.predict(X_val)\n",
    "\n",
    "            print('Val Weighted R2 score is:', r2_score(y_val, val_preds, sample_weight=weights_val))\n",
    "\n",
    "            return online_model\n",
    "\n",
    "            if i > 20:\n",
    "                return\n",
    "\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82f864-8066-48e1-9afb-184bc933850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study = val_online_learning(val_df, lgb_model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef849ad-a346-465f-ba9e-c4c3f3614bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd780c53-9568-480d-bc02-b28fc79566d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae940b42-2237-4577-bbe4-5a3b08bec314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157c449-2f9c-45ae-a31a-c7a2e4c7c47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5b2e5-0bce-41c2-8fcc-dd6e22a00aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8550b-71b1-4566-982c-4ae37e9ed558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69b03b-80e1-45c0-b742-063d9e9ee361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a704e-3869-4014-8d13-827cab482ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321b527-d9a1-4977-94bf-661d62e83be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5bfc2-0c8d-4dc5-9c1f-a02595836d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_df.drop(['date_id', 'time_id', 'symbol_id']).columns\n",
    "imp_df = pd.DataFrame(sorted(zip(cols, first_shap_importance)), columns=['Feature', 'Importance']).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459cef0-80a6-4b90-9918-332b449c380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506da0e-1120-4d22-99b8-31da7adc1a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7e244-dc03-4612-a335-bd7366f6a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 40))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(imp_df['Feature'], imp_df['Importance'])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c5ce2-6075-47e7-8bf5-98468f451b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_df = imp_df[imp_df['Importance'] <= imp_df['Importance'].quantile(0.3)]\n",
    "unimportant_cols = unimportant_df['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc98e4-b6c4-41a2-b1bf-e63e16828ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected_df = train_df.drop(unimportant_cols)\n",
    "print(train_selected_df.shape)\n",
    "train_selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8c121-661f-4c90-8e3b-c9aa62bf2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_shap_importance = lgb_train(train_selected_df, y_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c749891-7ec2-4ea7-b4a3-40691e436f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
